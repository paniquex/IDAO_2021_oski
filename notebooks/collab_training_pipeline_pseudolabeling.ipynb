{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSCmoclTpRN7",
    "outputId": "d8b5a616-a1f1-4a74-814e-b5965309c566"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpQ-VrFBtUTf",
    "outputId": "7e6892aa-82c9-457f-88e8-f7c4e7d946e0"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    !unzip gdrive/MyDrive/idao_data/IDAO_2021_oski.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gUq78vXwLnS",
    "outputId": "a2041592-dc9c-401b-abb5-31a60e447995"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    !pip install transformers\n",
    "    !pip install timm\n",
    "    !pip install albumentations==0.4.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\tdata  experiments  notebooks  README.md  src\r\n"
     ]
    }
   ],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PShc-I7Ou77w"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if COLAB:\n",
    "    sys.path.append(\"IDAO_2021_oski/src\")\n",
    "else:\n",
    "    sys.path.append(\"../src\")\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from datasets import SimpleDataset\n",
    "from models import Wrapper, MixUp\n",
    "from pipeline_utils import training, pseudolabeling\n",
    "from models import ENCODER_PARAMS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-3X1frCFwGnR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "    PATH_TO_CFG = \"IDAO_2021_oski/config/config.yaml\"\n",
    "else:\n",
    "    PATH_TO_CFG = \"../config/config.yaml\"\n",
    "with open(PATH_TO_CFG, \"r\") as file:\n",
    "    config = yaml.load(file)\n",
    "\n",
    "DATA_ROOT = config[\"general\"][\"data_root\"]\n",
    "\n",
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "fix_seed(config[\"general\"][\"seed\"])\n",
    "device_ids = [str(id) for id in config[\"general\"][\"device_ids\"]]\n",
    "ids = \",\".join(device_ids)\n",
    "DEVICE = torch.device(f\"cuda:{ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1rSsXK7BwUSl"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    DATA_ROOT = \"IDAO_2021_oski/data/track_1/idao_dataset\"\n",
    "else:\n",
    "    DATA_ROOT = \"../data/track_1/idao_dataset\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WJThBPXLxCt-"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_ROOT, \"train.csv\"), index_col=0)\n",
    "\n",
    "val_private = pd.read_csv(os.path.join(DATA_ROOT, \"val_private.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yof4_Anh-x9A"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    train[\"file_path\"] = train[\"file_path\"].str.replace(\"/media/paniquex/samsung_2tb/IDAO_2021_oski\", \"IDAO_2021_oski\")\n",
    "    val_private[\"file_path\"] = val_private[\"file_path\"].str.replace(\"/media/paniquex/samsung_2tb/IDAO_2021_oski\", \"IDAO_2021_oski\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "40Osk2lB6yuD",
    "outputId": "5bfebcc8-4a92-4b3d-8779-fc9c68313112"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>file_path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4030</th>\n",
       "      <td>NR</td>\n",
       "      <td>20</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12593</th>\n",
       "      <td>ER</td>\n",
       "      <td>30</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7515</th>\n",
       "      <td>ER</td>\n",
       "      <td>3</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>NR</td>\n",
       "      <td>6</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9627</th>\n",
       "      <td>ER</td>\n",
       "      <td>30</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7460</th>\n",
       "      <td>ER</td>\n",
       "      <td>30</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8568</th>\n",
       "      <td>ER</td>\n",
       "      <td>10</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7526</th>\n",
       "      <td>ER</td>\n",
       "      <td>10</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NR</td>\n",
       "      <td>20</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>NR</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1                                          file_path  target\n",
       "4030   NR  20  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       8\n",
       "12593  ER  30  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       4\n",
       "7515   ER   3  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       3\n",
       "1608   NR   6  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...      11\n",
       "9627   ER  30  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       4\n",
       "7460   ER  30  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       4\n",
       "8568   ER  10  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       1\n",
       "7526   ER  10  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       1\n",
       "35     NR  20  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       8\n",
       "1749   NR   1  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "_-vPK71b733C",
    "outputId": "a10e7738-ddbf-4ffc-90e5-c41a4c3ad82e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4411</th>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16149</th>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10109</th>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               file_path     type\n",
       "7498   /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...  private\n",
       "4411   /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...  private\n",
       "2246   /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...  private\n",
       "16149  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...  private\n",
       "10109  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...  private"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(os.path.join(DATA_ROOT, \"test.csv\"), index_col=0)\n",
    "if COLAB:\n",
    "    test[\"file_path\"] = test[\"file_path\"].str.replace(\"/media/paniquex/samsung_2tb/IDAO_2021_oski\", \"IDAO_2021_oski\")\n",
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rt9M3seC74AT"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    path = \"IDAO_2021_oski/data/track_1/idao_dataset\" # directory with public_test and private_test directories\n",
    "else:\n",
    "    path = \"../data/track_1/idao_dataset\" # directory with public_test and private_test directories\n",
    "    \n",
    "file_names_public = [x for x in os.listdir(os.path.join(path, \"public_test\")) if \".png\" in x] #+ os.listdir(os.path.join(path, \"private_test\"))\n",
    "test_csv = pd.DataFrame({\"file_path\": file_names_public, \"type\": \"public\"})\n",
    "file_names_private = [x for x in os.listdir(os.path.join(path, \"private_test\")) if \".png\" in x]#+ os.listdir(os.path.join(path, \"private_test\"))\n",
    "test_csv = test_csv.append(pd.DataFrame({\"file_path\": file_names_private, \"type\": \"private\"})).reset_index()\n",
    "\n",
    "test_csv.loc[test_csv[\"type\"] == \"public\", \"file_path\"] = str(os.path.join(path, \"public_test\")) + \"/\" + test_csv[\"file_path\"]\n",
    "test_csv.loc[test_csv[\"type\"] == \"private\", \"file_path\"] = str(os.path.join(path, \"private_test\")) + \"/\" + test_csv[\"file_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "naCzUoap74HY"
   },
   "outputs": [],
   "source": [
    "TEST = test_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TM3tvpYF7ydr"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder() \n",
    "\n",
    "\n",
    "\n",
    "mask_NR = (train[\"0\"] == \"NR\") & ((train[\"1\"] == 1) | (train[\"1\"] == 6) | (train[\"1\"] == 20))\n",
    "mask_ER = (train[\"0\"] == \"ER\") & ((train[\"1\"] == 3) | (train[\"1\"] == 10) | (train[\"1\"] == 30))\n",
    "train = train[mask_NR | mask_ER]\n",
    "train.index = pd.RangeIndex(0, len(train.index))\n",
    "if config[\"general\"][\"task_type\"] == \"regression\":\n",
    "    train[\"target\"] = train[\"1\"]\n",
    "    val_private[\"target\"] = val_private[\"1\"]\n",
    "elif config[\"general\"][\"task_type\"] == \"classification\":\n",
    "    train[\"target\"] = le.fit_transform(train[\"target\"])\n",
    "#     val_private[\"target\"] = le.fit_transform(val_private)\n",
    "elif config[\"general\"][\"task_type\"] == \"joint\":\n",
    "    train[\"target_regression\"] = train[\"1\"]\n",
    "    train[\"target_classification\"] = le.fit_transform(train[\"0\"])\n",
    "    train[\"target\"] = train[\"target_regression\"].astype(str) + \"_\" + train[\"target_classification\"].astype(str)\n",
    "    \n",
    "    val_private[\"target_regression\"] = val_private[\"1\"]\n",
    "    val_private[\"target_classification\"] = le.fit_transform(val_private[\"0\"])\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=config[\"training\"][\"n_folds\"], shuffle=True,\n",
    "                        random_state=config[\"general\"][\"seed\"])\n",
    "for fold, (t_idx, v_idx) in enumerate(kfold.split(train, train[\"target\"])):\n",
    "    train.loc[v_idx, \"kfold\"] = fold\n",
    "\n",
    "\n",
    "    \n",
    "train.to_csv(os.path.join(DATA_ROOT, \"train\", \"train_folds.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "7ze-lkpO70Vi",
    "outputId": "29f2de60-d591-44a2-9014-8e54eee77cb6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>file_path</th>\n",
       "      <th>target</th>\n",
       "      <th>target_regression</th>\n",
       "      <th>target_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>NR</td>\n",
       "      <td>30</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>NR</td>\n",
       "      <td>3</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>NR</td>\n",
       "      <td>10</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>NR</td>\n",
       "      <td>30</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5485</th>\n",
       "      <td>NR</td>\n",
       "      <td>3</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5781</th>\n",
       "      <td>NR</td>\n",
       "      <td>10</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7132</th>\n",
       "      <td>ER</td>\n",
       "      <td>20</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>ER</td>\n",
       "      <td>20</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8012</th>\n",
       "      <td>ER</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>ER</td>\n",
       "      <td>6</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8712</th>\n",
       "      <td>ER</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11714</th>\n",
       "      <td>ER</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1                                          file_path  target  \\\n",
       "2719   NR  30  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...      10   \n",
       "3783   NR   3  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       9   \n",
       "4874   NR  10  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       7   \n",
       "4915   NR  30  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...      10   \n",
       "5485   NR   3  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       9   \n",
       "5781   NR  10  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       7   \n",
       "7132   ER  20  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       2   \n",
       "7397   ER  20  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       2   \n",
       "8012   ER   1  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       0   \n",
       "8142   ER   6  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       5   \n",
       "8712   ER   1  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       0   \n",
       "11714  ER   1  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       0   \n",
       "\n",
       "       target_regression  target_classification  \n",
       "2719                  30                      1  \n",
       "3783                   3                      1  \n",
       "4874                  10                      1  \n",
       "4915                  30                      1  \n",
       "5485                   3                      1  \n",
       "5781                  10                      1  \n",
       "7132                  20                      0  \n",
       "7397                  20                      0  \n",
       "8012                   1                      0  \n",
       "8142                   6                      0  \n",
       "8712                   1                      0  \n",
       "11714                  1                      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hr5tT-V7522",
    "outputId": "d362c7eb-3b2a-4c0e-efb9-ab280e5aefd5"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    !pip install --upgrade --force-reinstall --no-deps albumentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YGp5DtXj732Z"
   },
   "outputs": [],
   "source": [
    "import albumentations\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "transforms_train = albumentations.Compose([\n",
    "    ColorJitter (brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "    ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "    CenterCrop(height=400,\n",
    "               width=400),\n",
    "    Resize(*config[\"preprocessing\"][\"img_size\"]),\n",
    "    Normalize(\n",
    "         mean=[0.485, 0.456, 0.406],\n",
    "         std=[0.229, 0.224, 0.225],\n",
    "     ),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "transforms_val = albumentations.Compose([\n",
    "    CenterCrop(height=400,\n",
    "               width=400),\n",
    "    Resize(*config[\"preprocessing\"][\"img_size\"]),\n",
    "    Normalize(\n",
    "         mean=[0.485, 0.456, 0.406],\n",
    "         std=[0.229, 0.224, 0.225],\n",
    "     ),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NUK2xoyJ79Rz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "    \n",
    "def focal_loss(input, target, focus=2.0, raw=False):\n",
    "\n",
    "    if raw:\n",
    "        input = torch.sigmoid(input)\n",
    "\n",
    "    eps = 1e-7\n",
    "\n",
    "    prob_true = input * target + (1 - input) * (1 - target)\n",
    "    prob_true = torch.clamp(prob_true, eps, 1-eps)\n",
    "    modulating_factor = (1.0 - prob_true).pow(focus)\n",
    "\n",
    "    return (-modulating_factor * prob_true.log()).mean()\n",
    "\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "\n",
    "\n",
    "class AngularPenaltySMLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, loss_type=\"cosface\", eps=1e-7, s=None, m=None):\n",
    "        '''\n",
    "        Angular Penalty Softmax Loss\n",
    "        Three 'loss_types' available: ['arcface', 'sphereface', 'cosface']\n",
    "        These losses are described in the following papers: \n",
    "        \n",
    "        ArcFace: https://arxiv.org/abs/1801.07698\n",
    "        SphereFace: https://arxiv.org/abs/1704.08063\n",
    "        CosFace/Ad Margin: https://arxiv.org/abs/1801.05599\n",
    "        '''\n",
    "        super(AngularPenaltySMLoss, self).__init__()\n",
    "        loss_type = loss_type.lower()\n",
    "        assert loss_type in  ['arcface', 'sphereface', 'cosface']\n",
    "        if loss_type == 'arcface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 0.5 if not m else m\n",
    "        if loss_type == 'sphereface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 1.35 if not m else m\n",
    "        if loss_type == 'cosface':\n",
    "            self.s = 30.0 if not s else s\n",
    "            self.m = 0.4 if not m else m\n",
    "        self.loss_type = loss_type\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        '''\n",
    "        input shape (N, in_features)\n",
    "        '''\n",
    "        assert len(x) == len(labels)\n",
    "        assert torch.min(labels) >= 0\n",
    "        assert torch.max(labels) < self.out_features\n",
    "        \n",
    "        for W in self.fc.parameters():\n",
    "            W = F.normalize(W, p=2, dim=1)\n",
    "\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "#         print(x.shape)\n",
    "        wf = self.fc(x)\n",
    "        if self.loss_type == 'cosface':\n",
    "            numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n",
    "        if self.loss_type == 'arcface':\n",
    "            numerator = self.s * torch.cos(torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)) + self.m)\n",
    "        if self.loss_type == 'sphereface':\n",
    "            numerator = self.s * torch.cos(self.m * torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)))\n",
    "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
    "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
    "        L = numerator - torch.log(denominator)\n",
    "        return -torch.mean(L), wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bnnH4xZ3GmZO"
   },
   "outputs": [],
   "source": [
    "config[\"training\"][\"loss\"] = {\"reg\": \"L1\", \"clf\": \"BCE\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "luyHVLAJ-Cro"
   },
   "outputs": [],
   "source": [
    "EPOCHS = config[\"training\"][\"n_epochs\"]\n",
    "\n",
    "\n",
    "criterion_aam = None\n",
    "if config[\"general\"][\"task_type\"] == \"classification\":\n",
    "    if config[\"training\"][\"loss\"][\"clf\"] == \"FOCAL\":\n",
    "        criterion = focal_loss\n",
    "    elif config[\"training\"][\"loss\"][\"clf\"] == \"AAM\":\n",
    "        criterion = \"AAM\"\n",
    "        criterion_aam = AngularPenaltySMLoss\n",
    "    elif config[\"training\"][\"loss\"][\"clf\"] == \"BCE\":\n",
    "        criterion = nn.BCELoss()\n",
    "elif config[\"general\"][\"task_type\"] == \"regression\":\n",
    "    if config[\"training\"][\"loss\"][\"reg\"] == \"L1\":\n",
    "        criterion = nn.L1Loss()\n",
    "    elif config[\"training\"][\"loss\"][\"reg\"] == \"L2\":\n",
    "        criterion = nn.MSELoss()\n",
    "elif config[\"training\"][\"loss\"] == \"L1\":\n",
    "    criterion = nn.L1Loss()\n",
    "elif config[\"general\"][\"task_type\"] == \"joint\":\n",
    "    criterion = {}\n",
    "    if config[\"training\"][\"loss\"][\"clf\"] == \"FOCAL\":\n",
    "        criterion[\"clf\"] = focal_loss\n",
    "    elif config[\"training\"][\"loss\"][\"clf\"] == \"AAM\":\n",
    "        criterion[\"clf\"] = \"AAM\"\n",
    "        criterion_aam = AngularPenaltySMLoss\n",
    "    elif config[\"training\"][\"loss\"][\"clf\"] == \"BCE\":\n",
    "        criterion[\"clf\"] = nn.BCELoss()\n",
    "    if config[\"training\"][\"loss\"][\"reg\"] == \"L1\":\n",
    "        criterion[\"reg\"] = nn.L1Loss()\n",
    "    elif config[\"training\"][\"loss\"][\"reg\"] == \"L2\":\n",
    "        criterion[\"reg\"] = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rcQIzBZF-ENg"
   },
   "outputs": [],
   "source": [
    "model_names = None\n",
    "if config[\"training\"][\"finetune\"]:\n",
    "    model_names = [name for name in os.listdir(config['training']['models_dir']) if name.find(\"best_model_fold\") != -1]\n",
    "    model_names = sorted(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PaDqqzvPGRIw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JSD2DAbBUtK",
    "outputId": "a43d9047-eca9-4077-f40e-c2673db749a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': BCELoss(), 'reg': L1Loss()}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "S8ih8e4peXWA"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    config[\"general\"][\"out_path\"] = \"IDAO_2021_oski/experiments/resnest14d_1e-4_joint_BCE_L1/\"\n",
    "else:\n",
    "    config[\"general\"][\"out_path\"] = \"../experiments/resnest14d_1e-4_joint_BCE_L1/\"\n",
    "    \n",
    "config[\"preprocessing\"][\"img_size\"] = [224, 224]\n",
    "config[\"training\"][\"dataloader\"][\"batch_size\"] = 4\n",
    "config[\"training\"][\"n_folds\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAcGc1w1-Ipw",
    "outputId": "38103bdf-8b82-4876-9a23-941d3fd38d2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5.7503:   7%|â–‹         | 166/2232 [00:29<06:10,  5.58it/s] \n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR in loss list appending\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-4156a8dd7984>\", line 65, in <module>\n",
      "    task_type=config[\"general\"][\"task_type\"], CONFIG_PATH=PATH_TO_CFG)\n",
      "  File \"../src/pipeline_utils.py\", line 63, in training\n",
      "    for batch in t:\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/tqdm/std.py\", line 1158, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1182, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1148, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 986, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/multiprocessing/connection.py\", line 620, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/inspect.py\", line 687, in getsourcefile\n",
      "    if any(filename.endswith(s) for s in all_bytecode_suffixes):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-4156a8dd7984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m                                             \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                                             task_type=config[\"general\"][\"task_type\"], CONFIG_PATH=PATH_TO_CFG)\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/paniquex/samsung_2tb/IDAO_2021_oski/src/pipeline_utils.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(EPOCHS, model, train_dataloader, val_dataloaders_dct, DEVICE, criterion, optimizer, config, scheduler, fold, pseudo_iter, task_type, CONFIG_PATH)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtask_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"joint\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSocketClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mSocketClient\u001b[0;34m(address)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FileNotFoundError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shutil.rmtree(config[\"general\"][\"out_path\"])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(config[\"general\"][\"out_path\"])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "if config[\"general\"][\"task_type\"] == \"regression\":\n",
    "    config[\"general\"][\"classes_num\"] = 1\n",
    "elif config[\"general\"][\"task_type\"] == \"joint\":\n",
    "    config[\"general\"][\"classes_num\"] = 2\n",
    "    \n",
    "    \n",
    "samples2preds_all = {}\n",
    "samples2trues_all = {}\n",
    "\n",
    "models = []\n",
    "for i in range(config[\"training\"][\"n_folds\"]):\n",
    "    model_name = config[\"general\"][\"model_name\"]\n",
    "    model = None\n",
    "    model = ENCODER_PARAMS[model_name][\"init_op\"]()\n",
    "    model = Wrapper(model, feat_module=None, classes_num=config[\"general\"][\"classes_num\"],\n",
    "                    model_name=model_name,\n",
    "                    spec_augmenter=None, \n",
    "                    mixup_module=None,\n",
    "                    task_type=config[\"general\"][\"task_type\"],\n",
    "                    activation_func=config[\"training\"][\"activation_func\"],\n",
    "                    criterion_aam=criterion_aam)\n",
    "    model.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"training\"][\"lr\"])\n",
    "#         optimizer = Ranger(model.parameters(),\n",
    "#                lr=config[\"training\"][\"lr\"],\n",
    "#                betas=(.90, 0.999), k=4)\n",
    "    train_dataset = SimpleDataset(df=train[train[\"kfold\"] != fold], mode=\"train\",\n",
    "                                  transform=transforms_train, classes_num=config[\"general\"][\"classes_num\"],\n",
    "                                  task_type=config[\"general\"][\"task_type\"])\n",
    "\n",
    "    val_dataset = SimpleDataset(df=train[train[\"kfold\"] == fold], mode=\"val\",\n",
    "                                transform=transforms_val, classes_num=config[\"general\"][\"classes_num\"],\n",
    "                                task_type=config[\"general\"][\"task_type\"])\n",
    "    val_private_dataset = SimpleDataset(df=val_private, mode=\"val\",\n",
    "                                        transform=transforms_val, classes_num=config[\"general\"][\"classes_num\"],\n",
    "                                        task_type=config[\"general\"][\"task_type\"])\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                  **config[\"training\"][\"dataloader\"])\n",
    "    val_dataloader = DataLoader(val_dataset,\n",
    "                                **config[\"validation\"][\"dataloader\"])\n",
    "    val_private_dataloader = DataLoader(val_private_dataset,\n",
    "                                        **config[\"validation\"][\"dataloader\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                      T_max=(config[\"training\"][\"n_epochs\"] - config[\"training\"][\"n_epochs_flat\"])  * len(train_dataloader),\n",
    "                                                      eta_min=1e-8)    \n",
    "    samples2preds, samples2trues, model = training(EPOCHS=EPOCHS, model=model,\n",
    "                                            train_dataloader=train_dataloader, \n",
    "                                            val_dataloaders_dct={\"val_dataloader\": val_dataloader,\n",
    "                                                                  \"val_private_dataloader\": val_private_dataloader},\n",
    "                                            DEVICE=DEVICE, criterion=criterion,\n",
    "                                            optimizer=optimizer, scheduler=scheduler,\n",
    "                                            config=config, fold=i,\n",
    "                                            task_type=config[\"general\"][\"task_type\"], CONFIG_PATH=PATH_TO_CFG)\n",
    "    models.append(model)\n",
    "    samples2preds_all.update(samples2preds)\n",
    "    samples2trues_all.update(samples2trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sxutlu3MeEpZ"
   },
   "outputs": [],
   "source": [
    "# import imp\n",
    "# #imp.reload(pipeline_utils)\n",
    "# imp.reload(datasets)\n",
    "# test = test_csv\n",
    "#import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMpIdLe1-JuZ",
    "outputId": "17615fb1-8aad-4416-d200-7ff348a7c9e3"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "samples2preds_all = {}\n",
    "samples2trues_all = {}\n",
    "LR = config[\"training\"][\"lr\"]\n",
    "flag_LR = True\n",
    "\n",
    "for j in range(config[\"pseudo\"][\"iter\"]):\n",
    "    with torch.no_grad():\n",
    "        train, test = pipeline_utils.pseudolabeling(models, train, test, config, DEVICE, transforms_val)\n",
    "        private = (train[\"type\"].values == \"private\").sum()\n",
    "        public = (train[\"type\"].values == \"public\").sum()\n",
    "        print(\"Pseudo labeling epoch\", j)\n",
    "        print(\"Private ratio\", private / (public + private)) \n",
    "        print(\"Public ratio\", public / (public + private))\n",
    "        if flag_LR:\n",
    "            LR *= config[\"pseudo\"][\"lr_coef\"]\n",
    "            flag_LR = False\n",
    "    \n",
    "    for i in range(config[\"training\"][\"n_folds\"]):\n",
    "        model = models[i]\n",
    "        model.to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    #         optimizer = Ranger(model.parameters(),\n",
    "    #                lr=config[\"training\"][\"lr\"],\n",
    "    #                betas=(.90, 0.999), k=4)\n",
    "        train_dataset = SimpleDataset(df=train[train[\"kfold\"] != fold], mode=\"train\",\n",
    "                                      transform=transforms_train, classes_num=config[\"general\"][\"classes_num\"],\n",
    "                                      task_type=config[\"general\"][\"task_type\"])\n",
    "\n",
    "        val_dataset = SimpleDataset(df=train[train[\"kfold\"] == fold], mode=\"val\",\n",
    "                                    transform=transforms_val, classes_num=config[\"general\"][\"classes_num\"],\n",
    "                                    task_type=config[\"general\"][\"task_type\"])\n",
    "        val_private_dataset = SimpleDataset(df=val_private, mode=\"val\",\n",
    "                                            transform=transforms_val, classes_num=config[\"general\"][\"classes_num\"],\n",
    "                                            task_type=config[\"general\"][\"task_type\"])\n",
    "        \n",
    "        train_dataloader = DataLoader(train_dataset,\n",
    "                                      **config[\"training\"][\"dataloader\"])\n",
    "        val_dataloader = DataLoader(val_dataset,\n",
    "                                    **config[\"validation\"][\"dataloader\"])\n",
    "        val_private_dataloader = DataLoader(val_private_dataset,\n",
    "                                            **config[\"validation\"][\"dataloader\"])\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                          T_max=(config[\"pseudo\"][\"n_epochs\"] - config[\"pseudo\"][\"n_epochs_flat\"])  * len(train_dataloader),\n",
    "                                                          eta_min=1e-8)    \n",
    "        samples2preds, samples2trues, model = training(EPOCHS=config[\"pseudo\"][\"n_epochs\"], model=model,\n",
    "                                                train_dataloader=train_dataloader, \n",
    "                                                val_dataloaders_dct={\"val_dataloader\": val_dataloader,\n",
    "                                                                      \"val_private_dataloader\": val_private_dataloader},\n",
    "                                                DEVICE=DEVICE, criterion=criterion,\n",
    "                                                optimizer=optimizer, scheduler=scheduler,\n",
    "                                                config=config, fold=i, pseudo_iter=j+1,\n",
    "                                                task_type=config[\"general\"][\"task_type\"], CONFIG_PATH=PATH_TO_CFG)\n",
    "        models[i] = model\n",
    "        samples2preds_all.update(samples2preds)\n",
    "        samples2trues_all.update(samples2trues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAYSmF9876rJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "collab_training_pipeline_pseudolabeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
