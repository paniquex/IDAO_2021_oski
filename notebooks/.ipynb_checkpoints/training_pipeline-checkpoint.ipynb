{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/media/paniquex/samsung_2tb/rfcx_kaggle_git/RFCX_kaggle/src\")\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "import librosa as lb\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "import audiomentations\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "from torchaudio.transforms import MFCC\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from datasets import LabeledWavDataset, StepWavDataset\n",
    "from preprocessing import CMVN, MelSpecComputer, MFCCComputer, MelSpecComputer3D\n",
    "from models import Wrapper, MixUp\n",
    "from pipeline_utils import training\n",
    "from models import ENCODER_PARAMS\n",
    "\n",
    "\n",
    "from ranger import Ranger\n",
    "\n",
    "\n",
    "os.chdir(\"/media/paniquex/samsung_2tb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:3: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_CFG = \"/media/paniquex/samsung_2tb/rfcx_kaggle_git/RFCX_kaggle/config/config.yaml\"\n",
    "with open(PATH_TO_CFG, \"r\") as file:\n",
    "    config = yaml.load(file)\n",
    "\n",
    "DATA_ROOT = config[\"general\"][\"data_root\"]\n",
    "\n",
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "fix_seed(config[\"general\"][\"seed\"])\n",
    "device_ids = [str(id) for id in config[\"general\"][\"device_ids\"]]\n",
    "ids = \",\".join(device_ids)\n",
    "DEVICE = torch.device(f\"cuda:{ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add mappings files\n",
    "if len(config[\"training\"][\"augmentations\"]):\n",
    "    augmenter_train = audiomentations.Compose([\n",
    "        audiomentations.AddGaussianNoise(**config[\"training\"][\"augmentations\"][\"GaussianNoise\"]),\n",
    "        audiomentations.AddGaussianSNR(**config[\"training\"][\"augmentations\"][\"GaussianSNR\"]),\n",
    "        #audiomentations.AddBackgroundNoise(\"../input/train_audio/\", p=1)\n",
    "        #audiomentations.AddImpulseResponse(p=0.1),\n",
    "        #audiomentations.AddShortNoises(\"../input/train_audio/\", p=1)\n",
    "#         audiomentations.FrequencyMask(min_frequency_band=0.0,  max_frequency_band=0.2, p=0.3),\n",
    "#         audiomentations.TimeMask(min_band_part=0.0, max_band_part=0.2, p=0.3),\n",
    "        #audiomentations.PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.05),\n",
    "        #audiomentations.Shift(p=0.1),\n",
    "        #audiomentations.Normalize(p=0.1),\n",
    "        #audiomentations.ClippingDistortion(min_percentile_threshold=0, max_percentile_threshold=1, p=0.05),\n",
    "        #audiomentations.PolarityInversion(p=0.05),\n",
    "        audiomentations.Gain(**config[\"training\"][\"augmentations\"][\"Gain\"])\n",
    "    ])\n",
    "else:\n",
    "    augmenter_train = None\n",
    "\n",
    "if len(config[\"validation\"][\"augmentations\"]):\n",
    "    augmenter_val = audiomentations.Compose([\n",
    "        audiomentations.AddGaussianNoise(**config[\"validation\"][\"augmentations\"][\"GaussianNoise\"]),\n",
    "        audiomentations.AddGaussianSNR(**config[\"validation\"][\"augmentations\"][\"GaussianSNR\"]),\n",
    "        #audiomentations.AddBackgroundNoise(\"../input/train_audio/\", p=1)\n",
    "        #audiomentations.AddImpulseResponse(p=0.1),\n",
    "        #audiomentations.AddShortNoises(\"../input/train_audio/\", p=1)\n",
    "        audiomentations.FrequencyMask(min_frequency_band=0.0,  max_frequency_band=0.2, p=0.3),\n",
    "        audiomentations.TimeMask(min_band_part=0.0, max_band_part=0.2, p=0.3),\n",
    "        #audiomentations.PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.05),\n",
    "        #audiomentations.Shift(p=0.1),\n",
    "        #audiomentations.Normalize(p=0.1),\n",
    "        #audiomentations.ClippingDistortion(min_percentile_threshold=0, max_percentile_threshold=1, p=0.05),\n",
    "        #audiomentations.PolarityInversion(p=0.05),\n",
    "        audiomentations.Gain(**config[\"validation\"][\"augmentations\"][\"Gain\"])\n",
    "    ])\n",
    "else:\n",
    "    augmenter_val = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    249\n",
      "4    247\n",
      "0    242\n",
      "3    240\n",
      "1    238\n",
      "Name: kfold, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_ROOT, \"train_tp.csv\"))\n",
    "# train_gby = train.groupby(\"recording_id\")[[\"species_id\"]].first().reset_index()\n",
    "# train_gby = train_gby.sample(frac=1, random_state=config[\"general\"][\"seed\"]).reset_index(drop=True)\n",
    "\n",
    "# X = train_gby[\"recording_id\"].values\n",
    "\n",
    "# samples_train, samples_val = train_test_split(X,\n",
    "#                                               train_size=config[\"training\"][\"train_size\"],\n",
    "#                                               random_state=config[\"general\"][\"seed\"])\n",
    "\n",
    "train_gby = train.groupby(\"recording_id\")[[\"species_id\"]].first().reset_index()\n",
    "train_gby = train_gby.sample(frac=1, random_state=config[\"general\"][\"seed\"]).reset_index(drop=True)\n",
    "train_gby.loc[:, 'kfold'] = -1\n",
    "\n",
    "X = train_gby[\"recording_id\"].values\n",
    "y = train_gby[\"species_id\"].values\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=config[\"training\"][\"n_folds\"])\n",
    "for fold, (t_idx, v_idx) in enumerate(kfold.split(X, y)):\n",
    "    train_gby.loc[v_idx, \"kfold\"] = fold\n",
    "\n",
    "train = train.merge(train_gby[['recording_id', 'kfold']], on=\"recording_id\", how=\"left\")\n",
    "print(train.kfold.value_counts())\n",
    "train.to_csv(\"/media/paniquex/samsung_2tb/rfcx_kaggle/rfcx-species-audio-detection/train_folds.csv\")\n",
    "train.to_csv(f\"/media/paniquex/samsung_2tb/rfcx_kaggle/rfcx-species-audio-detection/train_{config['preprocessing']['sr']}/train_folds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = LabeledWavDataset(transforms=augmenter_train,\n",
    "#                                   samples=samples_train,\n",
    "#                                   classes_num=config[\"general\"][\"classes_num\"],\n",
    "#                                   sr=config[\"preprocessing\"][\"sr\"],\n",
    "#                                   **config[\"training\"][\"dataset\"])\n",
    "\n",
    "# val_dataset = LabeledWavDataset(transforms=augmenter_val,\n",
    "#                                  samples=samples_val,\n",
    "#                                  classes_num=config[\"general\"][\"classes_num\"],\n",
    "#                                  sr=config[\"preprocessing\"][\"sr\"],\n",
    "#                                  **config[\"validation\"][\"dataset\"])\n",
    "\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, **config[\"training\"][\"dataloader\"])\n",
    "# val_dataloader = DataLoader(val_dataset, **config[\"validation\"][\"dataloader\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#torch.optim.Adam(model.model.parameters(), lr=config[\"training\"][\"lr\"]) # TODO: add mappings file for losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def lsep_loss_stable(input, target, average=True):\n",
    "\n",
    "    n = input.size(0)\n",
    "\n",
    "    differences = input.unsqueeze(1) - input.unsqueeze(2)\n",
    "    where_lower = (target.unsqueeze(1) < target.unsqueeze(2)).float()\n",
    "\n",
    "    differences = differences.view(n, -1)\n",
    "    where_lower = where_lower.view(n, -1)\n",
    "\n",
    "    max_difference, index = torch.max(differences, dim=1, keepdim=True)\n",
    "    differences = differences - max_difference\n",
    "    exps = differences.exp() * where_lower\n",
    "\n",
    "    lsep = max_difference + torch.log(torch.exp(-max_difference) + exps.sum(-1))\n",
    "\n",
    "    if average:\n",
    "        return lsep.mean()\n",
    "    else:\n",
    "        return lsep\n",
    "    \n",
    "    \n",
    "def focal_loss(input, target, focus=2.0, raw=False):\n",
    "\n",
    "    if raw:\n",
    "        input = torch.sigmoid(input)\n",
    "\n",
    "    eps = 1e-7\n",
    "\n",
    "    prob_true = input * target + (1 - input) * (1 - target)\n",
    "    prob_true = torch.clamp(prob_true, eps, 1-eps)\n",
    "    modulating_factor = (1.0 - prob_true).pow(focus)\n",
    "\n",
    "    return (-modulating_factor * prob_true.log()).mean()\n",
    "\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "\n",
    "class PANNsLoss(nn.Module):\n",
    "    def __init__(self, criterion_):\n",
    "        super().__init__()\n",
    "\n",
    "        self.criterion_ = criterion_\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input_ = input[\"clipwise_output\"]\n",
    "        input_ = torch.where(torch.isnan(input_),\n",
    "                             torch.zeros_like(input_),\n",
    "                             input_)\n",
    "        input_ = torch.where(torch.isinf(input_),\n",
    "                             torch.zeros_like(input_),\n",
    "                             input_)\n",
    "\n",
    "        target = target.float()\n",
    "\n",
    "        return self.criterion_(input_, target)\n",
    "\n",
    "class ImprovedPANNsLoss(nn.Module):\n",
    "    def __init__(self, output_key=\"logit\", weights=[1, 0.5]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_key = output_key\n",
    "        if output_key == \"logit\":\n",
    "            self.normal_loss = nn.BCEWithLogitsLoss()\n",
    "        else:\n",
    "            self.normal_loss = nn.BCELoss()\n",
    "\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input_ = input[self.output_key]\n",
    "        target = target.float()\n",
    "\n",
    "        framewise_output = input[\"framewise_output\"]\n",
    "        clipwise_output_with_max, _ = framewise_output.max(dim=1)\n",
    "\n",
    "        normal_loss = self.normal_loss(input_, target)\n",
    "        auxiliary_loss = self.bce(clipwise_output_with_max, target)\n",
    "\n",
    "        return self.weights[0] * normal_loss + self.weights[1] * auxiliary_loss\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class AngularPenaltySMLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, loss_type=\"cosface\", eps=1e-7, s=None, m=None):\n",
    "        '''\n",
    "        Angular Penalty Softmax Loss\n",
    "        Three 'loss_types' available: ['arcface', 'sphereface', 'cosface']\n",
    "        These losses are described in the following papers: \n",
    "        \n",
    "        ArcFace: https://arxiv.org/abs/1801.07698\n",
    "        SphereFace: https://arxiv.org/abs/1704.08063\n",
    "        CosFace/Ad Margin: https://arxiv.org/abs/1801.05599\n",
    "        '''\n",
    "        super(AngularPenaltySMLoss, self).__init__()\n",
    "        loss_type = loss_type.lower()\n",
    "        assert loss_type in  ['arcface', 'sphereface', 'cosface']\n",
    "        if loss_type == 'arcface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 0.5 if not m else m\n",
    "        if loss_type == 'sphereface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 1.35 if not m else m\n",
    "        if loss_type == 'cosface':\n",
    "            self.s = 30.0 if not s else s\n",
    "            self.m = 0.4 if not m else m\n",
    "        self.loss_type = loss_type\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        '''\n",
    "        input shape (N, in_features)\n",
    "        '''\n",
    "        assert len(x) == len(labels)\n",
    "        assert torch.min(labels) >= 0\n",
    "        assert torch.max(labels) < self.out_features\n",
    "        \n",
    "        for W in self.fc.parameters():\n",
    "            W = F.normalize(W, p=2, dim=1)\n",
    "\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "#         print(x.shape)\n",
    "        wf = self.fc(x)\n",
    "        if self.loss_type == 'cosface':\n",
    "            numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n",
    "        if self.loss_type == 'arcface':\n",
    "            numerator = self.s * torch.cos(torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)) + self.m)\n",
    "        if self.loss_type == 'sphereface':\n",
    "            numerator = self.s * torch.cos(self.m * torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)))\n",
    "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
    "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
    "        L = numerator - torch.log(denominator)\n",
    "        return -torch.mean(L), wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = config[\"training\"][\"n_epochs\"]\n",
    "\n",
    "criterion_aam = None\n",
    "if config[\"general\"][\"SED\"]:\n",
    "#     if config[\"training\"][\"loss\"] == \"BCE\":\n",
    "#         criterion_ = nn.BCELoss()\n",
    "#     elif config[\"training\"][\"loss\"] == \"LSEP\":\n",
    "#         criterion_ = lsep_loss_stable\n",
    "#     elif config[\"training\"][\"loss\"] == \"FOCAL\":\n",
    "#         criterion_ = focal_loss]\n",
    "    if config[\"training\"][\"loss\"] == \"ImprovedPANN\":\n",
    "        criterion = ImprovedPANNsLoss()\n",
    "#     criterion = PANNsLoss(criterion_=criterion_)\n",
    "else:\n",
    "    if config[\"training\"][\"loss\"] == \"BCE\":\n",
    "        criterion = nn.BCELoss()\n",
    "    elif config[\"training\"][\"loss\"] == \"LSEP\":\n",
    "        criterion = lsep_loss_stable\n",
    "    elif config[\"training\"][\"loss\"] == \"FOCAL\":\n",
    "        criterion = focal_loss\n",
    "    elif config[\"training\"][\"loss\"] == \"AAM\":\n",
    "        criterion = \"AAM\"\n",
    "        criterion_aam = AngularPenaltySMLoss\n",
    "    \n",
    "# num_train_steps = int(len(train_dataloader) * EPOCHS)\n",
    "# num_warmup_steps = int(0.1 * EPOCHS * len(train_dataloader))\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6) # TODO: add mappings file for losses\n",
    "# scheduler = None\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>songtype_id</th>\n",
       "      <th>t_min</th>\n",
       "      <th>f_min</th>\n",
       "      <th>t_max</th>\n",
       "      <th>f_max</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003bec244</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>44.5440</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.1307</td>\n",
       "      <td>5531.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006ab765f</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39.9615</td>\n",
       "      <td>7235.160</td>\n",
       "      <td>46.0452</td>\n",
       "      <td>11283.40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007f87ba2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>39.1360</td>\n",
       "      <td>562.500</td>\n",
       "      <td>42.2720</td>\n",
       "      <td>3281.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0099c367b</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>51.4206</td>\n",
       "      <td>1464.260</td>\n",
       "      <td>55.1996</td>\n",
       "      <td>4565.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009b760e6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0854</td>\n",
       "      <td>947.461</td>\n",
       "      <td>52.5293</td>\n",
       "      <td>10852.70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>fe8d9ac40</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>53.4720</td>\n",
       "      <td>93.750</td>\n",
       "      <td>54.0960</td>\n",
       "      <td>843.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>fea6b438a</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>43.5787</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.7653</td>\n",
       "      <td>4031.25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>ff2eb9ce5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2267</td>\n",
       "      <td>5906.250</td>\n",
       "      <td>16.0213</td>\n",
       "      <td>8250.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>ffb8d8391</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14.3467</td>\n",
       "      <td>4781.250</td>\n",
       "      <td>16.6987</td>\n",
       "      <td>10406.20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>ffb9a7b9a</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>40.3200</td>\n",
       "      <td>3187.500</td>\n",
       "      <td>41.0133</td>\n",
       "      <td>5062.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1216 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     recording_id  species_id  songtype_id    t_min     f_min    t_max  \\\n",
       "0       003bec244          14            1  44.5440  2531.250  45.1307   \n",
       "1       006ab765f          23            1  39.9615  7235.160  46.0452   \n",
       "2       007f87ba2          12            1  39.1360   562.500  42.2720   \n",
       "3       0099c367b          17            4  51.4206  1464.260  55.1996   \n",
       "4       009b760e6          10            1  50.0854   947.461  52.5293   \n",
       "...           ...         ...          ...      ...       ...      ...   \n",
       "1211    fe8d9ac40          13            1  53.4720    93.750  54.0960   \n",
       "1212    fea6b438a           4            1  43.5787  2531.250  45.7653   \n",
       "1213    ff2eb9ce5           0            1  15.2267  5906.250  16.0213   \n",
       "1214    ffb8d8391           5            1  14.3467  4781.250  16.6987   \n",
       "1215    ffb9a7b9a          18            1  40.3200  3187.500  41.0133   \n",
       "\n",
       "         f_max  kfold  \n",
       "0      5531.25      2  \n",
       "1     11283.40      3  \n",
       "2      3281.25      1  \n",
       "3      4565.04      1  \n",
       "4     10852.70      3  \n",
       "...        ...    ...  \n",
       "1211    843.75      4  \n",
       "1212   4031.25      3  \n",
       "1213   8250.00      1  \n",
       "1214  10406.20      3  \n",
       "1215   5062.50      0  \n",
       "\n",
       "[1216 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = None\n",
    "if config[\"training\"][\"finetune\"]:\n",
    "    model_names = [name for name in os.listdir(config['training']['models_dir']) if name.find(\"best_model_fold\") != -1]\n",
    "    model_names = sorted(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0516: 100%|██████████| 81/81 [00:37<00:00,  2.15it/s]\n",
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:02<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0437: 100%|██████████| 81/81 [00:32<00:00,  2.52it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0423: 100%|██████████| 81/81 [00:32<00:00,  2.48it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 11.75it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0428: 100%|██████████| 81/81 [00:32<00:00,  2.46it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.52it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0424: 100%|██████████| 81/81 [00:33<00:00,  2.43it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0420: 100%|██████████| 81/81 [00:32<00:00,  2.47it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.93it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0422: 100%|██████████| 81/81 [00:33<00:00,  2.45it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.43it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0416: 100%|██████████| 81/81 [00:32<00:00,  2.47it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.82it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0412: 100%|██████████| 81/81 [00:32<00:00,  2.50it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 13.06it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 4/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0408: 100%|██████████| 81/81 [00:32<00:00,  2.46it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 5/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0397: 100%|██████████| 81/81 [00:32<00:00,  2.47it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0401: 100%|██████████| 81/81 [00:32<00:00,  2.51it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0391: 100%|██████████| 81/81 [00:32<00:00,  2.51it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0387: 100%|██████████| 81/81 [00:33<00:00,  2.45it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 11.43it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0384: 100%|██████████| 81/81 [00:33<00:00,  2.44it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.68it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0381: 100%|██████████| 81/81 [00:32<00:00,  2.47it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0382: 100%|██████████| 81/81 [00:32<00:00,  2.49it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0377: 100%|██████████| 81/81 [00:32<00:00,  2.46it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 10.65it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0379: 100%|██████████| 81/81 [00:32<00:00,  2.45it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0378: 100%|██████████| 81/81 [00:32<00:00,  2.47it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0377: 100%|██████████| 81/81 [00:32<00:00,  2.50it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n",
      "['./rfcx_kaggle_git/RFCX_kaggle/experiments/finet_new_norm_preproc_w_augs_feat=melspec_mr_SR=32_model=densenet201_Pretr=T_SED=F_act_func=ReLU_crit=FOCAL_Balanced=T:T_Remove=F:F_l=10:5_r=0:0_s=10:5_i=0:0.1_n_classes=24_optim=Adam_wd_sched=cosine_lr=1e-3_SpecAug=T_MixUp=T_a=4_basic_Gain=T_nmels=224/densenet201_score=0.17324', './rfcx_kaggle_git/RFCX_kaggle/experiments/finet_new_norm_preproc_w_augs_feat=melspec_mr_SR=32_model=densenet201_Pretr=T_SED=F_act_func=ReLU_crit=FOCAL_Balanced=T:T_Remove=F:F_l=10:5_r=0:0_s=10:5_i=0:0.1_n_classes=24_optim=Adam_wd_sched=cosine_lr=1e-3_SpecAug=T_MixUp=T_a=4_basic_Gain=T_nmels=224/densenet201_score=0.24187', './rfcx_kaggle_git/RFCX_kaggle/experiments/finet_new_norm_preproc_w_augs_feat=melspec_mr_SR=32_model=densenet201_Pretr=T_SED=F_act_func=ReLU_crit=FOCAL_Balanced=T:T_Remove=F:F_l=10:5_r=0:0_s=10:5_i=0:0.1_n_classes=24_optim=Adam_wd_sched=cosine_lr=1e-3_SpecAug=T_MixUp=T_a=4_basic_Gain=T_nmels=224/densenet201_score=0.25710', './rfcx_kaggle_git/RFCX_kaggle/experiments/finet_new_norm_preproc_w_augs_feat=melspec_mr_SR=32_model=densenet201_Pretr=T_SED=F_act_func=ReLU_crit=FOCAL_Balanced=T:T_Remove=F:F_l=10:5_r=0:0_s=10:5_i=0:0.1_n_classes=24_optim=Adam_wd_sched=cosine_lr=1e-3_SpecAug=T_MixUp=T_a=4_basic_Gain=T_nmels=224/densenet201_score=0.26148', './rfcx_kaggle_git/RFCX_kaggle/experiments/finet_new_norm_preproc_w_augs_feat=melspec_mr_SR=32_model=densenet201_Pretr=T_SED=F_act_func=ReLU_crit=FOCAL_Balanced=T:T_Remove=F:F_l=10:5_r=0:0_s=10:5_i=0:0.1_n_classes=24_optim=Adam_wd_sched=cosine_lr=1e-3_SpecAug=T_MixUp=T_a=4_basic_Gain=T_nmels=224/densenet201_score=0.27873', './rfcx_kaggle_git/RFCX_kaggle/experiments/finet_new_norm_preproc_w_augs_feat=melspec_mr_SR=32_model=densenet201_Pretr=T_SED=F_act_func=ReLU_crit=FOCAL_Balanced=T:T_Remove=F:F_l=10:5_r=0:0_s=10:5_i=0:0.1_n_classes=24_optim=Adam_wd_sched=cosine_lr=1e-3_SpecAug=T_MixUp=T_a=4_basic_Gain=T_nmels=224/densenet201_score=0.29558', './rfcx_kaggle_git/RFCX_kaggle/experiments/finet_new_norm_preproc_w_augs_feat=melspec_mr_SR=32_model=densenet201_Pretr=T_SED=F_act_func=ReLU_crit=FOCAL_Balanced=T:T_Remove=F:F_l=10:5_r=0:0_s=10:5_i=0:0.1_n_classes=24_optim=Adam_wd_sched=cosine_lr=1e-3_SpecAug=T_MixUp=T_a=4_basic_Gain=T_nmels=224/densenet201_score=0.30667', './rfcx_kaggle_git/RFCX_kaggle/experiments/finet_new_norm_preproc_w_augs_feat=melspec_mr_SR=32_model=densenet201_Pretr=T_SED=F_act_func=ReLU_crit=FOCAL_Balanced=T:T_Remove=F:F_l=10:5_r=0:0_s=10:5_i=0:0.1_n_classes=24_optim=Adam_wd_sched=cosine_lr=1e-3_SpecAug=T_MixUp=T_a=4_basic_Gain=T_nmels=224/densenet201_score=0.31254', './rfcx_kaggle_git/RFCX_kaggle/experiments/finet_new_norm_preproc_w_augs_feat=melspec_mr_SR=32_model=densenet201_Pretr=T_SED=F_act_func=ReLU_crit=FOCAL_Balanced=T:T_Remove=F:F_l=10:5_r=0:0_s=10:5_i=0:0.1_n_classes=24_optim=Adam_wd_sched=cosine_lr=1e-3_SpecAug=T_MixUp=T_a=4_basic_Gain=T_nmels=224/densenet201_score=0.31751', './rfcx_kaggle_git/RFCX_kaggle/experiments/finet_new_norm_preproc_w_augs_feat=melspec_mr_SR=32_model=densenet201_Pretr=T_SED=F_act_func=ReLU_crit=FOCAL_Balanced=T:T_Remove=F:F_l=10:5_r=0:0_s=10:5_i=0:0.1_n_classes=24_optim=Adam_wd_sched=cosine_lr=1e-3_SpecAug=T_MixUp=T_a=4_basic_Gain=T_nmels=224/densenet201_score=0.32082', './rfcx_kaggle_git/RFCX_kaggle/experiments/finet_new_norm_preproc_w_augs_feat=melspec_mr_SR=32_model=densenet201_Pretr=T_SED=F_act_func=ReLU_crit=FOCAL_Balanced=T:T_Remove=F:F_l=10:5_r=0:0_s=10:5_i=0:0.1_n_classes=24_optim=Adam_wd_sched=cosine_lr=1e-3_SpecAug=T_MixUp=T_a=4_basic_Gain=T_nmels=224/densenet201_score=0.32351']\n",
      "./rfcx_kaggle_git/RFCX_kaggle/experiments/finet_new_norm_preproc_w_augs_feat=melspec_mr_SR=32_model=densenet201_Pretr=T_SED=F_act_func=ReLU_crit=FOCAL_Balanced=T:T_Remove=F:F_l=10:5_r=0:0_s=10:5_i=0:0.1_n_classes=24_optim=Adam_wd_sched=cosine_lr=1e-3_SpecAug=T_MixUp=T_a=4_basic_Gain=T_nmels=224/densenet201_score=0.32351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0527: 100%|██████████| 81/81 [00:33<00:00,  2.45it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0447: 100%|██████████| 81/81 [00:33<00:00,  2.45it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0439: 100%|██████████| 81/81 [00:33<00:00,  2.43it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.65it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0452: 100%|██████████| 81/81 [00:33<00:00,  2.44it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0434: 100%|██████████| 81/81 [00:33<00:00,  2.43it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0417: 100%|██████████| 81/81 [00:33<00:00,  2.41it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0417: 100%|██████████| 81/81 [00:33<00:00,  2.44it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0404: 100%|██████████| 81/81 [00:33<00:00,  2.43it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0408: 100%|██████████| 81/81 [00:33<00:00,  2.42it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0397: 100%|██████████| 81/81 [00:33<00:00,  2.44it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.92it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0405: 100%|██████████| 81/81 [00:33<00:00,  2.43it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.46it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0394: 100%|██████████| 81/81 [00:33<00:00,  2.44it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.99it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0397: 100%|██████████| 81/81 [00:33<00:00,  2.43it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.24it/s]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 4/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0390: 100%|██████████| 81/81 [00:32<00:00,  2.46it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 5/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0386: 100%|██████████| 81/81 [00:32<00:00,  2.46it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0383: 100%|██████████| 81/81 [00:32<00:00,  2.45it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0381: 100%|██████████| 81/81 [00:33<00:00,  2.43it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0378: 100%|██████████| 81/81 [00:32<00:00,  2.49it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0378: 100%|██████████| 81/81 [00:32<00:00,  2.47it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test without augmentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING COUNTER: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0374:  37%|███▋      | 30/81 [00:12<00:20,  2.51it/s]"
     ]
    }
   ],
   "source": [
    "from datasets import LenSampler, wav_collate\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(config[\"general\"][\"out_path\"])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(config[\"general\"][\"out_path\"])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "samples2preds_all = {}\n",
    "samples2trues_all = {}\n",
    "\n",
    "for i in range(config[\"training\"][\"n_folds\"]):\n",
    "    if config[\"preprocessing\"][\"features_type\"] == \"logmel\":\n",
    "        spectrogram_extractor = Spectrogram(**config[\"preprocessing\"][\"spectrogram\"])\n",
    "        logmel_extractor = LogmelFilterBank(sr=config[\"preprocessing\"][\"sr\"],\n",
    "                                            **config[\"preprocessing\"][\"logmel\"])\n",
    "    elif config[\"preprocessing\"][\"features_type\"] == \"melspec\":\n",
    "        melspec_extractor = MelSpecComputer(config=config)\n",
    "    elif config[\"preprocessing\"][\"features_type\"] == \"mfcc\":\n",
    "        mfcc_extractor = MFCCComputer(config=config)\n",
    "    elif config[\"preprocessing\"][\"features_type\"] == \"3D\":\n",
    "        melspec_extractor = MelSpecComputer3D(config=config)\n",
    "        \n",
    "    \n",
    "\n",
    "    # MixUp\n",
    "    if \"MixUp\" in config[\"training\"][\"augmentations\"]:\n",
    "        mixup = MixUp(**config[\"training\"][\"augmentations\"][\"MixUp\"])\n",
    "    else:\n",
    "        mixup = None\n",
    "\n",
    "    # Spec augmenter\n",
    "    if \"SpecAug\" in config[\"training\"][\"augmentations\"]:\n",
    "        spec_augmenter = SpecAugmentation(**config[\"training\"][\"augmentations\"][\"SpecAug\"])\n",
    "    else:\n",
    "        spec_augmenter = None\n",
    "\n",
    "\n",
    "    if config[\"preprocessing\"][\"use_cmvn\"]:\n",
    "        cmvn = CMVN(2)\n",
    "    else:\n",
    "        cmvn = None\n",
    "    \n",
    "    \n",
    "    model_name = config[\"general\"][\"model_name\"]\n",
    "    model = None\n",
    "    model = ENCODER_PARAMS[model_name][\"init_op\"]()\n",
    "    if config[\"preprocessing\"][\"features_type\"] == \"logmelfilter\":\n",
    "        feat_module = [spectrogram_extractor]\n",
    "        if cmvn is not None:\n",
    "            feat_module.append(cmvn)\n",
    "        feat_module.append(logmel_extractor)\n",
    "    elif config[\"preprocessing\"][\"features_type\"] == \"melspec\":\n",
    "        feat_module = [melspec_extractor]\n",
    "        if cmvn is not None:\n",
    "            feat_module.append(cmvn)\n",
    "    elif config[\"preprocessing\"][\"features_type\"] == \"mfcc\":\n",
    "        feat_module = [mfcc_extractor]\n",
    "        if cmvn is not None:\n",
    "            feat_module.append(cmvn)\n",
    "    elif config[\"preprocessing\"][\"features_type\"] == \"3D\":\n",
    "        feat_module = [melspec_extractor]\n",
    "        if cmvn is not None:\n",
    "            feat_module.append(cmvn)\n",
    "    \n",
    "    model = Wrapper(model, nn.Sequential(*feat_module), classes_num=config[\"general\"][\"classes_num\"],\n",
    "                    model_name=model_name,\n",
    "                spec_augmenter=spec_augmenter, \n",
    "                mixup_module=mixup,\n",
    "                SED=config[\"general\"][\"SED\"],\n",
    "                activation_func=config[\"training\"][\"activation_func\"],\n",
    "                criterion_aam=criterion_aam)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    if model_names is not None:\n",
    "        if config[\"general\"][\"SED\"]:\n",
    "#             try:\n",
    "            model_new = ENCODER_PARAMS[model_name][\"init_op\"]()\n",
    "            model_new = Wrapper(model_new, nn.Sequential(*feat_module), classes_num=config[\"general\"][\"classes_num\"],\n",
    "                    model_name=model_name,\n",
    "                spec_augmenter=spec_augmenter, \n",
    "                mixup_module=mixup,\n",
    "                SED=False,\n",
    "                activation_func=config[\"training\"][\"activation_func\"],\n",
    "                criterion_aam=criterion_aam)\n",
    "            model_new.load_state_dict(torch.load(os.path.join(config[\"training\"][\"models_dir\"],\n",
    "                                                          model_names[i]))['model_state_dict'])\n",
    "            model.model = deepcopy(model_new.model)\n",
    "            model_new.cpu()\n",
    "            del model_new\n",
    "#             except:\n",
    "#                 model.load_state_dict(torch.load(os.path.join(config[\"training\"][\"models_dir\"],\n",
    "#                                                           model_names[i]))['model_state_dict'])\n",
    "        else:\n",
    "            model.load_state_dict(torch.load(os.path.join(config[\"training\"][\"models_dir\"],\n",
    "                                                          model_names[i]))['model_state_dict'])\n",
    "        model.to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config[\"training\"][\"lr\"])\n",
    "#         optimizer = Ranger(model.parameters(),\n",
    "#                            lr=config[\"training\"][\"lr\"],\n",
    "#                            betas=(.95, 0.999), k=4)#torch.optim.Adam(model.model.parameters(), lr=config[\"training\"][\"lr\"]) # TODO: add mappings file for losses\n",
    "\n",
    "#         try:\n",
    "#             optimizer.load_state_dict(torch.load(config[\"training\"][\"state_dict\"],\n",
    "#                                                  map_location=torch.device(DEVICE))['optimizer_state_dict'])\n",
    "#         except:\n",
    "#             print(\"ERROR in optimizer loading\")\n",
    "#             pass\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config[\"training\"][\"lr\"])\n",
    "#         optimizer = Ranger(model.parameters(),\n",
    "#                lr=config[\"training\"][\"lr\"],\n",
    "#                betas=(.90, 0.999), k=4)\n",
    "\n",
    "    \n",
    "    train_dataset = LabeledWavDataset(transforms=augmenter_train,\n",
    "                                      fold=i,\n",
    "                                      classes_num=config[\"general\"][\"classes_num\"],\n",
    "                                      sr=config[\"preprocessing\"][\"sr\"],\n",
    "                                      **config[\"training\"][\"dataset\"])\n",
    "\n",
    "    val_dataset = LabeledWavDataset(transforms=augmenter_val,\n",
    "                                    fold=i,\n",
    "                                    classes_num=config[\"general\"][\"classes_num\"],\n",
    "                                    sr=config[\"preprocessing\"][\"sr\"],\n",
    "                                    **config[\"validation\"][\"dataset\"])\n",
    "    train_collate_fn = partial(wav_collate, **{\"random\": True})\n",
    "    val_collate_fn = partial(wav_collate, **{\"random\": False})\n",
    "    if config[\"training\"][\"len_sampling\"]:\n",
    "        sampler_train = LenSampler(train_dataset,\n",
    "                                   shuffle=config[\"training\"][\"dataloader\"][\"shuffle\"],\n",
    "                                   batch_size=config[\"training\"][\"dataloader\"][\"batch_size\"],\n",
    "                                   batches_per_bin=1,\n",
    "                                   min_length=0.5)\n",
    "        config[\"training\"][\"dataloader\"][\"batch_size\"] = 1\n",
    "        config[\"training\"][\"dataloader\"][\"shuffle\"] = False\n",
    "        config[\"training\"][\"dataloader\"][\"drop_last\"] = False\n",
    "        train_dataloader = DataLoader(train_dataset, collate_fn=train_collate_fn,\n",
    "                                      batch_sampler=sampler_train,\n",
    "                                      **config[\"training\"][\"dataloader\"])\n",
    "#         sampler_val = LenSampler(val_dataset,\n",
    "#                                    shuffle=config[\"validation\"][\"dataloader\"][\"shuffle\"],\n",
    "#                                    batch_size=config[\"validation\"][\"dataloader\"][\"batch_size\"],\n",
    "#                                     batches_per_bin=1,\n",
    "#                                     min_length=2)\n",
    "#         config[\"validation\"][\"dataloader\"][\"batch_size\"] = 1\n",
    "#         config[\"validation\"][\"dataloader\"][\"shuffle\"] = False\n",
    "#         config[\"validation\"][\"dataloader\"][\"drop_last\"] = False\n",
    "        \n",
    "#         val_dataloader = DataLoader(val_dataset, batch_sampler=sampler_val,\n",
    "#                                       **config[\"validation\"][\"dataloader\"])\n",
    "        val_dataloader = DataLoader(val_dataset, collate_fn=val_collate_fn,\n",
    "                                    **config[\"validation\"][\"dataloader\"])\n",
    "    else:\n",
    "        train_dataloader = DataLoader(train_dataset, collate_fn=train_collate_fn, \n",
    "                                      **config[\"training\"][\"dataloader\"])\n",
    "        val_dataloader = DataLoader(val_dataset, collate_fn=val_collate_fn,\n",
    "                                    **config[\"validation\"][\"dataloader\"])\n",
    " \n",
    "    \n",
    "#     scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=config[\"training\"][\"lr\"],\n",
    "#                                         total_steps=None, epochs=10, steps_per_epoch=len(train_dataloader),\n",
    "#                                         pct_start=0.4, anneal_strategy='cos', cycle_momentum=True,\n",
    "#                                         base_momentum=0.85, max_momentum=0.95, div_factor=10.0,\n",
    "#                                         final_div_factor=10000.0, last_epoch=-1)\n",
    "#     scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-7,\n",
    "#                                                   max_lr=config[\"training\"][\"lr\"],\n",
    "#                                                   step_size_up= 2 * len(train_dataloader) * 0.3,\n",
    "#                                                   step_size_down= 2 * len(train_dataloader) * 0.7,\n",
    "#                                                   mode='triangular2',\n",
    "#                                                   gamma=1.0, scale_fn=None,\n",
    "#                                                   scale_mode='cycle', cycle_momentum=False,\n",
    "#                                                   base_momentum=0.8, max_momentum=0.9,\n",
    "#                                                   last_epoch=-1)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                       T_max=(config[\"training\"][\"n_epochs\"] - config[\"training\"][\"n_epochs_flat\"])  * len(train_dataloader),\n",
    "                                                       eta_min=1e-8)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.7, patience=5, min_lr=1e-7, verbose=True)\n",
    "    \n",
    "    samples2preds, samples2trues = training(EPOCHS=EPOCHS, model=model,\n",
    "             train_dataloader=train_dataloader, val_dataloader=val_dataloader,\n",
    "             DEVICE=DEVICE, criterion=criterion, optimizer=optimizer,\n",
    "             scheduler=scheduler, config=config, fold=i)\n",
    "    samples2preds_all.update(samples2preds)\n",
    "    samples2trues_all.update(samples2trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from metrics import calculate_per_class_lwlrap\n",
    "\n",
    "# OOF calculation\n",
    "trues = []\n",
    "preds_max = []\n",
    "preds_mean = []\n",
    "for sample in samples2preds_all:\n",
    "    pred = np.vstack(samples2preds_all[sample])\n",
    "    true = np.vstack(samples2trues_all[sample])\n",
    "    if config[\"general\"][\"use_silence_class\"]:\n",
    "        silence_mask = np.argmax(pred, axis=1) == 24  # pred[:, -1] > 0.2\n",
    "        pred[silence_mask, :] = 0\n",
    "    preds_max.append(np.max(pred, axis=0)[:24])  # [:24] to exclude silence class\n",
    "    preds_mean.append(np.mean(pred, axis=0)[:24])\n",
    "    trues.append(np.max(true, axis=0)[:24])\n",
    "\n",
    "trues = np.vstack(trues)\n",
    "\n",
    "preds_max = np.vstack(preds_max)\n",
    "preds_mean = np.vstack(preds_mean)\n",
    "\n",
    "f1_score_max = f1_score(trues, np.round(preds_max), average='samples')\n",
    "prec_max = precision_score(trues, np.round(preds_max), average='samples')\n",
    "rec_max = recall_score(trues, np.round(preds_max), average='samples')\n",
    "lwlrap_scores, weight = calculate_per_class_lwlrap(trues, preds_max)\n",
    "lwlrap_max = (lwlrap_scores * weight).sum()\n",
    "\n",
    "f1_score_mean = f1_score(trues, np.round(preds_mean), average='samples')\n",
    "prec_mean = precision_score(trues, np.round(preds_mean), average='samples')\n",
    "rec_mean = recall_score(trues, np.round(preds_mean), average='samples')\n",
    "lwlrap_scores, weight = calculate_per_class_lwlrap(trues, preds_mean)\n",
    "lwlrap_mean = (lwlrap_scores * weight).sum()\n",
    "\n",
    "print(f\"OOF LWLRAP MAX: {lwlrap_max}\")\n",
    "print(f\"OOF LWLRAP MEAN: {lwlrap_mean}\")\n",
    "with open(f\"{config['general']['out_path']}OOF_LWLRAP_MAX_fold{fold}_{lwlrap_max:.5f}\", \"w+\") as file:\n",
    "    pass\n",
    "with open(f\"{config['general']['out_path']}OOF_LWLRAP_MEAN_fold{fold}_{lwlrap_mean:.5f}\", \"w+\") as file:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config[\"general\"][\"out_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_utils import evaluate\n",
    "_ = evaluate(model=model, dataloader=val_dataloader,\n",
    "              DEVICE=DEVICE, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_[0]['lwlrap_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_params = optimizer.state_dict()\n",
    "model_params = model.model.state_dict()\n",
    "all_params = {'model_state_dict': model_params, 'optimizer_state_dict': optim_params}\n",
    "torch.save(all_params, f\"{config['general']['out_path']}{config['general']['model_name']}_score=CHECK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
