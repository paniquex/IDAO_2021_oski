{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/media/paniquex/samsung_2tb/rfcx_kaggle_git/RFCX_kaggle/src\")\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "import audiomentations\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from datasets import LabeledWavDataset, StepWavDataset\n",
    "from preprocessing import CMVN, MelSpecComputer, MFCCComputer, MelSpecComputer3D\n",
    "from models import Wrapper\n",
    "from pipeline_utils import evaluate_test\n",
    "from models import ENCODER_PARAMS\n",
    "\n",
    "\n",
    "os.chdir(\"/media/paniquex/samsung_2tb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:3: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_CFG = \"/media/paniquex/samsung_2tb/rfcx_kaggle_git/RFCX_kaggle/experiments/new_norm_preproc_w_augs_feat=3D_mr_SR=32_model=eff_b0_Pretr=T_SED=T_act_func=ReLU_crit=Impr_Balanced=T:T_Remove=F:F_l=15:5_r=0:0_s=15:4_i=0:0.1_n_classes=24_optim=Adam_wd_sched=cosine_lr=1e-3_SpecAug=F_MixUp=T_a=4_basic_Gain=T_nmels=224/config.yaml\"\n",
    "with open(PATH_TO_CFG, \"r\") as file:\n",
    "    config = yaml.load(file)\n",
    "\n",
    "DATA_ROOT = config[\"general\"][\"data_root\"]\n",
    "\n",
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "fix_seed(config[\"general\"][\"seed\"])\n",
    "device_ids = [str(id) for id in config[\"general\"][\"device_ids\"]]\n",
    "ids = \",\".join(device_ids)\n",
    "DEVICE = torch.device(f\"cuda:{ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [name for name in os.listdir(config['general']['out_path']) if name.find(\"best_model_fold\") != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = StepWavDataset(**config[\"testing\"][\"dataset\"])\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, **config[\"testing\"][\"dataloader\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_extractor = Spectrogram(**config[\"preprocessing\"][\"spectrogram\"])\n",
    "logmel_extractor = LogmelFilterBank(sr=config[\"preprocessing\"][\"sr\"],\n",
    "                                    **config[\"preprocessing\"][\"logmel\"])\n",
    "\n",
    "if config[\"preprocessing\"][\"features_type\"] == \"logmel\":\n",
    "    spectrogram_extractor = Spectrogram(**config[\"preprocessing\"][\"spectrogram\"])\n",
    "    logmel_extractor = LogmelFilterBank(sr=config[\"preprocessing\"][\"sr\"],\n",
    "                                        **config[\"preprocessing\"][\"logmel\"])\n",
    "elif config[\"preprocessing\"][\"features_type\"] == \"melspec\":\n",
    "    melspec_extractor = MelSpecComputer(config=config)\n",
    "elif config[\"preprocessing\"][\"features_type\"] == \"mfcc\":\n",
    "    mfcc_extractor = MFCCComputer(config=config)\n",
    "elif config[\"preprocessing\"][\"features_type\"] == \"3D\":\n",
    "    melspec_extractor = MelSpecComputer3D(config=config)\n",
    "\n",
    "# Spec augmenter\n",
    "if \"SpecAug\" in config[\"testing\"][\"augmentations\"]:\n",
    "    spec_augmenter = SpecAugmentation(**config[\"training\"][\"augmentations\"][\"SpecAug\"])\n",
    "else:\n",
    "    spec_augmenter = None\n",
    "\n",
    "if config[\"preprocessing\"][\"use_cmvn\"]:\n",
    "    cmvn = CMVN(2)\n",
    "else:\n",
    "    cmvn = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class AngularPenaltySMLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, loss_type=\"cosface\", eps=1e-7, s=None, m=None):\n",
    "        '''\n",
    "        Angular Penalty Softmax Loss\n",
    "        Three 'loss_types' available: ['arcface', 'sphereface', 'cosface']\n",
    "        These losses are described in the following papers: \n",
    "        \n",
    "        ArcFace: https://arxiv.org/abs/1801.07698\n",
    "        SphereFace: https://arxiv.org/abs/1704.08063\n",
    "        CosFace/Ad Margin: https://arxiv.org/abs/1801.05599\n",
    "        '''\n",
    "        super(AngularPenaltySMLoss, self).__init__()\n",
    "        loss_type = loss_type.lower()\n",
    "        assert loss_type in  ['arcface', 'sphereface', 'cosface']\n",
    "        if loss_type == 'arcface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 0.5 if not m else m\n",
    "        if loss_type == 'sphereface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 1.35 if not m else m\n",
    "        if loss_type == 'cosface':\n",
    "            self.s = 30.0 if not s else s\n",
    "            self.m = 0.4 if not m else m\n",
    "        self.loss_type = loss_type\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        '''\n",
    "        input shape (N, in_features)\n",
    "        '''\n",
    "        assert len(x) == len(labels)\n",
    "        assert torch.min(labels) >= 0\n",
    "        assert torch.max(labels) < self.out_features\n",
    "        \n",
    "        for W in self.fc.parameters():\n",
    "            W = F.normalize(W, p=2, dim=1)\n",
    "\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "#         print(x.shape)\n",
    "        wf = self.fc(x)\n",
    "        if self.loss_type == 'cosface':\n",
    "            numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n",
    "        if self.loss_type == 'arcface':\n",
    "            numerator = self.s * torch.cos(torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)) + self.m)\n",
    "        if self.loss_type == 'sphereface':\n",
    "            numerator = self.s * torch.cos(self.m * torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)))\n",
    "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
    "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
    "        L = numerator - torch.log(denominator)\n",
    "        return -torch.mean(L), wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config[\"general\"][\"model_name\"]\n",
    "model = ENCODER_PARAMS[model_name][\"init_op\"]()\n",
    "if config[\"preprocessing\"][\"features_type\"] == \"logmelfilter\":\n",
    "    feat_module = [spectrogram_extractor]\n",
    "    if cmvn is not None:\n",
    "        feat_module.append(cmvn)\n",
    "    feat_module.append(logmel_extractor)\n",
    "elif config[\"preprocessing\"][\"features_type\"] == \"melspec\":\n",
    "    feat_module = [melspec_extractor]\n",
    "    if cmvn is not None:\n",
    "        feat_module.append(cmvn)\n",
    "elif config[\"preprocessing\"][\"features_type\"] == \"mfcc\":\n",
    "    feat_module = [mfcc_extractor]\n",
    "    if cmvn is not None:\n",
    "        feat_module.append(cmvn)\n",
    "elif config[\"preprocessing\"][\"features_type\"] == \"3D\":\n",
    "    feat_module = [melspec_extractor]\n",
    "    if cmvn is not None:\n",
    "        feat_module.append(cmvn)\n",
    "        \n",
    "if config[\"training\"][\"loss\"] == \"AAM\":\n",
    "    criterion_aam = AngularPenaltySMLoss\n",
    "else:\n",
    "    criterion_aam = None\n",
    "model = Wrapper(model, nn.Sequential(*feat_module), classes_num=config[\"general\"][\"classes_num\"],\n",
    "                    model_name=model_name,\n",
    "                spec_augmenter=None,\n",
    "                SED=config[\"general\"][\"SED\"],\n",
    "                activation_func=config[\"training\"][\"activation_func\"],\n",
    "                criterion_aam=criterion_aam)\n",
    "# if config[\"testing\"][\"state_dict\"] is not None:\n",
    "#     model.load_state_dict(torch.load(config[\"testing\"][\"state_dict\"],\n",
    "#                                      map_location=torch.device(DEVICE))['model_state_dict'])\n",
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4233/4233 [08:59<00:00,  7.84it/s]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(config[\"general\"][\"out_path\"])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "sample2preds = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    for model_name in model_names:\n",
    "        model.load_state_dict(torch.load(os.path.join(config[\"general\"][\"out_path\"], model_name),\n",
    "                                    map_location=torch.device(DEVICE))['model_state_dict'])\n",
    "        if sample2preds is None:\n",
    "            sample2preds = evaluate_test(model=model, dataloader=test_dataloader,\n",
    "                          DEVICE=DEVICE, config=config)\n",
    "        else:\n",
    "            sample2preds_new = evaluate_test(model=model, dataloader=test_dataloader,\n",
    "                          DEVICE=DEVICE, config=config)\n",
    "            for sample in sample2preds:\n",
    "                sample2preds[sample] += sample2preds_new[sample]\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_csv = pd.read_csv(os.path.join(config[\"general\"][\"data_root\"], 'sample_submission.csv'), index_col=0)\n",
    "for sample in sample2preds:\n",
    "    preds = np.vstack(sample2preds[sample])\n",
    "    if config[\"general\"][\"use_silence_class\"]:\n",
    "        silence_mask = np.argmax(pred, axis=1) == 24 #preds[:, -1] > 0.2\n",
    "        preds[silence_mask, :] = 0\n",
    "    preds_csv.loc[sample] = np.max(preds, axis=0)[:24] # [:24] to exclude silence class\n",
    "preds_csv.to_csv(os.path.join(config[\"general\"][\"out_path\"], 'submission_ensemble_max.csv'), index='recording_id')\n",
    "\n",
    "\n",
    "for sample in sample2preds:\n",
    "    preds = np.vstack(sample2preds[sample])\n",
    "    if config[\"general\"][\"use_silence_class\"]:\n",
    "        silence_mask = np.argmax(preds, axis=1) == 24\n",
    "        pred[silence_mask, :] = 0\n",
    "    preds_csv.loc[sample] = np.mean(preds, axis=0)[:24] # [:24] to exclude silence class\n",
    "\n",
    "preds_csv.to_csv(os.path.join(config[\"general\"][\"out_path\"], 'submission_ensemble_mean.csv'), index='recording_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'best_model_fold0_score=0.88102.pth'    val_pred_preds_max_41.npy\r\n",
      "'best_model_fold1_score=0.89363.pth'    val_pred_preds_max_42.npy\r\n",
      "'best_model_fold2_score=0.88093.pth'    val_pred_preds_max_43.npy\r\n",
      "'best_model_fold3_score=0.87272.pth'    val_pred_preds_max_44.npy\r\n",
      "'best_model_fold4_score=0.90775.pth'    val_pred_preds_max_45.npy\r\n",
      " config.yaml\t\t\t        val_pred_preds_max_46.npy\r\n",
      " OOF_LWLRAP_MAX_fold4_0.87328\t        val_pred_preds_max_47.npy\r\n",
      " OOF_LWLRAP_MEAN_fold4_0.87305\t        val_pred_preds_max_48.npy\r\n",
      " submission_ensemble_max.csv\t        val_pred_preds_max_49.npy\r\n",
      " submission_ensemble_mean.csv\t        val_pred_preds_max_4.npy\r\n",
      " submission_max.csv\t\t        val_pred_preds_max_50.npy\r\n",
      " submission_mean.csv\t\t        val_pred_preds_max_51.npy\r\n",
      "'tf_efficientnet_b0_ns_score=0.87234'   val_pred_preds_max_52.npy\r\n",
      "'tf_efficientnet_b0_ns_score=0.87462'   val_pred_preds_max_53.npy\r\n",
      "'tf_efficientnet_b0_ns_score=0.87777'   val_pred_preds_max_54.npy\r\n",
      "'tf_efficientnet_b0_ns_score=0.88879'   val_pred_preds_max_55.npy\r\n",
      "'tf_efficientnet_b0_ns_score=0.90434'   val_pred_preds_max_56.npy\r\n",
      " tf_efficientnet_b0_ns_train.csv        val_pred_preds_max_57.npy\r\n",
      " tf_efficientnet_b0_ns_val_0.csv        val_pred_preds_max_58.npy\r\n",
      " tf_efficientnet_b0_ns_val_1.csv        val_pred_preds_max_59.npy\r\n",
      " tf_efficientnet_b0_ns_val_2.csv        val_pred_preds_max_5.npy\r\n",
      " tf_efficientnet_b0_ns_val_3.csv        val_pred_preds_max_60.npy\r\n",
      " tf_efficientnet_b0_ns_val_4.csv        val_pred_preds_max_61.npy\r\n",
      " train_pred_preds_0.npy\t\t        val_pred_preds_max_62.npy\r\n",
      " train_pred_preds_10.npy\t        val_pred_preds_max_63.npy\r\n",
      " train_pred_preds_11.npy\t        val_pred_preds_max_64.npy\r\n",
      " train_pred_preds_12.npy\t        val_pred_preds_max_65.npy\r\n",
      " train_pred_preds_13.npy\t        val_pred_preds_max_66.npy\r\n",
      " train_pred_preds_14.npy\t        val_pred_preds_max_67.npy\r\n",
      " train_pred_preds_15.npy\t        val_pred_preds_max_68.npy\r\n",
      " train_pred_preds_16.npy\t        val_pred_preds_max_69.npy\r\n",
      " train_pred_preds_17.npy\t        val_pred_preds_max_6.npy\r\n",
      " train_pred_preds_18.npy\t        val_pred_preds_max_70.npy\r\n",
      " train_pred_preds_19.npy\t        val_pred_preds_max_71.npy\r\n",
      " train_pred_preds_1.npy\t\t        val_pred_preds_max_72.npy\r\n",
      " train_pred_preds_20.npy\t        val_pred_preds_max_73.npy\r\n",
      " train_pred_preds_21.npy\t        val_pred_preds_max_74.npy\r\n",
      " train_pred_preds_22.npy\t        val_pred_preds_max_75.npy\r\n",
      " train_pred_preds_23.npy\t        val_pred_preds_max_76.npy\r\n",
      " train_pred_preds_24.npy\t        val_pred_preds_max_77.npy\r\n",
      " train_pred_preds_25.npy\t        val_pred_preds_max_78.npy\r\n",
      " train_pred_preds_26.npy\t        val_pred_preds_max_79.npy\r\n",
      " train_pred_preds_27.npy\t        val_pred_preds_max_7.npy\r\n",
      " train_pred_preds_28.npy\t        val_pred_preds_max_80.npy\r\n",
      " train_pred_preds_29.npy\t        val_pred_preds_max_81.npy\r\n",
      " train_pred_preds_2.npy\t\t        val_pred_preds_max_82.npy\r\n",
      " train_pred_preds_30.npy\t        val_pred_preds_max_83.npy\r\n",
      " train_pred_preds_31.npy\t        val_pred_preds_max_84.npy\r\n",
      " train_pred_preds_32.npy\t        val_pred_preds_max_85.npy\r\n",
      " train_pred_preds_33.npy\t        val_pred_preds_max_86.npy\r\n",
      " train_pred_preds_34.npy\t        val_pred_preds_max_87.npy\r\n",
      " train_pred_preds_35.npy\t        val_pred_preds_max_88.npy\r\n",
      " train_pred_preds_36.npy\t        val_pred_preds_max_89.npy\r\n",
      " train_pred_preds_37.npy\t        val_pred_preds_max_8.npy\r\n",
      " train_pred_preds_38.npy\t        val_pred_preds_max_90.npy\r\n",
      " train_pred_preds_39.npy\t        val_pred_preds_max_91.npy\r\n",
      " train_pred_preds_3.npy\t\t        val_pred_preds_max_9.npy\r\n",
      " train_pred_preds_40.npy\t        val_pred_preds_mean_0.npy\r\n",
      " train_pred_preds_41.npy\t        val_pred_preds_mean_10.npy\r\n",
      " train_pred_preds_42.npy\t        val_pred_preds_mean_11.npy\r\n",
      " train_pred_preds_43.npy\t        val_pred_preds_mean_12.npy\r\n",
      " train_pred_preds_44.npy\t        val_pred_preds_mean_13.npy\r\n",
      " train_pred_preds_45.npy\t        val_pred_preds_mean_14.npy\r\n",
      " train_pred_preds_46.npy\t        val_pred_preds_mean_15.npy\r\n",
      " train_pred_preds_47.npy\t        val_pred_preds_mean_16.npy\r\n",
      " train_pred_preds_48.npy\t        val_pred_preds_mean_17.npy\r\n",
      " train_pred_preds_49.npy\t        val_pred_preds_mean_18.npy\r\n",
      " train_pred_preds_4.npy\t\t        val_pred_preds_mean_19.npy\r\n",
      " train_pred_preds_50.npy\t        val_pred_preds_mean_1.npy\r\n",
      " train_pred_preds_51.npy\t        val_pred_preds_mean_20.npy\r\n",
      " train_pred_preds_52.npy\t        val_pred_preds_mean_21.npy\r\n",
      " train_pred_preds_53.npy\t        val_pred_preds_mean_22.npy\r\n",
      " train_pred_preds_54.npy\t        val_pred_preds_mean_23.npy\r\n",
      " train_pred_preds_55.npy\t        val_pred_preds_mean_24.npy\r\n",
      " train_pred_preds_56.npy\t        val_pred_preds_mean_25.npy\r\n",
      " train_pred_preds_57.npy\t        val_pred_preds_mean_26.npy\r\n",
      " train_pred_preds_58.npy\t        val_pred_preds_mean_27.npy\r\n",
      " train_pred_preds_59.npy\t        val_pred_preds_mean_28.npy\r\n",
      " train_pred_preds_5.npy\t\t        val_pred_preds_mean_29.npy\r\n",
      " train_pred_preds_60.npy\t        val_pred_preds_mean_2.npy\r\n",
      " train_pred_preds_61.npy\t        val_pred_preds_mean_30.npy\r\n",
      " train_pred_preds_62.npy\t        val_pred_preds_mean_31.npy\r\n",
      " train_pred_preds_63.npy\t        val_pred_preds_mean_32.npy\r\n",
      " train_pred_preds_64.npy\t        val_pred_preds_mean_33.npy\r\n",
      " train_pred_preds_65.npy\t        val_pred_preds_mean_34.npy\r\n",
      " train_pred_preds_66.npy\t        val_pred_preds_mean_35.npy\r\n",
      " train_pred_preds_67.npy\t        val_pred_preds_mean_36.npy\r\n",
      " train_pred_preds_68.npy\t        val_pred_preds_mean_37.npy\r\n",
      " train_pred_preds_69.npy\t        val_pred_preds_mean_38.npy\r\n",
      " train_pred_preds_6.npy\t\t        val_pred_preds_mean_39.npy\r\n",
      " train_pred_preds_70.npy\t        val_pred_preds_mean_3.npy\r\n",
      " train_pred_preds_71.npy\t        val_pred_preds_mean_40.npy\r\n",
      " train_pred_preds_72.npy\t        val_pred_preds_mean_41.npy\r\n",
      " train_pred_preds_73.npy\t        val_pred_preds_mean_42.npy\r\n",
      " train_pred_preds_74.npy\t        val_pred_preds_mean_43.npy\r\n",
      " train_pred_preds_75.npy\t        val_pred_preds_mean_44.npy\r\n",
      " train_pred_preds_76.npy\t        val_pred_preds_mean_45.npy\r\n",
      " train_pred_preds_77.npy\t        val_pred_preds_mean_46.npy\r\n",
      " train_pred_preds_78.npy\t        val_pred_preds_mean_47.npy\r\n",
      " train_pred_preds_79.npy\t        val_pred_preds_mean_48.npy\r\n",
      " train_pred_preds_7.npy\t\t        val_pred_preds_mean_49.npy\r\n",
      " train_pred_preds_80.npy\t        val_pred_preds_mean_4.npy\r\n",
      " train_pred_preds_81.npy\t        val_pred_preds_mean_50.npy\r\n",
      " train_pred_preds_82.npy\t        val_pred_preds_mean_51.npy\r\n",
      " train_pred_preds_83.npy\t        val_pred_preds_mean_52.npy\r\n",
      " train_pred_preds_84.npy\t        val_pred_preds_mean_53.npy\r\n",
      " train_pred_preds_85.npy\t        val_pred_preds_mean_54.npy\r\n",
      " train_pred_preds_86.npy\t        val_pred_preds_mean_55.npy\r\n",
      " train_pred_preds_87.npy\t        val_pred_preds_mean_56.npy\r\n",
      " train_pred_preds_88.npy\t        val_pred_preds_mean_57.npy\r\n",
      " train_pred_preds_89.npy\t        val_pred_preds_mean_58.npy\r\n",
      " train_pred_preds_8.npy\t\t        val_pred_preds_mean_59.npy\r\n",
      " train_pred_preds_90.npy\t        val_pred_preds_mean_5.npy\r\n",
      " train_pred_preds_91.npy\t        val_pred_preds_mean_60.npy\r\n",
      " train_pred_preds_9.npy\t\t        val_pred_preds_mean_61.npy\r\n",
      " train_true_0.npy\t\t        val_pred_preds_mean_62.npy\r\n",
      " train_true_10.npy\t\t        val_pred_preds_mean_63.npy\r\n",
      " train_true_11.npy\t\t        val_pred_preds_mean_64.npy\r\n",
      " train_true_12.npy\t\t        val_pred_preds_mean_65.npy\r\n",
      " train_true_13.npy\t\t        val_pred_preds_mean_66.npy\r\n",
      " train_true_14.npy\t\t        val_pred_preds_mean_67.npy\r\n",
      " train_true_15.npy\t\t        val_pred_preds_mean_68.npy\r\n",
      " train_true_16.npy\t\t        val_pred_preds_mean_69.npy\r\n",
      " train_true_17.npy\t\t        val_pred_preds_mean_6.npy\r\n",
      " train_true_18.npy\t\t        val_pred_preds_mean_70.npy\r\n",
      " train_true_19.npy\t\t        val_pred_preds_mean_71.npy\r\n",
      " train_true_1.npy\t\t        val_pred_preds_mean_72.npy\r\n",
      " train_true_20.npy\t\t        val_pred_preds_mean_73.npy\r\n",
      " train_true_21.npy\t\t        val_pred_preds_mean_74.npy\r\n",
      " train_true_22.npy\t\t        val_pred_preds_mean_75.npy\r\n",
      " train_true_23.npy\t\t        val_pred_preds_mean_76.npy\r\n",
      " train_true_24.npy\t\t        val_pred_preds_mean_77.npy\r\n",
      " train_true_25.npy\t\t        val_pred_preds_mean_78.npy\r\n",
      " train_true_26.npy\t\t        val_pred_preds_mean_79.npy\r\n",
      " train_true_27.npy\t\t        val_pred_preds_mean_7.npy\r\n",
      " train_true_28.npy\t\t        val_pred_preds_mean_80.npy\r\n",
      " train_true_29.npy\t\t        val_pred_preds_mean_81.npy\r\n",
      " train_true_2.npy\t\t        val_pred_preds_mean_82.npy\r\n",
      " train_true_30.npy\t\t        val_pred_preds_mean_83.npy\r\n",
      " train_true_31.npy\t\t        val_pred_preds_mean_84.npy\r\n",
      " train_true_32.npy\t\t        val_pred_preds_mean_85.npy\r\n",
      " train_true_33.npy\t\t        val_pred_preds_mean_86.npy\r\n",
      " train_true_34.npy\t\t        val_pred_preds_mean_87.npy\r\n",
      " train_true_35.npy\t\t        val_pred_preds_mean_88.npy\r\n",
      " train_true_36.npy\t\t        val_pred_preds_mean_89.npy\r\n",
      " train_true_37.npy\t\t        val_pred_preds_mean_8.npy\r\n",
      " train_true_38.npy\t\t        val_pred_preds_mean_90.npy\r\n",
      " train_true_39.npy\t\t        val_pred_preds_mean_91.npy\r\n",
      " train_true_3.npy\t\t        val_pred_preds_mean_9.npy\r\n",
      " train_true_40.npy\t\t        val_true_0.npy\r\n",
      " train_true_41.npy\t\t        val_true_10.npy\r\n",
      " train_true_42.npy\t\t        val_true_11.npy\r\n",
      " train_true_43.npy\t\t        val_true_12.npy\r\n",
      " train_true_44.npy\t\t        val_true_13.npy\r\n",
      " train_true_45.npy\t\t        val_true_14.npy\r\n",
      " train_true_46.npy\t\t        val_true_15.npy\r\n",
      " train_true_47.npy\t\t        val_true_16.npy\r\n",
      " train_true_48.npy\t\t        val_true_17.npy\r\n",
      " train_true_49.npy\t\t        val_true_18.npy\r\n",
      " train_true_4.npy\t\t        val_true_19.npy\r\n",
      " train_true_50.npy\t\t        val_true_1.npy\r\n",
      " train_true_51.npy\t\t        val_true_20.npy\r\n",
      " train_true_52.npy\t\t        val_true_21.npy\r\n",
      " train_true_53.npy\t\t        val_true_22.npy\r\n",
      " train_true_54.npy\t\t        val_true_23.npy\r\n",
      " train_true_55.npy\t\t        val_true_24.npy\r\n",
      " train_true_56.npy\t\t        val_true_25.npy\r\n",
      " train_true_57.npy\t\t        val_true_26.npy\r\n",
      " train_true_58.npy\t\t        val_true_27.npy\r\n",
      " train_true_59.npy\t\t        val_true_28.npy\r\n",
      " train_true_5.npy\t\t        val_true_29.npy\r\n",
      " train_true_60.npy\t\t        val_true_2.npy\r\n",
      " train_true_61.npy\t\t        val_true_30.npy\r\n",
      " train_true_62.npy\t\t        val_true_31.npy\r\n",
      " train_true_63.npy\t\t        val_true_32.npy\r\n",
      " train_true_64.npy\t\t        val_true_33.npy\r\n",
      " train_true_65.npy\t\t        val_true_34.npy\r\n",
      " train_true_66.npy\t\t        val_true_35.npy\r\n",
      " train_true_67.npy\t\t        val_true_36.npy\r\n",
      " train_true_68.npy\t\t        val_true_37.npy\r\n",
      " train_true_69.npy\t\t        val_true_38.npy\r\n",
      " train_true_6.npy\t\t        val_true_39.npy\r\n",
      " train_true_70.npy\t\t        val_true_3.npy\r\n",
      " train_true_71.npy\t\t        val_true_40.npy\r\n",
      " train_true_72.npy\t\t        val_true_41.npy\r\n",
      " train_true_73.npy\t\t        val_true_42.npy\r\n",
      " train_true_74.npy\t\t        val_true_43.npy\r\n",
      " train_true_75.npy\t\t        val_true_44.npy\r\n",
      " train_true_76.npy\t\t        val_true_45.npy\r\n",
      " train_true_77.npy\t\t        val_true_46.npy\r\n",
      " train_true_78.npy\t\t        val_true_47.npy\r\n",
      " train_true_79.npy\t\t        val_true_48.npy\r\n",
      " train_true_7.npy\t\t        val_true_49.npy\r\n",
      " train_true_80.npy\t\t        val_true_4.npy\r\n",
      " train_true_81.npy\t\t        val_true_50.npy\r\n",
      " train_true_82.npy\t\t        val_true_51.npy\r\n",
      " train_true_83.npy\t\t        val_true_52.npy\r\n",
      " train_true_84.npy\t\t        val_true_53.npy\r\n",
      " train_true_85.npy\t\t        val_true_54.npy\r\n",
      " train_true_86.npy\t\t        val_true_55.npy\r\n",
      " train_true_87.npy\t\t        val_true_56.npy\r\n",
      " train_true_88.npy\t\t        val_true_57.npy\r\n",
      " train_true_89.npy\t\t        val_true_58.npy\r\n",
      " train_true_8.npy\t\t        val_true_59.npy\r\n",
      " train_true_90.npy\t\t        val_true_5.npy\r\n",
      " train_true_91.npy\t\t        val_true_60.npy\r\n",
      " train_true_9.npy\t\t        val_true_61.npy\r\n",
      " val_pred_preds_max_0.npy\t        val_true_62.npy\r\n",
      " val_pred_preds_max_10.npy\t        val_true_63.npy\r\n",
      " val_pred_preds_max_11.npy\t        val_true_64.npy\r\n",
      " val_pred_preds_max_12.npy\t        val_true_65.npy\r\n",
      " val_pred_preds_max_13.npy\t        val_true_66.npy\r\n",
      " val_pred_preds_max_14.npy\t        val_true_67.npy\r\n",
      " val_pred_preds_max_15.npy\t        val_true_68.npy\r\n",
      " val_pred_preds_max_16.npy\t        val_true_69.npy\r\n",
      " val_pred_preds_max_17.npy\t        val_true_6.npy\r\n",
      " val_pred_preds_max_18.npy\t        val_true_70.npy\r\n",
      " val_pred_preds_max_19.npy\t        val_true_71.npy\r\n",
      " val_pred_preds_max_1.npy\t        val_true_72.npy\r\n",
      " val_pred_preds_max_20.npy\t        val_true_73.npy\r\n",
      " val_pred_preds_max_21.npy\t        val_true_74.npy\r\n",
      " val_pred_preds_max_22.npy\t        val_true_75.npy\r\n",
      " val_pred_preds_max_23.npy\t        val_true_76.npy\r\n",
      " val_pred_preds_max_24.npy\t        val_true_77.npy\r\n",
      " val_pred_preds_max_25.npy\t        val_true_78.npy\r\n",
      " val_pred_preds_max_26.npy\t        val_true_79.npy\r\n",
      " val_pred_preds_max_27.npy\t        val_true_7.npy\r\n",
      " val_pred_preds_max_28.npy\t        val_true_80.npy\r\n",
      " val_pred_preds_max_29.npy\t        val_true_81.npy\r\n",
      " val_pred_preds_max_2.npy\t        val_true_82.npy\r\n",
      " val_pred_preds_max_30.npy\t        val_true_83.npy\r\n",
      " val_pred_preds_max_31.npy\t        val_true_84.npy\r\n",
      " val_pred_preds_max_32.npy\t        val_true_85.npy\r\n",
      " val_pred_preds_max_33.npy\t        val_true_86.npy\r\n",
      " val_pred_preds_max_34.npy\t        val_true_87.npy\r\n",
      " val_pred_preds_max_35.npy\t        val_true_88.npy\r\n",
      " val_pred_preds_max_36.npy\t        val_true_89.npy\r\n",
      " val_pred_preds_max_37.npy\t        val_true_8.npy\r\n",
      " val_pred_preds_max_38.npy\t        val_true_90.npy\r\n",
      " val_pred_preds_max_39.npy\t        val_true_91.npy\r\n",
      " val_pred_preds_max_3.npy\t        val_true_9.npy\r\n",
      " val_pred_preds_max_40.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls './rfcx_kaggle_git/RFCX_kaggle/experiments/logs1_features=melspec_mr_SR=32_CMVN=F_mean_model=tf_effnet_b0_Pretrained=T_SED=T_aggr=mean_act_func=Mish_criterion=FOCAL_Balanced=T_length=6_n_classes=24_optim=ranger_sched=cosine_lr=1e-3_SpecAug=F_MixUp=True_alpha=16_Gain=T_n_mels=256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test_32000  train\ttrain_48000\t train_tp.csv\r\n",
      "test\t\t       test_48000  train_22050\ttrain_folds.csv\r\n",
      "test_22050\t       tfrecords   train_32000\ttrain_fp.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /media/paniquex/samsung_2tb/rfcx_kaggle/rfcx-species-audio-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backup\t\t\tOOF_LWLRAP_MAX_0.22912\r\n",
      "cornell_archive.tar\tOOF_LWLRAP_MAX_0.23021\r\n",
      "lost+found\t\tOOF_LWLRAP_MAX_0.23421\r\n",
      "ngrok\t\t\tOOF_LWLRAP_MEAN_0.18588\r\n",
      "OOF_LWLRAP_MAX_0.18437\tOOF_LWLRAP_MEAN_0.20676\r\n",
      "OOF_LWLRAP_MAX_0.18475\tOOF_LWLRAP_MEAN_0.21748\r\n",
      "OOF_LWLRAP_MAX_0.20346\tOOF_LWLRAP_MEAN_0.22392\r\n",
      "OOF_LWLRAP_MAX_0.20997\tOOF_LWLRAP_MEAN_0.22700\r\n",
      "OOF_LWLRAP_MAX_0.21698\trfcx_kaggle\r\n",
      "OOF_LWLRAP_MAX_0.21761\trfcx_kaggle_git\r\n",
      "OOF_LWLRAP_MAX_0.22885\trfcx-species-audio-detection.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 17 23:06:27 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.102.04   Driver Version: 450.102.04   CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:0E:00.0  On |                  N/A |\r\n",
      "| 47%   63C    P2   104W / 260W |  10125MiB / 11018MiB |     31%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:0F:00.0 Off |                  N/A |\r\n",
      "| 22%   46C    P2   101W / 300W |   9455MiB / 11019MiB |     20%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1503      G   /usr/lib/xorg/Xorg                 18MiB |\r\n",
      "|    0   N/A  N/A      1751      G   /usr/bin/gnome-shell               57MiB |\r\n",
      "|    0   N/A  N/A      1946      C   ...a3/envs/kaggle/bin/python     1845MiB |\r\n",
      "|    0   N/A  N/A      2339      G   /usr/lib/xorg/Xorg                333MiB |\r\n",
      "|    0   N/A  N/A      2471      G   /usr/bin/gnome-shell              258MiB |\r\n",
      "|    0   N/A  N/A      3442      G   ...AAAAAAAAA= --shared-files      266MiB |\r\n",
      "|    0   N/A  N/A     21253      G   ...AAAAAAAA== --shared-files       24MiB |\r\n",
      "|    0   N/A  N/A     21448      C   ...a3/envs/kaggle/bin/python     6267MiB |\r\n",
      "|    0   N/A  N/A     25463      G   ..._25129.log --shared-files       23MiB |\r\n",
      "|    0   N/A  N/A     27584      G   ...AAAAAAAAA= --shared-files       44MiB |\r\n",
      "|    0   N/A  N/A     29634      G   ...gAAAAAAAAA --shared-files       22MiB |\r\n",
      "|    0   N/A  N/A     31158      C   ...a3/envs/kaggle/bin/python      955MiB |\r\n",
      "|    1   N/A  N/A      1503      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    1   N/A  N/A      2339      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    1   N/A  N/A     31158      C   ...a3/envs/kaggle/bin/python     9441MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(config[\"general\"][\"data_root\"], 'train_tp.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"time_diff\"] = data[\"t_max\"] - data[\"t_min\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1216.000000\n",
       "mean        2.537119\n",
       "std         1.903589\n",
       "min         0.272000\n",
       "25%         1.093300\n",
       "50%         1.856000\n",
       "75%         3.344000\n",
       "max         7.923900\n",
       "Name: time_diff, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"time_diff\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[data[\"time_diff\"] < 0.6][\"time_diff\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
