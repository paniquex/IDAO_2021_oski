{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "I wanted to share something that worked pretty well for me early on in this competition. The idea comes from a [2018 paper](https://arxiv.org/pdf/1703.01780.pdf) titled *Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results* by Antti Tarvainen and Harri Valpola. \n",
    "\n",
    "### Mean Teacher\n",
    "Biefly, the idea is to use two models. A student model with weights trained the standard way, using backprop. And a teacher model with weights that are an exponential moving average of the student's weights. The teacher is the *mean* of the student \\*ba dum tss\\*. The student is then trained using two different losses, a standard classification loss and a consistency loss that penalizes student predictions that deviate from the teaher's. \n",
    "\n",
    "![](https://raw.githubusercontent.com/CuriousAI/mean-teacher/master/mean_teacher.png)\n",
    "\n",
    "Mean teachers are useful in a semi-supervised context where we have both labeled and unlabeled samples. The consistency loss on the unlabeled samples acts as a form of regularization and helps the model generalize better. As an added bonus the final teacher model is a temporal ensemble which tends to perform better than the results at the end of a single epoch. \n",
    "\n",
    "### Missing Labels\n",
    "As a few others have pointed out, there are a lot of missing labels. If we were to randomly sample a segment from the training data, we might consider it completely unlabeled rather than rely on the provided labels. We'll train our mean teacher model(s) on two classes of data, carefully selected positive samples and randomly selected unlabeled samples. The classification loss won't apply to the unlabeled samples. \n",
    "\n",
    "![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F4704212%2F9ca088bb386abf7114543c019c1d8a5f%2Ffig.png?generation=1609892974092435&alt=media)\n",
    "\n",
    "*Thanks to [shinmura0](https://www.kaggle.com/shinmurashinmura) for the great visualization!*\n",
    "\n",
    "### Results\n",
    "For me, mean teacher worked a good bit better than baseline models with similar configurations. \n",
    "\n",
    "|                                         | Baseline | Mean Teacher |\n",
    "|-----------------------------------------|----------|--------------|\n",
    "| Well Tuned, 5 fold, from my local setup | 0.847        | **0.865**            |\n",
    "| Single fold Expt1 on Kaggle                   | 0.592**        | **0.786**            |\n",
    "| Single fold Expt2 on Kaggle                   | 0.826        | **0.830**            |\n",
    "| 5 Fold on Kaggle***                        | 0.844        | **0.857**           |\n",
    "\n",
    "\\*\\* I might have accidentally sabatoged this run.\n",
    "\n",
    "\\*\\*\\* There was a major bug in v21 of the notebook where the consistence_ramp was set to 1000 which means it was just normal / non-mean-teacher training. Setting consisteny_ramp to 6 and using the mean teacher, we get an improvement of 0.13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "!pip -q install --upgrade pip\n",
    "!pip -q install timm\n",
    "!pip -q install torchlibrosa\n",
    "!pip -q install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "import audiomentations as A\n",
    "import os, time, librosa, random\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from timm.models import resnet34d, resnest26d, resnest50d\n",
    "from timm.models.efficientnet import tf_efficientnet_b4_ns, tf_efficientnet_b3_ns, \\\n",
    "    tf_efficientnet_b5_ns, tf_efficientnet_b2_ns, tf_efficientnet_b6_ns, tf_efficientnet_b7_ns, tf_efficientnet_b0_ns, tf_efficientnet_b1_ns\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "from contextlib import nullcontext\n",
    "\n",
    "\n",
    "from ranger import Ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixUp(nn.Module):\n",
    "    def __init__(self, prob=0.33, alpha=8, mixup_mode=\"basic\"):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.prob = prob\n",
    "        self.mixup_mode = mixup_mode\n",
    "        \n",
    "    def forward(self, waveforms, labels):\n",
    "        inds = np.arange(waveforms.shape[0])\n",
    "        new_inds = inds.copy()\n",
    "        np.random.shuffle(new_inds)\n",
    "        aug_count = int(inds[inds != new_inds].shape[0] * self.prob)\n",
    "        to_augment = np.random.choice(inds[inds != new_inds], aug_count, replace=False)\n",
    "        betas = torch.tensor(np.random.beta(self.alpha, self.alpha, size=aug_count),\n",
    "                             dtype=torch.float).unsqueeze(1).to(waveforms.device)\n",
    "        # new_inds = torch.tensor(new_inds)\n",
    "        # to_augment = torch.tensor(to_augment)\n",
    "        waveforms[to_augment] = betas * waveforms[to_augment] + (1 - betas) * waveforms[new_inds][to_augment]\n",
    "        if self.mixup_mode == \"basic\":\n",
    "            labels[to_augment] = betas * labels[to_augment] + (1 - betas) * labels[new_inds][to_augment]\n",
    "        elif self.mixup_mode == \"or\":\n",
    "            labels[to_augment] = torch.clamp_max(labels[to_augment] + labels[new_inds][to_augment], max=1.)\n",
    "        return waveforms, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config\n",
    "We'll start by setting up some global config variable that we'll access later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Global Vars\n",
    "NO_LABEL = -1\n",
    "NUM_CLASSES = 24\n",
    "\n",
    "LOSS_TYPE = \"BCE\"\n",
    "\n",
    "class config:\n",
    "    seed = 42\n",
    "    device = \"cuda:0\"\n",
    "    \n",
    "    train_tp_csv = '/media/paniquex/samsung_2tb/rfcx_kaggle/rfcx-species-audio-detection/train_tp.csv'\n",
    "    test_csv = '/media/paniquex/samsung_2tb/rfcx_kaggle/rfcx-species-audio-detection/sample_submission.csv'\n",
    "    save_path = '../experiments/mean_teacher_ImprPanns_eff_b0_adamw_period=3_val=3_encoder_percent_unlabeled=1.0_consistency_weight=50_consistency_rampup=6_ema_decay=0.995'\n",
    "    \n",
    "    encoder = tf_efficientnet_b0_ns\n",
    "    encoder_features = 1280\n",
    "    \n",
    "    percent_unlabeled = 1.0\n",
    "    consistency_weight = 100.0\n",
    "    consistency_rampup = 6\n",
    "    \n",
    "    ema_decay = 0.995\n",
    "    positive_weight = 2.0\n",
    "    \n",
    "    lr = 1e-3\n",
    "    epochs = 25\n",
    "    batch_size = 16\n",
    "    num_workers = 8\n",
    "    train_5_folds = True\n",
    "    \n",
    "    period = 3 # 6 second clips\n",
    "    period_val = 2\n",
    "\n",
    "    \n",
    "    step = 1\n",
    "    model_params = {\n",
    "        'sample_rate': 48000,\n",
    "        'window_size': 1024,\n",
    "        'hop_size': 345,\n",
    "        'mel_bins': 128,\n",
    "        'fmin': 20,\n",
    "        'fmax': 48000 // 2,\n",
    "        'classes_num': NUM_CLASSES,\n",
    "        'mixup_module': None\n",
    "    }\n",
    "    \n",
    "    augmenter = A.Compose([\n",
    "        A.AddGaussianNoise(p=0.33, max_amplitude=0.02),\n",
    "        A.AddGaussianSNR(p=0.33),\n",
    "        A.FrequencyMask(min_frequency_band=0.01,  max_frequency_band=0.25, p=0.33),\n",
    "        A.TimeMask(min_band_part=0.01, max_band_part=0.25, p=0.33),\n",
    "        A.Gain(p=0.33)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(config.save_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(config.save_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "## Utils - Not much interesting going on here.\n",
    "\n",
    "def get_n_fold_df(csv_path, folds=5):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df_group = df.groupby(\"recording_id\")[[\"species_id\"]].first().reset_index()\n",
    "    df_group = df_group.sample(frac=1, random_state=config.seed).reset_index(drop=True)\n",
    "    df_group.loc[:, 'fold'] = -1\n",
    "\n",
    "    X = df_group[\"recording_id\"].values\n",
    "    y = df_group[\"species_id\"].values\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=folds, random_state=config.seed)\n",
    "    for fold, (t_idx, v_idx) in enumerate(kfold.split(X, y)):\n",
    "        df_group.loc[v_idx, \"fold\"] = fold\n",
    "\n",
    "    return df.merge(df_group[['recording_id', 'fold']], on=\"recording_id\", how=\"left\")\n",
    "    \n",
    "\n",
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def sigmoid_rampup(current, rampup_length):\n",
    "    \"\"\"Exponential rampup from https://arxiv.org/abs/1610.02242\"\"\"\n",
    "    if rampup_length == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        current = np.clip(current, 0.0, rampup_length)\n",
    "        phase = 1.0 - current / rampup_length\n",
    "        return float(np.exp(-5.0 * phase * phase))\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class MetricMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.y_true = []\n",
    "        self.y_pred = []\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        try:\n",
    "            self.y_true.extend(y_true.detach().cpu().numpy().tolist())\n",
    "            self.y_pred.extend(torch.sigmoid(y_pred).cpu().detach().numpy().tolist())\n",
    "        except:\n",
    "            print(\"UPDATE FAILURE\")\n",
    "\n",
    "    def update_list(self, y_true, y_pred):\n",
    "        self.y_true.extend(y_true)\n",
    "        self.y_pred.extend(y_pred)\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        score_class, weight = lwlrap(np.array(self.y_true), np.array(self.y_pred))\n",
    "        self.score = (score_class * weight).sum()\n",
    "\n",
    "        return self.score\n",
    "    \n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "\n",
    "def lwlrap(truth, scores):\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = _one_sample_positive_class_precisions(scores[sample_num, :],\n",
    "                                                                                     truth[sample_num, :])\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = precision_at_hits\n",
    "\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    return per_class_lwlrap, weight_per_class\n",
    "\n",
    "\n",
    "def pretty_print_metrics(fold, epoch, optimizer, train_loss_metrics, val_loss_metrics):\n",
    "    print(f\"\"\"\n",
    "    {time.ctime()} \\n\n",
    "    Fold:{fold}, Epoch:{epoch}, LR:{optimizer.param_groups[0]['lr']:.7}, Cons. Weight: {train_loss_metrics['consistency_weight']}\\n\n",
    "    --------------------------------------------------------\n",
    "    Metric:              Train    |   Val\n",
    "    --------------------------------------------------------\n",
    "    Loss:                {train_loss_metrics['loss']:0.4f}   |   {val_loss_metrics['loss']:0.4f}\\n\n",
    "    LWLRAP:              {train_loss_metrics['lwlrap']:0.4f}   |   {val_loss_metrics['lwlrap']:0.4f}\\n\n",
    "    Class Loss:          {train_loss_metrics['class_loss']:0.4f}   |   {val_loss_metrics['class_loss']:0.4f}\\n\n",
    "    Consistency Loss:    {train_loss_metrics['consistency_loss']:0.4f}   |   {val_loss_metrics['consistency_loss']:0.4f}\\n\n",
    "    --------------------------------------------------------\\n\n",
    "    \"\"\")\n",
    "    \n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, data_path, period=10, step=1):\n",
    "        self.data_path = data_path\n",
    "        self.period = period\n",
    "        self.step = step\n",
    "        self.recording_ids = list(df[\"recording_id\"].unique())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.recording_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        recording_id = self.recording_ids[idx]\n",
    "\n",
    "        y, sr = sf.read(f\"{self.data_path}/{recording_id}.flac\")\n",
    "\n",
    "        len_y = len(y)\n",
    "        effective_length = sr * self.period\n",
    "        effective_step = sr * self.step\n",
    "\n",
    "        y_ = []\n",
    "        i = 0\n",
    "        while i+effective_length <= len_y:\n",
    "            y__ = y[i:i + effective_length]\n",
    "\n",
    "            y_.append(y__)\n",
    "            i = i + effective_step\n",
    "\n",
    "        y = np.stack(y_)\n",
    "\n",
    "        label = np.zeros(NUM_CLASSES, dtype='f')\n",
    "\n",
    "        return {\n",
    "            \"waveform\": y,\n",
    "            \"target\": torch.tensor(label, dtype=torch.float),\n",
    "            \"id\": recording_id\n",
    "        }\n",
    "\n",
    "\n",
    "def predict_on_test(model, test_loader):\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    id_list = []\n",
    "    with torch.no_grad():\n",
    "        t = tqdm(test_loader)\n",
    "        for i, sample in enumerate(t):\n",
    "            input = sample[\"waveform\"].to(config.device)\n",
    "            bs, seq, w = input.shape\n",
    "            input = input.reshape(bs * seq, w)\n",
    "            id = sample[\"id\"]\n",
    "            output, _, _ = model(input)\n",
    "            output = output.reshape(bs, seq, -1)\n",
    "            output, _ = torch.max(output, dim=1)\n",
    "            \n",
    "            output = output.cpu().detach().numpy().tolist()\n",
    "            pred_list.extend(output)\n",
    "            id_list.extend(id)\n",
    "\n",
    "    return pred_list, id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "The model should look pretty familiar if you're using [SED](https://arxiv.org/abs/1912.04761). (Huge thanks to [Hidehisa Arai](https://www.kaggle.com/hidehisaarai1213) and their [SED Notebook](https://www.kaggle.com/hidehisaarai1213/introduction-to-sound-event-detection)!) You could use any model you'd like here. There's just one small tweak we need to make for our mean teacher setup. We need to \"detach\" the teacher's parameters so they aren't updated by the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class SEDAudioClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, sample_rate, window_size, hop_size, \n",
    "                 mel_bins, fmin, fmax, classes_num, mixup_module=None):\n",
    "        super().__init__()\n",
    "        self.interpolate_ratio = 32\n",
    "\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, \n",
    "                                                 hop_length=hop_size,\n",
    "                                                 win_length=window_size, \n",
    "                                                 window='hann', center=True,\n",
    "                                                 pad_mode='reflect', \n",
    "                                                 freeze_parameters=True)\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size,\n",
    "                                                 n_mels=mel_bins, fmin=fmin, \n",
    "                                                 fmax=fmax, ref=1.0, \n",
    "                                                 amin=1e-10, top_db=None, \n",
    "                                                 freeze_parameters=True)\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm2d(mel_bins)\n",
    "        self.encoder = partial(config.encoder, pretrained=True, in_chans=1)()\n",
    "        self.fc = nn.Linear(config.encoder_features, \n",
    "                            config.encoder_features, bias=True)\n",
    "        self.att_head = AttBlockV2(config.encoder_features, classes_num)\n",
    "        self.avg_pool = nn.modules.pooling.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.mixup_module = mixup_module\n",
    "        \n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.batch_norm)\n",
    "        init_layer(self.fc)\n",
    "        self.att_head.init_weights()\n",
    "\n",
    "    def forward(self, input, labels=None, spec_aug=False, return_encoding=False):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if self.mixup_module and labels is not None:\n",
    "                input, labels = self.mixup_module(input, labels)\n",
    "        \n",
    "        x = self.spectrogram_extractor(input.float())\n",
    "        x = self.logmel_extractor(x)\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.batch_norm(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        x = self.encoder.forward_features(x)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_head(x)\n",
    "        logit = torch.sum(norm_att * self.att_head.cla(x), dim=2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        framewise_output = interpolate(segmentwise_output, self.interpolate_ratio)\n",
    "        if labels is not None:\n",
    "            return clipwise_output, framewise_output, logit, labels\n",
    "        else:\n",
    "            return clipwise_output, framewise_output, labels\n",
    "\n",
    "\n",
    "def get_model(is_mean_teacher=False):\n",
    "    model = SEDAudioClassifier(**config.model_params)\n",
    "    model = model.to(config.device)\n",
    "    \n",
    "    # Detach params for Exponential Moving Average Model (aka the Mean Teacher).\n",
    "    # We'll manually update these params instead of using backprop.\n",
    "    if is_mean_teacher:\n",
    "        for param in model.parameters():\n",
    "            param.detach_()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "The loss function has 2 components:\n",
    "\n",
    "1. A classification loss that only applies to labeled samples.\n",
    "2. A consistency loss that applies to all samples. \n",
    "\n",
    "For the consistency loss we'll use the mean square error between the student and teacher predictions. We'll slowly ramp up the influence of the consistency loss since we don't want bad, early predictions having too much influence. \n",
    "\n",
    "Notice that we're weighting the positive samples for the classification loss. This is because we know the positives are correct while we're less sure about the negatives due to the missing labels issue. I found that this works better in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedPANNsLoss(nn.Module):\n",
    "    def __init__(self, pos_weight, weights=[1, 0.5]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.normal_loss = nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
    "\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, input, framewise_output, target):\n",
    "        input_ = input\n",
    "        target = target.float()\n",
    "\n",
    "        clipwise_output_with_max, _ = framewise_output.max(dim=1)\n",
    "\n",
    "        normal_loss = self.normal_loss(input_, target)\n",
    "        auxiliary_loss = self.bce(clipwise_output_with_max, target)\n",
    "\n",
    "        return self.weights[0] * normal_loss + self.weights[1] * auxiliary_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_mse_loss(input_logits, target_logits):\n",
    "    assert input_logits.size() == target_logits.size()\n",
    "    input_softmax = torch.sigmoid(input_logits)\n",
    "    target_softmax = torch.sigmoid(target_logits)\n",
    "    num_classes = input_logits.size()[1]\n",
    "    return F.mse_loss(input_softmax, target_softmax, size_average=False\n",
    "                     ) / num_classes\n",
    "\n",
    "def lsep_loss_stable(input, target, average=True):\n",
    "\n",
    "    n = input.size(0)\n",
    "\n",
    "    differences = input.unsqueeze(1) - input.unsqueeze(2)\n",
    "    where_lower = (target.unsqueeze(1) < target.unsqueeze(2)).float()\n",
    "\n",
    "    differences = differences.view(n, -1)\n",
    "    where_lower = where_lower.view(n, -1)\n",
    "\n",
    "    max_difference, index = torch.max(differences, dim=1, keepdim=True)\n",
    "    differences = differences - max_difference\n",
    "    exps = differences.exp() * where_lower\n",
    "\n",
    "    lsep = max_difference + torch.log(torch.exp(-max_difference) + exps.sum(-1))\n",
    "\n",
    "    if average:\n",
    "        return lsep.mean()\n",
    "    else:\n",
    "        return lsep\n",
    "\n",
    "\n",
    "class MeanTeacherLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.positive_weight = torch.ones(\n",
    "            NUM_CLASSES).to(config.device) * config.positive_weight\n",
    "        self.class_criterion = nn.BCEWithLogitsLoss(\n",
    "            reduction='none', pos_weight=self.positive_weight)\n",
    "        self.consistency_criterion = sigmoid_mse_loss\n",
    "\n",
    "    def make_safe(self, pred):\n",
    "        pred = torch.where(torch.isnan(pred), torch.zeros_like(pred), pred)\n",
    "        return torch.where(torch.isinf(pred), torch.zeros_like(pred), pred)\n",
    "        \n",
    "    def get_consistency_weight(self, epoch):\n",
    "        # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
    "        return config.consistency_weight * sigmoid_rampup(\n",
    "            epoch, config.consistency_rampup)\n",
    "    \n",
    "    def forward(self, student_pred, teacher_pred, target, classif_weights, epoch):\n",
    "        student_pred = self.make_safe(student_pred)\n",
    "        teacher_pred = self.make_safe(teacher_pred).detach().data\n",
    "\n",
    "        batch_size = len(target)\n",
    "        labeled_batch_size = target.ne(NO_LABEL).all(axis=1).sum().item() + 1e-3\n",
    "\n",
    "        student_classif, student_consistency = student_pred, student_pred\n",
    "        student_class_loss = (self.class_criterion(\n",
    "            student_classif, target) * classif_weights / labeled_batch_size).sum()\n",
    "\n",
    "        consistency_weights = self.get_consistency_weight(epoch)\n",
    "        consistency_loss = consistency_weights * self.consistency_criterion(\n",
    "            student_consistency, teacher_pred) / batch_size\n",
    "        loss = student_class_loss + consistency_loss\n",
    "        return loss, student_class_loss, consistency_loss, consistency_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader\n",
    "The data loader produces two types of samples:\n",
    "\n",
    "1. Labeled samples with the audio centered in the clip.\n",
    "2. Random unlabeled clips without labels selected from files with at least one true positive label.\n",
    "\n",
    "Each sample contains 2 different inputs, one for the student and one for the teacher. Different augmentations are applied to each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanTeacherDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transforms, period=5, \n",
    "                 data_path=\"/media/paniquex/samsung_2tb/rfcx_kaggle/rfcx-species-audio-detection/train\", \n",
    "                 val=False, percent_unlabeled=0.0):\n",
    "        self.period = period\n",
    "        self.transforms = transforms\n",
    "        self.data_path = data_path\n",
    "        self.val = val\n",
    "        self.percent_unlabeled = percent_unlabeled\n",
    "\n",
    "        dfgby = df.groupby(\"recording_id\").agg(lambda x: list(x)).reset_index()\n",
    "        self.recording_ids = dfgby[\"recording_id\"].values\n",
    "        self.species_ids = dfgby[\"species_id\"].values\n",
    "        self.t_mins = dfgby[\"t_min\"].values\n",
    "        self.t_maxs = dfgby[\"t_max\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.recording_ids) * (1 + self.percent_unlabeled))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.recording_ids):\n",
    "            audio, label, rec_id, sr = self.get_unlabeled_item(idx)\n",
    "            # For unlabeled samples, we zero out the classification loss.\n",
    "            classif_weights = np.zeros(NUM_CLASSES, dtype='f')\n",
    "        else:\n",
    "            audio, label, rec_id, sr = self.get_labeled_item(idx)\n",
    "            classif_weights = np.ones(NUM_CLASSES, dtype='f')\n",
    "\n",
    "        audio_teacher = np.copy(audio)\n",
    "\n",
    "        # The 2 samples fed to the 2 models have should have different augmentations.\n",
    "        audio = self.transforms(samples=audio, sample_rate=sr)\n",
    "        audio_teacher = self.transforms(samples=audio_teacher, sample_rate=sr)\n",
    "        # assert (audio != audio_teacher).any()\n",
    "        \n",
    "        return {\n",
    "            \"waveform\": audio,\n",
    "            \"teacher_waveform\": audio_teacher,\n",
    "            \"target\": torch.tensor(label, dtype=torch.float),\n",
    "            \"classification_weights\": classif_weights,\n",
    "            \"id\": rec_id\n",
    "        }\n",
    "\n",
    "    def get_labeled_item(self, idx):\n",
    "        recording_id = self.recording_ids[idx]\n",
    "        species_id = self.species_ids[idx]\n",
    "        t_min, t_max = self.t_mins[idx], self.t_maxs[idx]\n",
    "\n",
    "        rec, sr = sf.read(f\"{self.data_path}/{recording_id}.flac\")\n",
    "\n",
    "        len_rec = len(rec)\n",
    "        effective_length = sr * self.period\n",
    "        rint = np.random.randint(len(t_min))\n",
    "        tmin, tmax = round(sr * t_min[rint]), round(sr * t_max[rint])\n",
    "        dur = tmax - tmin\n",
    "        min_dur = min(dur, round(sr * self.period))\n",
    "\n",
    "        center = round((tmin + tmax) / 2)\n",
    "        rand_start = center - effective_length + max(min_dur - dur//2, 0)\n",
    "        if rand_start < 0:\n",
    "            rand_start = 0\n",
    "        rand_end = center - max(min_dur - dur//2, 0)\n",
    "        start = np.random.randint(rand_start, rand_end)\n",
    "        rec = rec[start:start + effective_length]\n",
    "        if len(rec) < effective_length:\n",
    "            new_rec = np.zeros(effective_length, dtype=rec.dtype)\n",
    "            start1 = np.random.randint(effective_length - len(rec))\n",
    "            new_rec[start1:start1 + len(rec)] = rec\n",
    "            rec = new_rec.astype(np.float32)\n",
    "        else:\n",
    "            rec = rec.astype(np.float32)\n",
    "\n",
    "        start_time = start / sr\n",
    "        end_time = (start + effective_length) / sr\n",
    "\n",
    "        label = np.zeros(NUM_CLASSES, dtype='f')\n",
    "\n",
    "        for i in range(len(t_min)):\n",
    "            if (t_min[i] >= start_time) & (t_max[i] <= end_time):\n",
    "                label[species_id[i]] = 1\n",
    "            elif start_time <= ((t_min[i] + t_max[i]) / 2) <= end_time:\n",
    "                label[species_id[i]] = 1\n",
    "\n",
    "        return rec, label, recording_id, sr\n",
    "\n",
    "    def get_unlabeled_item(self, idx, random_sample=False):\n",
    "        real_idx = idx - len(self.recording_ids)\n",
    "        # We want our validation set to be fixed.\n",
    "        if self.val:\n",
    "            rec_id = self.recording_ids[real_idx]\n",
    "        else:\n",
    "            rec_id = random.sample(list(self.recording_ids), 1)[0]\n",
    "\n",
    "        rec, sr = sf.read(f\"{self.data_path}/{rec_id}.flac\")\n",
    "        effective_length = int(sr * self.period)\n",
    "        max_end = len(rec) - effective_length\n",
    "        if self.val:\n",
    "            # Fixed start for validation. Probaably a better way to do this.\n",
    "            start = int(idx * 16963 % max_end)\n",
    "        else:\n",
    "            start = np.random.randint(0, max_end)\n",
    "        rec = rec[start:(start+effective_length)]\n",
    "        rec = rec.astype(np.float32)\n",
    "\n",
    "        label = np.ones(NUM_CLASSES, dtype='f') * NO_LABEL\n",
    "\n",
    "        return rec, label, rec_id, sr\n",
    "\n",
    "    \n",
    "def get_data_loader(df, is_val=False):\n",
    "    if is_val:\n",
    "        period = config.period_val\n",
    "    else:\n",
    "        period = config.period\n",
    "    dataset = MeanTeacherDataset(\n",
    "        df=df,\n",
    "        transforms=config.augmenter,\n",
    "        period=period,\n",
    "        percent_unlabeled=config.percent_unlabeled\n",
    "    )\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=not is_val,\n",
    "        drop_last=not is_val,\n",
    "        num_workers=config.num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "At the end of each training step we update the teacher weights by averaging in the latest student weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update teacher to be exponential moving average of student params.\n",
    "def update_teacher_params(student, teacher, alpha, global_step):\n",
    "    # Use the true average until the exponential average is more correct\n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    for ema_param, param in zip(teacher.parameters(), student.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n",
    "\n",
    "\n",
    "def train_one_epoch(student, mean_teacher, loader, \n",
    "                    criterion, optimizer, scheduler, epoch, is_val=False):\n",
    "    global_step = 0\n",
    "    losses = AverageMeter()\n",
    "    consistency_loss_avg = AverageMeter()\n",
    "    class_loss_avg = AverageMeter()\n",
    "    comp_metric = MetricMeter()\n",
    "    \n",
    "    if is_val:\n",
    "        student.eval()\n",
    "        mean_teacher.eval()\n",
    "        context = torch.no_grad()\n",
    "    else:\n",
    "        student.train()\n",
    "        mean_teacher.train()\n",
    "        context = nullcontext()\n",
    "    \n",
    "    with context:\n",
    "        t = tqdm(loader)\n",
    "        for i, sample in enumerate(t):\n",
    "            student_input = sample['waveform'].to(config.device)\n",
    "            teacher_input = sample['teacher_waveform'].to(config.device)\n",
    "            target = sample['target'].to(config.device)\n",
    "            classif_weights = sample['classification_weights'].to(config.device)\n",
    "            batch_size = len(target)\n",
    "            \n",
    "            if student.mixup_module:\n",
    "                student_pred, framewise_output, logit, target  = student(student_input, labels=target)\n",
    "            else:\n",
    "                student_pred, framewise_output, logit, target  = student(student_input, labels=target)\n",
    "#             if teacher.mixup_module:\n",
    "#                 teacher_pred, _, target  = mean_teacher(teacher_input, labels=target)\n",
    "#             else:\n",
    "            teacher_pred, _, _ = mean_teacher(teacher_input)\n",
    "\n",
    "            loss, class_loss, consistency_loss, consistency_weight = criterion(\n",
    "                student_pred, teacher_pred, target, classif_weights, epoch)\n",
    "\n",
    "            if not is_val:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                update_teacher_params(student, mean_teacher, \n",
    "                                      config.ema_decay, global_step)\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "            comp_metric.update(target, student_pred)\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            consistency_loss_avg.update(consistency_loss.item(), batch_size)\n",
    "            class_loss_avg.update(class_loss.item(), batch_size)\n",
    "            global_step += 1\n",
    "\n",
    "            t.set_description(f\"Epoch:{epoch} - Loss:{losses.avg:0.4f}\")\n",
    "        t.close()\n",
    "    return {'lwlrap':comp_metric.avg, \n",
    "            'loss':losses.avg, \n",
    "            'consistency_loss':consistency_loss_avg.avg, \n",
    "            'class_loss':class_loss_avg.avg, \n",
    "            'consistency_weight':consistency_weight}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally putting everything together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  \n",
      "Epoch:0 - Loss:7.2951: 100%|██████████| 113/113 [00:20<00:00,  5.49it/s]\n",
      "Epoch:0 - Loss:6.4672: 100%|██████████| 28/28 [00:03<00:00,  8.20it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:15:54 2021 \n",
      "\n",
      "    Fold:0, Epoch:0, LR:0.0009960574, Cons. Weight: 0.6737946999085467\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                7.2951   |   6.4672\n",
      "\n",
      "    LWLRAP:              0.2781   |   0.3984\n",
      "\n",
      "    Class Loss:          7.2860   |   6.4512\n",
      "\n",
      "    Consistency Loss:    0.0090   |   0.0160\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from -inf --> 0.39841709300920947\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 - Loss:5.3833: 100%|██████████| 113/113 [00:20<00:00,  5.56it/s]\n",
      "Epoch:1 - Loss:5.2231: 100%|██████████| 28/28 [00:04<00:00,  5.61it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:16:19 2021 \n",
      "\n",
      "    Fold:0, Epoch:1, LR:0.0009842916, Cons. Weight: 3.1047958479329627\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                5.3833   |   5.2231\n",
      "\n",
      "    LWLRAP:              0.4771   |   0.5633\n",
      "\n",
      "    Class Loss:          5.3423   |   5.1429\n",
      "\n",
      "    Consistency Loss:    0.0410   |   0.0802\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.39841709300920947 --> 0.5632856353466575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2 - Loss:4.4889: 100%|██████████| 113/113 [00:18<00:00,  6.08it/s]\n",
      "Epoch:2 - Loss:4.6290: 100%|██████████| 28/28 [00:04<00:00,  5.70it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:16:43 2021 \n",
      "\n",
      "    Fold:0, Epoch:2, LR:0.0009648882, Cons. Weight: 10.836802322189582\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                4.4889   |   4.6290\n",
      "\n",
      "    LWLRAP:              0.6077   |   0.6601\n",
      "\n",
      "    Class Loss:          4.3379   |   4.3783\n",
      "\n",
      "    Consistency Loss:    0.1510   |   0.2507\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.5632856353466575 --> 0.6601470468336683\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3 - Loss:4.0068: 100%|██████████| 113/113 [00:19<00:00,  5.83it/s]\n",
      "Epoch:3 - Loss:3.7440: 100%|██████████| 28/28 [00:04<00:00,  5.77it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:17:07 2021 \n",
      "\n",
      "    Fold:0, Epoch:3, LR:0.0009381533, Cons. Weight: 28.650479686019008\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                4.0068   |   3.7440\n",
      "\n",
      "    LWLRAP:              0.7004   |   0.7571\n",
      "\n",
      "    Class Loss:          3.6468   |   3.2913\n",
      "\n",
      "    Consistency Loss:    0.3600   |   0.4527\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.6601470468336683 --> 0.7571474064283799\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4 - Loss:3.5091: 100%|██████████| 113/113 [00:19<00:00,  5.89it/s]\n",
      "Epoch:4 - Loss:4.3120: 100%|██████████| 28/28 [00:05<00:00,  5.59it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:17:31 2021 \n",
      "\n",
      "    Fold:0, Epoch:4, LR:0.0009045085, Cons. Weight: 57.375342073743276\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.5091   |   4.3120\n",
      "\n",
      "    LWLRAP:              0.7656   |   0.7313\n",
      "\n",
      "    Class Loss:          2.8923   |   3.4151\n",
      "\n",
      "    Consistency Loss:    0.6167   |   0.8969\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5 - Loss:3.3693: 100%|██████████| 113/113 [00:19<00:00,  5.72it/s]\n",
      "Epoch:5 - Loss:3.7464: 100%|██████████| 28/28 [00:04<00:00,  6.14it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:17:56 2021 \n",
      "\n",
      "    Fold:0, Epoch:5, LR:0.0008644843, Cons. Weight: 87.03247258333906\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.3693   |   3.7464\n",
      "\n",
      "    LWLRAP:              0.7964   |   0.7923\n",
      "\n",
      "    Class Loss:          2.5751   |   2.6858\n",
      "\n",
      "    Consistency Loss:    0.7942   |   1.0606\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.7571474064283799 --> 0.7923351872342904\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6 - Loss:3.1317: 100%|██████████| 113/113 [00:19<00:00,  5.70it/s]\n",
      "Epoch:6 - Loss:3.4846: 100%|██████████| 28/28 [00:04<00:00,  5.87it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:18:21 2021 \n",
      "\n",
      "    Fold:0, Epoch:6, LR:0.000818712, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.1317   |   3.4846\n",
      "\n",
      "    LWLRAP:              0.8399   |   0.8299\n",
      "\n",
      "    Class Loss:          2.2852   |   2.5687\n",
      "\n",
      "    Consistency Loss:    0.8465   |   0.9160\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.7923351872342904 --> 0.8299004020670687\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7 - Loss:2.8690: 100%|██████████| 113/113 [00:19<00:00,  5.81it/s]\n",
      "Epoch:7 - Loss:3.9312: 100%|██████████| 28/28 [00:05<00:00,  5.59it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:18:45 2021 \n",
      "\n",
      "    Fold:0, Epoch:7, LR:0.0007679134, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.8690   |   3.9312\n",
      "\n",
      "    LWLRAP:              0.8513   |   0.8033\n",
      "\n",
      "    Class Loss:          2.0642   |   2.7805\n",
      "\n",
      "    Consistency Loss:    0.8048   |   1.1507\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8 - Loss:2.8870: 100%|██████████| 113/113 [00:19<00:00,  5.75it/s]\n",
      "Epoch:8 - Loss:3.3450: 100%|██████████| 28/28 [00:05<00:00,  5.41it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:19:10 2021 \n",
      "\n",
      "    Fold:0, Epoch:8, LR:0.0007128896, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.8870   |   3.3450\n",
      "\n",
      "    LWLRAP:              0.8416   |   0.8374\n",
      "\n",
      "    Class Loss:          2.0878   |   2.3698\n",
      "\n",
      "    Consistency Loss:    0.7992   |   0.9752\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8299004020670687 --> 0.8374478611144496\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9 - Loss:2.4544: 100%|██████████| 113/113 [00:19<00:00,  5.76it/s]\n",
      "Epoch:9 - Loss:3.1128: 100%|██████████| 28/28 [00:05<00:00,  5.34it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:19:35 2021 \n",
      "\n",
      "    Fold:0, Epoch:9, LR:0.0006545085, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.4544   |   3.1128\n",
      "\n",
      "    LWLRAP:              0.8751   |   0.8410\n",
      "\n",
      "    Class Loss:          1.7397   |   2.1498\n",
      "\n",
      "    Consistency Loss:    0.7147   |   0.9630\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8374478611144496 --> 0.8410159732973371\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:10 - Loss:2.4742: 100%|██████████| 113/113 [00:19<00:00,  5.84it/s]\n",
      "Epoch:10 - Loss:3.4796: 100%|██████████| 28/28 [00:05<00:00,  5.43it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:20:00 2021 \n",
      "\n",
      "    Fold:0, Epoch:10, LR:0.0005936907, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.4742   |   3.4796\n",
      "\n",
      "    LWLRAP:              0.8762   |   0.8106\n",
      "\n",
      "    Class Loss:          1.7320   |   2.5496\n",
      "\n",
      "    Consistency Loss:    0.7422   |   0.9300\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:11 - Loss:2.2279: 100%|██████████| 113/113 [00:20<00:00,  5.41it/s]\n",
      "Epoch:11 - Loss:3.0862: 100%|██████████| 28/28 [00:03<00:00,  8.32it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:20:24 2021 \n",
      "\n",
      "    Fold:0, Epoch:11, LR:0.0005313953, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.2279   |   3.0862\n",
      "\n",
      "    LWLRAP:              0.8780   |   0.8531\n",
      "\n",
      "    Class Loss:          1.5284   |   2.1776\n",
      "\n",
      "    Consistency Loss:    0.6995   |   0.9086\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8410159732973371 --> 0.8531456629789963\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:12 - Loss:2.0932: 100%|██████████| 113/113 [00:19<00:00,  5.76it/s]\n",
      "Epoch:12 - Loss:3.2507: 100%|██████████| 28/28 [00:04<00:00,  6.31it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:20:48 2021 \n",
      "\n",
      "    Fold:0, Epoch:12, LR:0.0004686047, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.0932   |   3.2507\n",
      "\n",
      "    LWLRAP:              0.9043   |   0.8361\n",
      "\n",
      "    Class Loss:          1.4262   |   2.4656\n",
      "\n",
      "    Consistency Loss:    0.6670   |   0.7851\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:13 - Loss:1.7930: 100%|██████████| 113/113 [00:18<00:00,  6.00it/s]\n",
      "Epoch:13 - Loss:3.0012: 100%|██████████| 28/28 [00:04<00:00,  6.28it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:21:12 2021 \n",
      "\n",
      "    Fold:0, Epoch:13, LR:0.0004063093, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.7930   |   3.0012\n",
      "\n",
      "    LWLRAP:              0.9193   |   0.8347\n",
      "\n",
      "    Class Loss:          1.1511   |   2.2301\n",
      "\n",
      "    Consistency Loss:    0.6418   |   0.7711\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:14 - Loss:1.6634: 100%|██████████| 113/113 [00:19<00:00,  5.84it/s]\n",
      "Epoch:14 - Loss:2.9024: 100%|██████████| 28/28 [00:04<00:00,  5.69it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:21:36 2021 \n",
      "\n",
      "    Fold:0, Epoch:14, LR:0.0003454915, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.6634   |   2.9024\n",
      "\n",
      "    LWLRAP:              0.9218   |   0.8576\n",
      "\n",
      "    Class Loss:          1.0514   |   2.0850\n",
      "\n",
      "    Consistency Loss:    0.6119   |   0.8174\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8531456629789963 --> 0.8575610555503841\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:15 - Loss:1.6710: 100%|██████████| 113/113 [00:18<00:00,  5.99it/s]\n",
      "Epoch:15 - Loss:3.1154: 100%|██████████| 28/28 [00:03<00:00,  7.09it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:21:59 2021 \n",
      "\n",
      "    Fold:0, Epoch:15, LR:0.0002871104, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.6710   |   3.1154\n",
      "\n",
      "    LWLRAP:              0.9362   |   0.8579\n",
      "\n",
      "    Class Loss:          1.0501   |   2.2164\n",
      "\n",
      "    Consistency Loss:    0.6209   |   0.8989\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8575610555503841 --> 0.8579029929279405\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:16 - Loss:1.7221: 100%|██████████| 113/113 [00:20<00:00,  5.57it/s]\n",
      "Epoch:16 - Loss:2.4907: 100%|██████████| 28/28 [00:03<00:00,  8.01it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:22:23 2021 \n",
      "\n",
      "    Fold:0, Epoch:16, LR:0.0002320866, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.7221   |   2.4907\n",
      "\n",
      "    LWLRAP:              0.9282   |   0.8599\n",
      "\n",
      "    Class Loss:          1.0929   |   1.8348\n",
      "\n",
      "    Consistency Loss:    0.6292   |   0.6559\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8579029929279405 --> 0.8598945718989772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:17 - Loss:1.4385: 100%|██████████| 113/113 [00:20<00:00,  5.56it/s]\n",
      "Epoch:17 - Loss:2.7283: 100%|██████████| 28/28 [00:04<00:00,  5.65it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:22:48 2021 \n",
      "\n",
      "    Fold:0, Epoch:17, LR:0.000181288, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.4385   |   2.7283\n",
      "\n",
      "    LWLRAP:              0.9415   |   0.8541\n",
      "\n",
      "    Class Loss:          0.9304   |   2.1212\n",
      "\n",
      "    Consistency Loss:    0.5081   |   0.6071\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:18 - Loss:1.3671: 100%|██████████| 113/113 [00:20<00:00,  5.63it/s]\n",
      "Epoch:18 - Loss:2.9288: 100%|██████████| 28/28 [00:05<00:00,  5.35it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:23:14 2021 \n",
      "\n",
      "    Fold:0, Epoch:18, LR:0.0001355157, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3671   |   2.9288\n",
      "\n",
      "    LWLRAP:              0.9453   |   0.8467\n",
      "\n",
      "    Class Loss:          0.8389   |   2.2841\n",
      "\n",
      "    Consistency Loss:    0.5282   |   0.6447\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:19 - Loss:1.3907: 100%|██████████| 113/113 [00:19<00:00,  5.93it/s]\n",
      "Epoch:19 - Loss:2.6528: 100%|██████████| 28/28 [00:04<00:00,  5.93it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:23:38 2021 \n",
      "\n",
      "    Fold:0, Epoch:19, LR:9.54915e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3907   |   2.6528\n",
      "\n",
      "    LWLRAP:              0.9424   |   0.8695\n",
      "\n",
      "    Class Loss:          0.8728   |   2.0231\n",
      "\n",
      "    Consistency Loss:    0.5179   |   0.6297\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8598945718989772 --> 0.8694511977697819\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:20 - Loss:1.3049: 100%|██████████| 113/113 [00:18<00:00,  6.06it/s]\n",
      "Epoch:20 - Loss:2.4285: 100%|██████████| 28/28 [00:04<00:00,  6.06it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:24:01 2021 \n",
      "\n",
      "    Fold:0, Epoch:20, LR:6.184666e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3049   |   2.4285\n",
      "\n",
      "    LWLRAP:              0.9465   |   0.8961\n",
      "\n",
      "    Class Loss:          0.7454   |   1.7997\n",
      "\n",
      "    Consistency Loss:    0.5596   |   0.6288\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8694511977697819 --> 0.8960699944107022\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:21 - Loss:1.3130: 100%|██████████| 113/113 [00:19<00:00,  5.77it/s]\n",
      "Epoch:21 - Loss:2.6028: 100%|██████████| 28/28 [00:04<00:00,  6.76it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:24:25 2021 \n",
      "\n",
      "    Fold:0, Epoch:21, LR:3.511176e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3130   |   2.6028\n",
      "\n",
      "    LWLRAP:              0.9520   |   0.8573\n",
      "\n",
      "    Class Loss:          0.7442   |   2.0098\n",
      "\n",
      "    Consistency Loss:    0.5688   |   0.5931\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:22 - Loss:1.2294: 100%|██████████| 113/113 [00:19<00:00,  5.84it/s]\n",
      "Epoch:22 - Loss:2.2118: 100%|██████████| 28/28 [00:04<00:00,  6.01it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:24:49 2021 \n",
      "\n",
      "    Fold:0, Epoch:22, LR:1.570842e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.2294   |   2.2118\n",
      "\n",
      "    LWLRAP:              0.9515   |   0.8896\n",
      "\n",
      "    Class Loss:          0.7188   |   1.6940\n",
      "\n",
      "    Consistency Loss:    0.5106   |   0.5178\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:23 - Loss:1.2080: 100%|██████████| 113/113 [00:19<00:00,  5.85it/s]\n",
      "Epoch:23 - Loss:2.2364: 100%|██████████| 28/28 [00:04<00:00,  6.08it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:25:13 2021 \n",
      "\n",
      "    Fold:0, Epoch:23, LR:3.942649e-06, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.2080   |   2.2364\n",
      "\n",
      "    LWLRAP:              0.9603   |   0.8768\n",
      "\n",
      "    Class Loss:          0.6845   |   1.7163\n",
      "\n",
      "    Consistency Loss:    0.5234   |   0.5201\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:24 - Loss:1.2438: 100%|██████████| 113/113 [00:19<00:00,  5.67it/s]\n",
      "Epoch:24 - Loss:2.6864: 100%|██████████| 28/28 [00:04<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:25:38 2021 \n",
      "\n",
      "    Fold:0, Epoch:24, LR:0.0, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.2438   |   2.6864\n",
      "\n",
      "    LWLRAP:              0.9472   |   0.8588\n",
      "\n",
      "    Class Loss:          0.7133   |   2.0590\n",
      "\n",
      "    Consistency Loss:    0.5306   |   0.6274\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:0 - Loss:7.2745: 100%|██████████| 113/113 [00:19<00:00,  5.91it/s]\n",
      "Epoch:0 - Loss:6.4080: 100%|██████████| 28/28 [00:03<00:00,  8.59it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:26:02 2021 \n",
      "\n",
      "    Fold:1, Epoch:0, LR:0.0009960574, Cons. Weight: 0.6737946999085467\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                7.2745   |   6.4080\n",
      "\n",
      "    LWLRAP:              0.2810   |   0.3776\n",
      "\n",
      "    Class Loss:          7.2660   |   6.3939\n",
      "\n",
      "    Consistency Loss:    0.0085   |   0.0141\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from -inf --> 0.3776146525950448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 - Loss:5.6386: 100%|██████████| 113/113 [00:12<00:00,  8.82it/s]\n",
      "Epoch:1 - Loss:5.6550: 100%|██████████| 28/28 [00:03<00:00,  8.21it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:26:18 2021 \n",
      "\n",
      "    Fold:1, Epoch:1, LR:0.0009842916, Cons. Weight: 3.1047958479329627\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                5.6386   |   5.6550\n",
      "\n",
      "    LWLRAP:              0.4687   |   0.5056\n",
      "\n",
      "    Class Loss:          5.5958   |   5.5809\n",
      "\n",
      "    Consistency Loss:    0.0428   |   0.0741\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.3776146525950448 --> 0.505592328964005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2 - Loss:4.5007: 100%|██████████| 113/113 [00:12<00:00,  8.80it/s]\n",
      "Epoch:2 - Loss:4.9162: 100%|██████████| 28/28 [00:03<00:00,  8.90it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:26:34 2021 \n",
      "\n",
      "    Fold:1, Epoch:2, LR:0.0009648882, Cons. Weight: 10.836802322189582\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                4.5007   |   4.9162\n",
      "\n",
      "    LWLRAP:              0.5944   |   0.5917\n",
      "\n",
      "    Class Loss:          4.3594   |   4.6662\n",
      "\n",
      "    Consistency Loss:    0.1412   |   0.2500\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.505592328964005 --> 0.5917495948443553\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3 - Loss:4.0911: 100%|██████████| 113/113 [00:12<00:00,  9.08it/s]\n",
      "Epoch:3 - Loss:4.8863: 100%|██████████| 28/28 [00:03<00:00,  8.43it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:26:50 2021 \n",
      "\n",
      "    Fold:1, Epoch:3, LR:0.0009381533, Cons. Weight: 28.650479686019008\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                4.0911   |   4.8863\n",
      "\n",
      "    LWLRAP:              0.6703   |   0.6063\n",
      "\n",
      "    Class Loss:          3.7330   |   4.2337\n",
      "\n",
      "    Consistency Loss:    0.3581   |   0.6526\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.5917495948443553 --> 0.6063463457345419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4 - Loss:3.9383: 100%|██████████| 113/113 [00:12<00:00,  8.80it/s]\n",
      "Epoch:4 - Loss:4.8440: 100%|██████████| 28/28 [00:03<00:00,  8.30it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:27:06 2021 \n",
      "\n",
      "    Fold:1, Epoch:4, LR:0.0009045085, Cons. Weight: 57.375342073743276\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.9383   |   4.8440\n",
      "\n",
      "    LWLRAP:              0.7218   |   0.6805\n",
      "\n",
      "    Class Loss:          3.2748   |   3.9493\n",
      "\n",
      "    Consistency Loss:    0.6636   |   0.8946\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.6063463457345419 --> 0.6805332995355418\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5 - Loss:3.4434: 100%|██████████| 113/113 [00:13<00:00,  8.62it/s]\n",
      "Epoch:5 - Loss:3.9397: 100%|██████████| 28/28 [00:03<00:00,  8.43it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:27:23 2021 \n",
      "\n",
      "    Fold:1, Epoch:5, LR:0.0008644843, Cons. Weight: 87.03247258333906\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.4434   |   3.9397\n",
      "\n",
      "    LWLRAP:              0.7866   |   0.7949\n",
      "\n",
      "    Class Loss:          2.6390   |   2.9361\n",
      "\n",
      "    Consistency Loss:    0.8044   |   1.0037\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.6805332995355418 --> 0.7948619360384066\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6 - Loss:3.1157: 100%|██████████| 113/113 [00:12<00:00,  9.24it/s]\n",
      "Epoch:6 - Loss:3.9801: 100%|██████████| 28/28 [00:03<00:00,  9.19it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:27:38 2021 \n",
      "\n",
      "    Fold:1, Epoch:6, LR:0.000818712, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.1157   |   3.9801\n",
      "\n",
      "    LWLRAP:              0.8297   |   0.8013\n",
      "\n",
      "    Class Loss:          2.2704   |   2.6900\n",
      "\n",
      "    Consistency Loss:    0.8453   |   1.2901\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.7948619360384066 --> 0.8012525562467843\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7 - Loss:2.7699: 100%|██████████| 113/113 [00:12<00:00,  9.13it/s]\n",
      "Epoch:7 - Loss:4.1217: 100%|██████████| 28/28 [00:03<00:00,  8.95it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:27:54 2021 \n",
      "\n",
      "    Fold:1, Epoch:7, LR:0.0007679134, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.7699   |   4.1217\n",
      "\n",
      "    LWLRAP:              0.8476   |   0.7993\n",
      "\n",
      "    Class Loss:          2.0613   |   2.9577\n",
      "\n",
      "    Consistency Loss:    0.7086   |   1.1641\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8 - Loss:2.8232: 100%|██████████| 113/113 [00:13<00:00,  8.67it/s]\n",
      "Epoch:8 - Loss:3.2100: 100%|██████████| 28/28 [00:03<00:00,  7.18it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:28:11 2021 \n",
      "\n",
      "    Fold:1, Epoch:8, LR:0.0007128896, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.8232   |   3.2100\n",
      "\n",
      "    LWLRAP:              0.8431   |   0.8270\n",
      "\n",
      "    Class Loss:          2.0651   |   2.3018\n",
      "\n",
      "    Consistency Loss:    0.7581   |   0.9082\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8012525562467843 --> 0.8270080206964265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9 - Loss:2.7969: 100%|██████████| 113/113 [00:13<00:00,  8.39it/s]\n",
      "Epoch:9 - Loss:3.2562: 100%|██████████| 28/28 [00:03<00:00,  8.09it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:28:28 2021 \n",
      "\n",
      "    Fold:1, Epoch:9, LR:0.0006545085, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.7969   |   3.2562\n",
      "\n",
      "    LWLRAP:              0.8415   |   0.8287\n",
      "\n",
      "    Class Loss:          2.0513   |   2.3670\n",
      "\n",
      "    Consistency Loss:    0.7456   |   0.8891\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8270080206964265 --> 0.8287355292994392\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:10 - Loss:2.2720: 100%|██████████| 113/113 [00:12<00:00,  9.31it/s]\n",
      "Epoch:10 - Loss:3.4015: 100%|██████████| 28/28 [00:03<00:00,  8.60it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:28:44 2021 \n",
      "\n",
      "    Fold:1, Epoch:10, LR:0.0005936907, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.2720   |   3.4015\n",
      "\n",
      "    LWLRAP:              0.8817   |   0.8172\n",
      "\n",
      "    Class Loss:          1.5625   |   2.5090\n",
      "\n",
      "    Consistency Loss:    0.7095   |   0.8925\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:11 - Loss:2.1475: 100%|██████████| 113/113 [00:11<00:00,  9.58it/s]\n",
      "Epoch:11 - Loss:4.1541: 100%|██████████| 28/28 [00:03<00:00,  8.97it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:28:59 2021 \n",
      "\n",
      "    Fold:1, Epoch:11, LR:0.0005313953, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.1475   |   4.1541\n",
      "\n",
      "    LWLRAP:              0.8919   |   0.8170\n",
      "\n",
      "    Class Loss:          1.4384   |   3.1449\n",
      "\n",
      "    Consistency Loss:    0.7091   |   1.0092\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:12 - Loss:2.3193: 100%|██████████| 113/113 [00:13<00:00,  8.43it/s]\n",
      "Epoch:12 - Loss:3.1374: 100%|██████████| 28/28 [00:03<00:00,  8.61it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:29:15 2021 \n",
      "\n",
      "    Fold:1, Epoch:12, LR:0.0004686047, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.3193   |   3.1374\n",
      "\n",
      "    LWLRAP:              0.8929   |   0.8320\n",
      "\n",
      "    Class Loss:          1.5366   |   2.2188\n",
      "\n",
      "    Consistency Loss:    0.7827   |   0.9186\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8287355292994392 --> 0.83195067264574\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:13 - Loss:2.0196: 100%|██████████| 113/113 [00:12<00:00,  9.29it/s]\n",
      "Epoch:13 - Loss:3.1926: 100%|██████████| 28/28 [00:03<00:00,  8.32it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:29:31 2021 \n",
      "\n",
      "    Fold:1, Epoch:13, LR:0.0004063093, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.0196   |   3.1926\n",
      "\n",
      "    LWLRAP:              0.9038   |   0.8251\n",
      "\n",
      "    Class Loss:          1.3760   |   2.3511\n",
      "\n",
      "    Consistency Loss:    0.6436   |   0.8414\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:14 - Loss:1.8509: 100%|██████████| 113/113 [00:11<00:00,  9.42it/s]\n",
      "Epoch:14 - Loss:3.3408: 100%|██████████| 28/28 [00:03<00:00,  9.31it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:29:46 2021 \n",
      "\n",
      "    Fold:1, Epoch:14, LR:0.0003454915, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.8509   |   3.3408\n",
      "\n",
      "    LWLRAP:              0.9144   |   0.8352\n",
      "\n",
      "    Class Loss:          1.2480   |   2.6823\n",
      "\n",
      "    Consistency Loss:    0.6029   |   0.6585\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.83195067264574 --> 0.8352417779265631\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:15 - Loss:1.7814: 100%|██████████| 113/113 [00:11<00:00,  9.48it/s]\n",
      "Epoch:15 - Loss:2.9479: 100%|██████████| 28/28 [00:03<00:00,  9.21it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:30:01 2021 \n",
      "\n",
      "    Fold:1, Epoch:15, LR:0.0002871104, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.7814   |   2.9479\n",
      "\n",
      "    LWLRAP:              0.9201   |   0.8347\n",
      "\n",
      "    Class Loss:          1.1237   |   2.2576\n",
      "\n",
      "    Consistency Loss:    0.6577   |   0.6903\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:16 - Loss:1.6883: 100%|██████████| 113/113 [00:12<00:00,  9.11it/s]\n",
      "Epoch:16 - Loss:3.0023: 100%|██████████| 28/28 [00:03<00:00,  8.29it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:30:17 2021 \n",
      "\n",
      "    Fold:1, Epoch:16, LR:0.0002320866, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.6883   |   3.0023\n",
      "\n",
      "    LWLRAP:              0.9288   |   0.8547\n",
      "\n",
      "    Class Loss:          1.0546   |   2.2678\n",
      "\n",
      "    Consistency Loss:    0.6336   |   0.7346\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8352417779265631 --> 0.8546677088343755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:17 - Loss:1.5153: 100%|██████████| 113/113 [00:14<00:00,  7.73it/s]\n",
      "Epoch:17 - Loss:3.1865: 100%|██████████| 28/28 [00:03<00:00,  8.31it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:30:35 2021 \n",
      "\n",
      "    Fold:1, Epoch:17, LR:0.000181288, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.5153   |   3.1865\n",
      "\n",
      "    LWLRAP:              0.9357   |   0.8502\n",
      "\n",
      "    Class Loss:          0.9460   |   2.3981\n",
      "\n",
      "    Consistency Loss:    0.5693   |   0.7884\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:18 - Loss:1.4542: 100%|██████████| 113/113 [00:12<00:00,  9.20it/s]\n",
      "Epoch:18 - Loss:2.6592: 100%|██████████| 28/28 [00:03<00:00,  8.35it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:30:51 2021 \n",
      "\n",
      "    Fold:1, Epoch:18, LR:0.0001355157, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.4542   |   2.6592\n",
      "\n",
      "    LWLRAP:              0.9374   |   0.8813\n",
      "\n",
      "    Class Loss:          0.8710   |   2.0293\n",
      "\n",
      "    Consistency Loss:    0.5832   |   0.6299\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8546677088343755 --> 0.8813074536211791\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:19 - Loss:1.3789: 100%|██████████| 113/113 [00:12<00:00,  8.70it/s]\n",
      "Epoch:19 - Loss:3.1370: 100%|██████████| 28/28 [00:05<00:00,  5.12it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:31:09 2021 \n",
      "\n",
      "    Fold:1, Epoch:19, LR:9.54915e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3789   |   3.1370\n",
      "\n",
      "    LWLRAP:              0.9526   |   0.8461\n",
      "\n",
      "    Class Loss:          0.8061   |   2.5509\n",
      "\n",
      "    Consistency Loss:    0.5728   |   0.5862\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:20 - Loss:1.3665: 100%|██████████| 113/113 [00:19<00:00,  5.95it/s]\n",
      "Epoch:20 - Loss:2.6609: 100%|██████████| 28/28 [00:05<00:00,  5.49it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:31:34 2021 \n",
      "\n",
      "    Fold:1, Epoch:20, LR:6.184666e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3665   |   2.6609\n",
      "\n",
      "    LWLRAP:              0.9429   |   0.8692\n",
      "\n",
      "    Class Loss:          0.7900   |   2.0377\n",
      "\n",
      "    Consistency Loss:    0.5765   |   0.6232\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:21 - Loss:1.3781: 100%|██████████| 113/113 [00:20<00:00,  5.59it/s]\n",
      "Epoch:21 - Loss:2.8231: 100%|██████████| 28/28 [00:05<00:00,  5.45it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:31:59 2021 \n",
      "\n",
      "    Fold:1, Epoch:21, LR:3.511176e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3781   |   2.8231\n",
      "\n",
      "    LWLRAP:              0.9488   |   0.8616\n",
      "\n",
      "    Class Loss:          0.7891   |   2.1694\n",
      "\n",
      "    Consistency Loss:    0.5890   |   0.6537\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:22 - Loss:1.2022: 100%|██████████| 113/113 [00:20<00:00,  5.63it/s]\n",
      "Epoch:22 - Loss:2.7446: 100%|██████████| 28/28 [00:05<00:00,  5.04it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:32:25 2021 \n",
      "\n",
      "    Fold:1, Epoch:22, LR:1.570842e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.2022   |   2.7446\n",
      "\n",
      "    LWLRAP:              0.9530   |   0.8579\n",
      "\n",
      "    Class Loss:          0.6789   |   2.2003\n",
      "\n",
      "    Consistency Loss:    0.5233   |   0.5442\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:23 - Loss:1.3087: 100%|██████████| 113/113 [00:20<00:00,  5.49it/s]\n",
      "Epoch:23 - Loss:2.5833: 100%|██████████| 28/28 [00:05<00:00,  5.05it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:32:51 2021 \n",
      "\n",
      "    Fold:1, Epoch:23, LR:3.942649e-06, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3087   |   2.5833\n",
      "\n",
      "    LWLRAP:              0.9480   |   0.8726\n",
      "\n",
      "    Class Loss:          0.7355   |   1.9679\n",
      "\n",
      "    Consistency Loss:    0.5732   |   0.6154\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:24 - Loss:1.3247: 100%|██████████| 113/113 [00:20<00:00,  5.42it/s]\n",
      "Epoch:24 - Loss:2.8985: 100%|██████████| 28/28 [00:05<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:33:17 2021 \n",
      "\n",
      "    Fold:1, Epoch:24, LR:0.0, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3247   |   2.8985\n",
      "\n",
      "    LWLRAP:              0.9475   |   0.8716\n",
      "\n",
      "    Class Loss:          0.7703   |   2.2344\n",
      "\n",
      "    Consistency Loss:    0.5544   |   0.6641\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:0 - Loss:7.3904: 100%|██████████| 113/113 [00:20<00:00,  5.53it/s]\n",
      "Epoch:0 - Loss:6.7244: 100%|██████████| 28/28 [00:04<00:00,  5.88it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:33:43 2021 \n",
      "\n",
      "    Fold:2, Epoch:0, LR:0.0009960574, Cons. Weight: 0.6737946999085467\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                7.3904   |   6.7244\n",
      "\n",
      "    LWLRAP:              0.2726   |   0.3699\n",
      "\n",
      "    Class Loss:          7.3817   |   6.7092\n",
      "\n",
      "    Consistency Loss:    0.0087   |   0.0151\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from -inf --> 0.36994637557344523\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 - Loss:5.0916: 100%|██████████| 113/113 [00:19<00:00,  5.67it/s]\n",
      "Epoch:1 - Loss:4.3079: 100%|██████████| 28/28 [00:04<00:00,  6.56it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:34:08 2021 \n",
      "\n",
      "    Fold:2, Epoch:1, LR:0.0009842916, Cons. Weight: 3.1047958479329627\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                5.0916   |   4.3079\n",
      "\n",
      "    LWLRAP:              0.5160   |   0.6259\n",
      "\n",
      "    Class Loss:          5.0492   |   4.2344\n",
      "\n",
      "    Consistency Loss:    0.0424   |   0.0735\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.36994637557344523 --> 0.6259256109674066\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2 - Loss:4.4410: 100%|██████████| 113/113 [00:19<00:00,  5.79it/s]\n",
      "Epoch:2 - Loss:5.3958: 100%|██████████| 28/28 [00:05<00:00,  4.95it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:34:33 2021 \n",
      "\n",
      "    Fold:2, Epoch:2, LR:0.0009648882, Cons. Weight: 10.836802322189582\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                4.4410   |   5.3958\n",
      "\n",
      "    LWLRAP:              0.6193   |   0.6487\n",
      "\n",
      "    Class Loss:          4.2900   |   5.1466\n",
      "\n",
      "    Consistency Loss:    0.1509   |   0.2492\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.6259256109674066 --> 0.6486954899008124\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3 - Loss:3.6230: 100%|██████████| 113/113 [00:19<00:00,  5.92it/s]\n",
      "Epoch:3 - Loss:3.7031: 100%|██████████| 28/28 [00:05<00:00,  4.96it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:34:58 2021 \n",
      "\n",
      "    Fold:2, Epoch:3, LR:0.0009381533, Cons. Weight: 28.650479686019008\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.6230   |   3.7031\n",
      "\n",
      "    LWLRAP:              0.7344   |   0.7570\n",
      "\n",
      "    Class Loss:          3.2635   |   3.1910\n",
      "\n",
      "    Consistency Loss:    0.3595   |   0.5121\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.6486954899008124 --> 0.7569730036618583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4 - Loss:3.5667: 100%|██████████| 113/113 [00:19<00:00,  5.92it/s]\n",
      "Epoch:4 - Loss:3.3427: 100%|██████████| 28/28 [00:05<00:00,  4.94it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:35:23 2021 \n",
      "\n",
      "    Fold:2, Epoch:4, LR:0.0009045085, Cons. Weight: 57.375342073743276\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.5667   |   3.3427\n",
      "\n",
      "    LWLRAP:              0.7694   |   0.8207\n",
      "\n",
      "    Class Loss:          2.9939   |   2.5909\n",
      "\n",
      "    Consistency Loss:    0.5728   |   0.7518\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.7569730036618583 --> 0.8206731738758136\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5 - Loss:3.2690: 100%|██████████| 113/113 [00:18<00:00,  6.02it/s]\n",
      "Epoch:5 - Loss:4.6270: 100%|██████████| 28/28 [00:05<00:00,  5.32it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:35:47 2021 \n",
      "\n",
      "    Fold:2, Epoch:5, LR:0.0008644843, Cons. Weight: 87.03247258333906\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.2690   |   4.6270\n",
      "\n",
      "    LWLRAP:              0.8162   |   0.7797\n",
      "\n",
      "    Class Loss:          2.4884   |   3.4584\n",
      "\n",
      "    Consistency Loss:    0.7806   |   1.1685\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6 - Loss:3.1030: 100%|██████████| 113/113 [00:19<00:00,  5.80it/s]\n",
      "Epoch:6 - Loss:3.5455: 100%|██████████| 28/28 [00:05<00:00,  5.39it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:36:12 2021 \n",
      "\n",
      "    Fold:2, Epoch:6, LR:0.000818712, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.1030   |   3.5455\n",
      "\n",
      "    LWLRAP:              0.8225   |   0.8440\n",
      "\n",
      "    Class Loss:          2.2189   |   2.5136\n",
      "\n",
      "    Consistency Loss:    0.8841   |   1.0319\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8206731738758136 --> 0.8440181965851609\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7 - Loss:2.9747: 100%|██████████| 113/113 [00:17<00:00,  6.33it/s]\n",
      "Epoch:7 - Loss:4.2982: 100%|██████████| 28/28 [00:05<00:00,  4.76it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:36:36 2021 \n",
      "\n",
      "    Fold:2, Epoch:7, LR:0.0007679134, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.9747   |   4.2982\n",
      "\n",
      "    LWLRAP:              0.8418   |   0.8038\n",
      "\n",
      "    Class Loss:          2.1292   |   2.8324\n",
      "\n",
      "    Consistency Loss:    0.8454   |   1.4658\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8 - Loss:2.8073: 100%|██████████| 113/113 [00:19<00:00,  5.65it/s]\n",
      "Epoch:8 - Loss:3.6858: 100%|██████████| 28/28 [00:08<00:00,  3.15it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:37:05 2021 \n",
      "\n",
      "    Fold:2, Epoch:8, LR:0.0007128896, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.8073   |   3.6858\n",
      "\n",
      "    LWLRAP:              0.8510   |   0.8323\n",
      "\n",
      "    Class Loss:          1.9846   |   2.6639\n",
      "\n",
      "    Consistency Loss:    0.8227   |   1.0219\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9 - Loss:2.6110: 100%|██████████| 113/113 [00:25<00:00,  4.42it/s]\n",
      "Epoch:9 - Loss:3.3144: 100%|██████████| 28/28 [00:07<00:00,  3.63it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:37:38 2021 \n",
      "\n",
      "    Fold:2, Epoch:9, LR:0.0006545085, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.6110   |   3.3144\n",
      "\n",
      "    LWLRAP:              0.8737   |   0.8368\n",
      "\n",
      "    Class Loss:          1.8423   |   2.3857\n",
      "\n",
      "    Consistency Loss:    0.7687   |   0.9286\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:10 - Loss:2.1644: 100%|██████████| 113/113 [00:28<00:00,  3.90it/s]\n",
      "Epoch:10 - Loss:3.5239: 100%|██████████| 28/28 [00:07<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:38:15 2021 \n",
      "\n",
      "    Fold:2, Epoch:10, LR:0.0005936907, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.1644   |   3.5239\n",
      "\n",
      "    LWLRAP:              0.8967   |   0.8499\n",
      "\n",
      "    Class Loss:          1.4338   |   2.3983\n",
      "\n",
      "    Consistency Loss:    0.7306   |   1.1256\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8440181965851609 --> 0.8499188405018001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:11 - Loss:2.2547: 100%|██████████| 113/113 [00:28<00:00,  4.00it/s]\n",
      "Epoch:11 - Loss:3.6773: 100%|██████████| 28/28 [00:05<00:00,  4.94it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:38:49 2021 \n",
      "\n",
      "    Fold:2, Epoch:11, LR:0.0005313953, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.2547   |   3.6773\n",
      "\n",
      "    LWLRAP:              0.9027   |   0.8372\n",
      "\n",
      "    Class Loss:          1.4993   |   2.7981\n",
      "\n",
      "    Consistency Loss:    0.7554   |   0.8792\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:12 - Loss:2.0322: 100%|██████████| 113/113 [00:26<00:00,  4.31it/s]\n",
      "Epoch:12 - Loss:3.7483: 100%|██████████| 28/28 [00:08<00:00,  3.33it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:39:24 2021 \n",
      "\n",
      "    Fold:2, Epoch:12, LR:0.0004686047, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.0322   |   3.7483\n",
      "\n",
      "    LWLRAP:              0.9145   |   0.8432\n",
      "\n",
      "    Class Loss:          1.3290   |   2.8160\n",
      "\n",
      "    Consistency Loss:    0.7032   |   0.9323\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:13 - Loss:2.0930: 100%|██████████| 113/113 [00:33<00:00,  3.35it/s]\n",
      "Epoch:13 - Loss:2.6455: 100%|██████████| 28/28 [00:11<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:40:09 2021 \n",
      "\n",
      "    Fold:2, Epoch:13, LR:0.0004063093, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.0930   |   2.6455\n",
      "\n",
      "    LWLRAP:              0.9031   |   0.8737\n",
      "\n",
      "    Class Loss:          1.4040   |   1.8488\n",
      "\n",
      "    Consistency Loss:    0.6890   |   0.7967\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8499188405018001 --> 0.8737160493827161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:14 - Loss:1.7274: 100%|██████████| 113/113 [00:36<00:00,  3.07it/s]\n",
      "Epoch:14 - Loss:2.7132: 100%|██████████| 28/28 [00:11<00:00,  2.48it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:40:58 2021 \n",
      "\n",
      "    Fold:2, Epoch:14, LR:0.0003454915, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.7274   |   2.7132\n",
      "\n",
      "    LWLRAP:              0.9257   |   0.8528\n",
      "\n",
      "    Class Loss:          1.1281   |   1.8938\n",
      "\n",
      "    Consistency Loss:    0.5993   |   0.8195\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:15 - Loss:1.6634: 100%|██████████| 113/113 [00:33<00:00,  3.34it/s]\n",
      "Epoch:15 - Loss:2.9999: 100%|██████████| 28/28 [00:08<00:00,  3.42it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:41:40 2021 \n",
      "\n",
      "    Fold:2, Epoch:15, LR:0.0002871104, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.6634   |   2.9999\n",
      "\n",
      "    LWLRAP:              0.9282   |   0.8501\n",
      "\n",
      "    Class Loss:          1.0613   |   2.1290\n",
      "\n",
      "    Consistency Loss:    0.6021   |   0.8709\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:16 - Loss:1.4178: 100%|██████████| 113/113 [00:25<00:00,  4.51it/s]\n",
      "Epoch:16 - Loss:2.7096: 100%|██████████| 28/28 [00:07<00:00,  3.92it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:42:12 2021 \n",
      "\n",
      "    Fold:2, Epoch:16, LR:0.0002320866, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.4178   |   2.7096\n",
      "\n",
      "    LWLRAP:              0.9400   |   0.8602\n",
      "\n",
      "    Class Loss:          0.8626   |   1.9579\n",
      "\n",
      "    Consistency Loss:    0.5552   |   0.7518\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:17 - Loss:1.4058: 100%|██████████| 113/113 [00:25<00:00,  4.40it/s]\n",
      "Epoch:17 - Loss:2.8303: 100%|██████████| 28/28 [00:07<00:00,  3.92it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:42:45 2021 \n",
      "\n",
      "    Fold:2, Epoch:17, LR:0.000181288, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.4058   |   2.8303\n",
      "\n",
      "    LWLRAP:              0.9435   |   0.8527\n",
      "\n",
      "    Class Loss:          0.8800   |   2.0957\n",
      "\n",
      "    Consistency Loss:    0.5258   |   0.7346\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:18 - Loss:1.3228: 100%|██████████| 113/113 [00:29<00:00,  3.81it/s]\n",
      "Epoch:18 - Loss:2.8921: 100%|██████████| 28/28 [00:05<00:00,  5.33it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:43:20 2021 \n",
      "\n",
      "    Fold:2, Epoch:18, LR:0.0001355157, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3228   |   2.8921\n",
      "\n",
      "    LWLRAP:              0.9456   |   0.8692\n",
      "\n",
      "    Class Loss:          0.8133   |   2.1325\n",
      "\n",
      "    Consistency Loss:    0.5096   |   0.7595\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:19 - Loss:1.3298: 100%|██████████| 113/113 [00:29<00:00,  3.90it/s]\n",
      "Epoch:19 - Loss:3.0486: 100%|██████████| 28/28 [00:06<00:00,  4.22it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:43:56 2021 \n",
      "\n",
      "    Fold:2, Epoch:19, LR:9.54915e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3298   |   3.0486\n",
      "\n",
      "    LWLRAP:              0.9475   |   0.8557\n",
      "\n",
      "    Class Loss:          0.7598   |   2.2742\n",
      "\n",
      "    Consistency Loss:    0.5700   |   0.7744\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:20 - Loss:1.2798: 100%|██████████| 113/113 [00:25<00:00,  4.35it/s]\n",
      "Epoch:20 - Loss:2.6632: 100%|██████████| 28/28 [00:07<00:00,  3.63it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:44:30 2021 \n",
      "\n",
      "    Fold:2, Epoch:20, LR:6.184666e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.2798   |   2.6632\n",
      "\n",
      "    LWLRAP:              0.9490   |   0.8558\n",
      "\n",
      "    Class Loss:          0.7274   |   2.0522\n",
      "\n",
      "    Consistency Loss:    0.5525   |   0.6110\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:21 - Loss:1.2786: 100%|██████████| 113/113 [00:26<00:00,  4.34it/s]\n",
      "Epoch:21 - Loss:2.9054: 100%|██████████| 28/28 [00:08<00:00,  3.48it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:45:04 2021 \n",
      "\n",
      "    Fold:2, Epoch:21, LR:3.511176e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.2786   |   2.9054\n",
      "\n",
      "    LWLRAP:              0.9518   |   0.8629\n",
      "\n",
      "    Class Loss:          0.7475   |   2.1941\n",
      "\n",
      "    Consistency Loss:    0.5311   |   0.7113\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:22 - Loss:1.1412: 100%|██████████| 113/113 [00:25<00:00,  4.44it/s]\n",
      "Epoch:22 - Loss:2.9045: 100%|██████████| 28/28 [00:08<00:00,  3.45it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:45:37 2021 \n",
      "\n",
      "    Fold:2, Epoch:22, LR:1.570842e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1412   |   2.9045\n",
      "\n",
      "    LWLRAP:              0.9634   |   0.8664\n",
      "\n",
      "    Class Loss:          0.6202   |   2.2167\n",
      "\n",
      "    Consistency Loss:    0.5210   |   0.6878\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:23 - Loss:1.2105: 100%|██████████| 113/113 [00:24<00:00,  4.57it/s]\n",
      "Epoch:23 - Loss:2.2894: 100%|██████████| 28/28 [00:06<00:00,  4.37it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:46:09 2021 \n",
      "\n",
      "    Fold:2, Epoch:23, LR:3.942649e-06, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.2105   |   2.2894\n",
      "\n",
      "    LWLRAP:              0.9518   |   0.8836\n",
      "\n",
      "    Class Loss:          0.6548   |   1.6399\n",
      "\n",
      "    Consistency Loss:    0.5557   |   0.6495\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8737160493827161 --> 0.883563492063492\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:24 - Loss:1.3024: 100%|██████████| 113/113 [00:24<00:00,  4.56it/s]\n",
      "Epoch:24 - Loss:2.9333: 100%|██████████| 28/28 [00:08<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:46:42 2021 \n",
      "\n",
      "    Fold:2, Epoch:24, LR:0.0, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3024   |   2.9333\n",
      "\n",
      "    LWLRAP:              0.9514   |   0.8835\n",
      "\n",
      "    Class Loss:          0.7622   |   2.3212\n",
      "\n",
      "    Consistency Loss:    0.5402   |   0.6121\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:0 - Loss:7.3077: 100%|██████████| 113/113 [00:25<00:00,  4.37it/s]\n",
      "Epoch:0 - Loss:6.2200: 100%|██████████| 28/28 [00:07<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:47:17 2021 \n",
      "\n",
      "    Fold:3, Epoch:0, LR:0.0009960574, Cons. Weight: 0.6737946999085467\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                7.3077   |   6.2200\n",
      "\n",
      "    LWLRAP:              0.2839   |   0.4016\n",
      "\n",
      "    Class Loss:          7.2988   |   6.2045\n",
      "\n",
      "    Consistency Loss:    0.0089   |   0.0155\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from -inf --> 0.40160450895560906\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 - Loss:5.4297: 100%|██████████| 113/113 [00:26<00:00,  4.23it/s]\n",
      "Epoch:1 - Loss:5.9913: 100%|██████████| 28/28 [00:06<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:47:52 2021 \n",
      "\n",
      "    Fold:3, Epoch:1, LR:0.0009842916, Cons. Weight: 3.1047958479329627\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                5.4297   |   5.9913\n",
      "\n",
      "    LWLRAP:              0.4719   |   0.5699\n",
      "\n",
      "    Class Loss:          5.3874   |   5.9059\n",
      "\n",
      "    Consistency Loss:    0.0423   |   0.0854\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.40160450895560906 --> 0.5699298724640948\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2 - Loss:4.4774: 100%|██████████| 113/113 [00:25<00:00,  4.50it/s]\n",
      "Epoch:2 - Loss:4.1825: 100%|██████████| 28/28 [00:06<00:00,  4.12it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:48:24 2021 \n",
      "\n",
      "    Fold:3, Epoch:2, LR:0.0009648882, Cons. Weight: 10.836802322189582\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                4.4774   |   4.1825\n",
      "\n",
      "    LWLRAP:              0.6302   |   0.6986\n",
      "\n",
      "    Class Loss:          4.3219   |   3.9468\n",
      "\n",
      "    Consistency Loss:    0.1556   |   0.2357\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.5699298724640948 --> 0.6986462340618065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3 - Loss:3.6891: 100%|██████████| 113/113 [00:25<00:00,  4.38it/s]\n",
      "Epoch:3 - Loss:3.7244: 100%|██████████| 28/28 [00:07<00:00,  3.90it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:48:57 2021 \n",
      "\n",
      "    Fold:3, Epoch:3, LR:0.0009381533, Cons. Weight: 28.650479686019008\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.6891   |   3.7244\n",
      "\n",
      "    LWLRAP:              0.7220   |   0.7552\n",
      "\n",
      "    Class Loss:          3.3393   |   3.2510\n",
      "\n",
      "    Consistency Loss:    0.3497   |   0.4734\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.6986462340618065 --> 0.7552413287641458\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4 - Loss:3.4280: 100%|██████████| 113/113 [00:27<00:00,  4.06it/s]\n",
      "Epoch:4 - Loss:3.9594: 100%|██████████| 28/28 [00:05<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:49:31 2021 \n",
      "\n",
      "    Fold:3, Epoch:4, LR:0.0009045085, Cons. Weight: 57.375342073743276\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.4280   |   3.9594\n",
      "\n",
      "    LWLRAP:              0.7742   |   0.7602\n",
      "\n",
      "    Class Loss:          2.7833   |   3.1317\n",
      "\n",
      "    Consistency Loss:    0.6447   |   0.8277\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.7552413287641458 --> 0.760193542222628\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5 - Loss:3.6112: 100%|██████████| 113/113 [00:27<00:00,  4.08it/s]\n",
      "Epoch:5 - Loss:3.5691: 100%|██████████| 28/28 [00:08<00:00,  3.38it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:50:07 2021 \n",
      "\n",
      "    Fold:3, Epoch:5, LR:0.0008644843, Cons. Weight: 87.03247258333906\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.6112   |   3.5691\n",
      "\n",
      "    LWLRAP:              0.7906   |   0.8079\n",
      "\n",
      "    Class Loss:          2.7576   |   2.6078\n",
      "\n",
      "    Consistency Loss:    0.8535   |   0.9613\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.760193542222628 --> 0.8078637684832375\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6 - Loss:3.3635: 100%|██████████| 113/113 [00:26<00:00,  4.19it/s]\n",
      "Epoch:6 - Loss:4.0546: 100%|██████████| 28/28 [00:09<00:00,  3.01it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:50:44 2021 \n",
      "\n",
      "    Fold:3, Epoch:6, LR:0.000818712, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.3635   |   4.0546\n",
      "\n",
      "    LWLRAP:              0.8115   |   0.8173\n",
      "\n",
      "    Class Loss:          2.5472   |   3.1648\n",
      "\n",
      "    Consistency Loss:    0.8163   |   0.8898\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8078637684832375 --> 0.817270254658147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7 - Loss:2.6319: 100%|██████████| 113/113 [00:25<00:00,  4.39it/s]\n",
      "Epoch:7 - Loss:3.6726: 100%|██████████| 28/28 [00:07<00:00,  3.99it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:51:17 2021 \n",
      "\n",
      "    Fold:3, Epoch:7, LR:0.0007679134, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.6319   |   3.6726\n",
      "\n",
      "    LWLRAP:              0.8621   |   0.8039\n",
      "\n",
      "    Class Loss:          1.8924   |   2.8591\n",
      "\n",
      "    Consistency Loss:    0.7395   |   0.8136\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8 - Loss:2.6721: 100%|██████████| 113/113 [00:24<00:00,  4.68it/s]\n",
      "Epoch:8 - Loss:3.4120: 100%|██████████| 28/28 [00:06<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:51:48 2021 \n",
      "\n",
      "    Fold:3, Epoch:8, LR:0.0007128896, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.6721   |   3.4120\n",
      "\n",
      "    LWLRAP:              0.8589   |   0.8344\n",
      "\n",
      "    Class Loss:          1.8611   |   2.4276\n",
      "\n",
      "    Consistency Loss:    0.8110   |   0.9844\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.817270254658147 --> 0.8344337938567346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9 - Loss:2.4330: 100%|██████████| 113/113 [00:24<00:00,  4.69it/s]\n",
      "Epoch:9 - Loss:3.3730: 100%|██████████| 28/28 [00:05<00:00,  4.80it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:52:18 2021 \n",
      "\n",
      "    Fold:3, Epoch:9, LR:0.0006545085, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.4330   |   3.3730\n",
      "\n",
      "    LWLRAP:              0.8710   |   0.8253\n",
      "\n",
      "    Class Loss:          1.7076   |   2.5424\n",
      "\n",
      "    Consistency Loss:    0.7255   |   0.8306\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:10 - Loss:2.3611: 100%|██████████| 113/113 [00:28<00:00,  4.03it/s]\n",
      "Epoch:10 - Loss:3.4392: 100%|██████████| 28/28 [00:07<00:00,  3.54it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:52:54 2021 \n",
      "\n",
      "    Fold:3, Epoch:10, LR:0.0005936907, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.3611   |   3.4392\n",
      "\n",
      "    LWLRAP:              0.8890   |   0.8290\n",
      "\n",
      "    Class Loss:          1.6413   |   2.5483\n",
      "\n",
      "    Consistency Loss:    0.7198   |   0.8908\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:11 - Loss:2.1930: 100%|██████████| 113/113 [00:27<00:00,  4.11it/s]\n",
      "Epoch:11 - Loss:2.8553: 100%|██████████| 28/28 [00:06<00:00,  4.46it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:53:28 2021 \n",
      "\n",
      "    Fold:3, Epoch:11, LR:0.0005313953, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.1930   |   2.8553\n",
      "\n",
      "    LWLRAP:              0.8948   |   0.8696\n",
      "\n",
      "    Class Loss:          1.5257   |   2.1738\n",
      "\n",
      "    Consistency Loss:    0.6673   |   0.6815\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8344337938567346 --> 0.8696306717973384\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:12 - Loss:1.9033: 100%|██████████| 113/113 [00:25<00:00,  4.49it/s]\n",
      "Epoch:12 - Loss:2.8832: 100%|██████████| 28/28 [00:09<00:00,  3.11it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:54:02 2021 \n",
      "\n",
      "    Fold:3, Epoch:12, LR:0.0004686047, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.9033   |   2.8832\n",
      "\n",
      "    LWLRAP:              0.9146   |   0.8520\n",
      "\n",
      "    Class Loss:          1.2102   |   2.1107\n",
      "\n",
      "    Consistency Loss:    0.6931   |   0.7726\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:13 - Loss:1.7598: 100%|██████████| 113/113 [00:27<00:00,  4.12it/s]\n",
      "Epoch:13 - Loss:3.4577: 100%|██████████| 28/28 [00:08<00:00,  3.41it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:54:38 2021 \n",
      "\n",
      "    Fold:3, Epoch:13, LR:0.0004063093, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.7598   |   3.4577\n",
      "\n",
      "    LWLRAP:              0.9241   |   0.8067\n",
      "\n",
      "    Class Loss:          1.0864   |   2.5647\n",
      "\n",
      "    Consistency Loss:    0.6734   |   0.8930\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:14 - Loss:1.8495: 100%|██████████| 113/113 [00:38<00:00,  2.94it/s]\n",
      "Epoch:14 - Loss:2.9659: 100%|██████████| 28/28 [00:10<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:55:27 2021 \n",
      "\n",
      "    Fold:3, Epoch:14, LR:0.0003454915, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.8495   |   2.9659\n",
      "\n",
      "    LWLRAP:              0.9130   |   0.8735\n",
      "\n",
      "    Class Loss:          1.2034   |   2.2646\n",
      "\n",
      "    Consistency Loss:    0.6461   |   0.7012\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8696306717973384 --> 0.873503861003861\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:15 - Loss:1.8117: 100%|██████████| 113/113 [00:38<00:00,  2.95it/s]\n",
      "Epoch:15 - Loss:2.6682: 100%|██████████| 28/28 [00:05<00:00,  4.68it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:56:12 2021 \n",
      "\n",
      "    Fold:3, Epoch:15, LR:0.0002871104, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.8117   |   2.6682\n",
      "\n",
      "    LWLRAP:              0.9234   |   0.8719\n",
      "\n",
      "    Class Loss:          1.2281   |   1.9023\n",
      "\n",
      "    Consistency Loss:    0.5836   |   0.7659\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:16 - Loss:1.6028: 100%|██████████| 113/113 [00:29<00:00,  3.81it/s]\n",
      "Epoch:16 - Loss:2.8608: 100%|██████████| 28/28 [00:10<00:00,  2.77it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:56:52 2021 \n",
      "\n",
      "    Fold:3, Epoch:16, LR:0.0002320866, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.6028   |   2.8608\n",
      "\n",
      "    LWLRAP:              0.9371   |   0.8499\n",
      "\n",
      "    Class Loss:          0.9927   |   2.1059\n",
      "\n",
      "    Consistency Loss:    0.6102   |   0.7549\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:17 - Loss:1.5178: 100%|██████████| 113/113 [00:37<00:00,  3.00it/s]\n",
      "Epoch:17 - Loss:3.0734: 100%|██████████| 28/28 [00:10<00:00,  2.79it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:57:39 2021 \n",
      "\n",
      "    Fold:3, Epoch:17, LR:0.000181288, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.5178   |   3.0734\n",
      "\n",
      "    LWLRAP:              0.9407   |   0.8651\n",
      "\n",
      "    Class Loss:          0.9294   |   2.3387\n",
      "\n",
      "    Consistency Loss:    0.5885   |   0.7347\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:18 - Loss:1.3465: 100%|██████████| 113/113 [00:38<00:00,  2.91it/s]\n",
      "Epoch:18 - Loss:2.9969: 100%|██████████| 28/28 [00:10<00:00,  2.66it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:58:29 2021 \n",
      "\n",
      "    Fold:3, Epoch:18, LR:0.0001355157, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3465   |   2.9969\n",
      "\n",
      "    LWLRAP:              0.9471   |   0.8511\n",
      "\n",
      "    Class Loss:          0.8181   |   2.2947\n",
      "\n",
      "    Consistency Loss:    0.5284   |   0.7022\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:19 - Loss:1.3088: 100%|██████████| 113/113 [00:38<00:00,  2.92it/s]\n",
      "Epoch:19 - Loss:2.7592: 100%|██████████| 28/28 [00:10<00:00,  2.67it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:59:18 2021 \n",
      "\n",
      "    Fold:3, Epoch:19, LR:9.54915e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3088   |   2.7592\n",
      "\n",
      "    LWLRAP:              0.9521   |   0.8652\n",
      "\n",
      "    Class Loss:          0.7639   |   2.0349\n",
      "\n",
      "    Consistency Loss:    0.5449   |   0.7243\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:20 - Loss:1.1085: 100%|██████████| 113/113 [00:38<00:00,  2.96it/s]\n",
      "Epoch:20 - Loss:2.7645: 100%|██████████| 28/28 [00:09<00:00,  2.95it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:00:06 2021 \n",
      "\n",
      "    Fold:3, Epoch:20, LR:6.184666e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1085   |   2.7645\n",
      "\n",
      "    LWLRAP:              0.9679   |   0.8709\n",
      "\n",
      "    Class Loss:          0.5832   |   2.1178\n",
      "\n",
      "    Consistency Loss:    0.5252   |   0.6467\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:21 - Loss:1.1863: 100%|██████████| 113/113 [00:38<00:00,  2.94it/s]\n",
      "Epoch:21 - Loss:2.8317: 100%|██████████| 28/28 [00:08<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:00:53 2021 \n",
      "\n",
      "    Fold:3, Epoch:21, LR:3.511176e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1863   |   2.8317\n",
      "\n",
      "    LWLRAP:              0.9615   |   0.8804\n",
      "\n",
      "    Class Loss:          0.6499   |   2.2133\n",
      "\n",
      "    Consistency Loss:    0.5364   |   0.6184\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.873503861003861 --> 0.8804431741651473\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:22 - Loss:1.1913: 100%|██████████| 113/113 [00:39<00:00,  2.85it/s]\n",
      "Epoch:22 - Loss:2.5195: 100%|██████████| 28/28 [00:08<00:00,  3.16it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:01:43 2021 \n",
      "\n",
      "    Fold:3, Epoch:22, LR:1.570842e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1913   |   2.5195\n",
      "\n",
      "    LWLRAP:              0.9544   |   0.8842\n",
      "\n",
      "    Class Loss:          0.6655   |   1.9639\n",
      "\n",
      "    Consistency Loss:    0.5258   |   0.5556\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8804431741651473 --> 0.8842021720969089\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:23 - Loss:1.1246: 100%|██████████| 113/113 [00:38<00:00,  2.92it/s]\n",
      "Epoch:23 - Loss:2.5305: 100%|██████████| 28/28 [00:10<00:00,  2.73it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:02:32 2021 \n",
      "\n",
      "    Fold:3, Epoch:23, LR:3.942649e-06, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1246   |   2.5305\n",
      "\n",
      "    LWLRAP:              0.9660   |   0.8788\n",
      "\n",
      "    Class Loss:          0.6035   |   1.9823\n",
      "\n",
      "    Consistency Loss:    0.5211   |   0.5481\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:24 - Loss:1.1020: 100%|██████████| 113/113 [00:36<00:00,  3.09it/s]\n",
      "Epoch:24 - Loss:2.3498: 100%|██████████| 28/28 [00:11<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:03:20 2021 \n",
      "\n",
      "    Fold:3, Epoch:24, LR:0.0, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1020   |   2.3498\n",
      "\n",
      "    LWLRAP:              0.9638   |   0.8943\n",
      "\n",
      "    Class Loss:          0.5563   |   1.7089\n",
      "\n",
      "    Consistency Loss:    0.5457   |   0.6408\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8842021720969089 --> 0.8943145595800462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:0 - Loss:7.5009: 100%|██████████| 113/113 [00:36<00:00,  3.08it/s]\n",
      "Epoch:0 - Loss:6.7987: 100%|██████████| 28/28 [00:10<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:04:10 2021 \n",
      "\n",
      "    Fold:4, Epoch:0, LR:0.0009960574, Cons. Weight: 0.6737946999085467\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                7.5009   |   6.7987\n",
      "\n",
      "    LWLRAP:              0.2619   |   0.3451\n",
      "\n",
      "    Class Loss:          7.4925   |   6.7863\n",
      "\n",
      "    Consistency Loss:    0.0084   |   0.0124\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from -inf --> 0.34514470208231773\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 - Loss:5.7046: 100%|██████████| 113/113 [00:36<00:00,  3.14it/s]\n",
      "Epoch:1 - Loss:5.4286: 100%|██████████| 28/28 [00:10<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:04:57 2021 \n",
      "\n",
      "    Fold:4, Epoch:1, LR:0.0009842916, Cons. Weight: 3.1047958479329627\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                5.7046   |   5.4286\n",
      "\n",
      "    LWLRAP:              0.4302   |   0.5495\n",
      "\n",
      "    Class Loss:          5.6705   |   5.3711\n",
      "\n",
      "    Consistency Loss:    0.0341   |   0.0576\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.34514470208231773 --> 0.5494704136501848\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2 - Loss:5.0033: 100%|██████████| 113/113 [00:37<00:00,  3.05it/s]\n",
      "Epoch:2 - Loss:5.3915: 100%|██████████| 28/28 [00:11<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:05:47 2021 \n",
      "\n",
      "    Fold:4, Epoch:2, LR:0.0009648882, Cons. Weight: 10.836802322189582\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                5.0033   |   5.3915\n",
      "\n",
      "    LWLRAP:              0.5417   |   0.6035\n",
      "\n",
      "    Class Loss:          4.8553   |   5.1186\n",
      "\n",
      "    Consistency Loss:    0.1480   |   0.2730\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.5494704136501848 --> 0.603454466626701\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3 - Loss:4.0606: 100%|██████████| 113/113 [00:35<00:00,  3.19it/s]\n",
      "Epoch:3 - Loss:4.1454: 100%|██████████| 28/28 [00:10<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:06:34 2021 \n",
      "\n",
      "    Fold:4, Epoch:3, LR:0.0009381533, Cons. Weight: 28.650479686019008\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                4.0606   |   4.1454\n",
      "\n",
      "    LWLRAP:              0.6742   |   0.7132\n",
      "\n",
      "    Class Loss:          3.7261   |   3.6962\n",
      "\n",
      "    Consistency Loss:    0.3344   |   0.4492\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.603454466626701 --> 0.7131901727808465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4 - Loss:3.5871: 100%|██████████| 113/113 [00:36<00:00,  3.12it/s]\n",
      "Epoch:4 - Loss:3.7860: 100%|██████████| 28/28 [00:11<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:07:22 2021 \n",
      "\n",
      "    Fold:4, Epoch:4, LR:0.0009045085, Cons. Weight: 57.375342073743276\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.5871   |   3.7860\n",
      "\n",
      "    LWLRAP:              0.7458   |   0.7677\n",
      "\n",
      "    Class Loss:          3.0186   |   3.0715\n",
      "\n",
      "    Consistency Loss:    0.5685   |   0.7144\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.7131901727808465 --> 0.7677194475546629\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5 - Loss:3.4578: 100%|██████████| 113/113 [00:37<00:00,  3.00it/s]\n",
      "Epoch:5 - Loss:3.6995: 100%|██████████| 28/28 [00:11<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:08:12 2021 \n",
      "\n",
      "    Fold:4, Epoch:5, LR:0.0008644843, Cons. Weight: 87.03247258333906\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.4578   |   3.6995\n",
      "\n",
      "    LWLRAP:              0.7774   |   0.8104\n",
      "\n",
      "    Class Loss:          2.7605   |   2.6951\n",
      "\n",
      "    Consistency Loss:    0.6973   |   1.0044\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.7677194475546629 --> 0.8104079014282033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6 - Loss:3.2512: 100%|██████████| 113/113 [00:35<00:00,  3.20it/s]\n",
      "Epoch:6 - Loss:3.8249: 100%|██████████| 28/28 [00:11<00:00,  2.40it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:08:59 2021 \n",
      "\n",
      "    Fold:4, Epoch:6, LR:0.000818712, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.2512   |   3.8249\n",
      "\n",
      "    LWLRAP:              0.8202   |   0.8063\n",
      "\n",
      "    Class Loss:          2.4300   |   2.8050\n",
      "\n",
      "    Consistency Loss:    0.8213   |   1.0200\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7 - Loss:2.9856: 100%|██████████| 113/113 [00:35<00:00,  3.18it/s]\n",
      "Epoch:7 - Loss:3.5295: 100%|██████████| 28/28 [00:12<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:09:47 2021 \n",
      "\n",
      "    Fold:4, Epoch:7, LR:0.0007679134, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.9856   |   3.5295\n",
      "\n",
      "    LWLRAP:              0.8302   |   0.8324\n",
      "\n",
      "    Class Loss:          2.2001   |   2.4473\n",
      "\n",
      "    Consistency Loss:    0.7854   |   1.0822\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8104079014282033 --> 0.8324275749163641\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8 - Loss:2.9603: 100%|██████████| 113/113 [00:35<00:00,  3.14it/s]\n",
      "Epoch:8 - Loss:3.7541: 100%|██████████| 28/28 [00:12<00:00,  2.33it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:10:36 2021 \n",
      "\n",
      "    Fold:4, Epoch:8, LR:0.0007128896, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.9603   |   3.7541\n",
      "\n",
      "    LWLRAP:              0.8371   |   0.8093\n",
      "\n",
      "    Class Loss:          2.0636   |   2.7145\n",
      "\n",
      "    Consistency Loss:    0.8967   |   1.0396\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9 - Loss:2.5489: 100%|██████████| 113/113 [00:35<00:00,  3.19it/s]\n",
      "Epoch:9 - Loss:3.2518: 100%|██████████| 28/28 [00:11<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:11:23 2021 \n",
      "\n",
      "    Fold:4, Epoch:9, LR:0.0006545085, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.5489   |   3.2518\n",
      "\n",
      "    LWLRAP:              0.8675   |   0.8432\n",
      "\n",
      "    Class Loss:          1.8483   |   2.4080\n",
      "\n",
      "    Consistency Loss:    0.7007   |   0.8438\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8324275749163641 --> 0.8432284116028876\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:10 - Loss:2.3518: 100%|██████████| 113/113 [00:36<00:00,  3.12it/s]\n",
      "Epoch:10 - Loss:2.6595: 100%|██████████| 28/28 [00:12<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:12:12 2021 \n",
      "\n",
      "    Fold:4, Epoch:10, LR:0.0005936907, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.3518   |   2.6595\n",
      "\n",
      "    LWLRAP:              0.8869   |   0.8723\n",
      "\n",
      "    Class Loss:          1.6557   |   1.8759\n",
      "\n",
      "    Consistency Loss:    0.6962   |   0.7836\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8432284116028876 --> 0.8722691914972616\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:11 - Loss:2.1836: 100%|██████████| 113/113 [00:35<00:00,  3.17it/s]\n",
      "Epoch:11 - Loss:3.3737: 100%|██████████| 28/28 [00:11<00:00,  2.38it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:13:00 2021 \n",
      "\n",
      "    Fold:4, Epoch:11, LR:0.0005313953, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.1836   |   3.3737\n",
      "\n",
      "    LWLRAP:              0.8899   |   0.8275\n",
      "\n",
      "    Class Loss:          1.4947   |   2.4187\n",
      "\n",
      "    Consistency Loss:    0.6889   |   0.9550\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:12 - Loss:2.0168: 100%|██████████| 113/113 [00:38<00:00,  2.95it/s]\n",
      "Epoch:12 - Loss:3.0310: 100%|██████████| 28/28 [00:11<00:00,  2.47it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:13:50 2021 \n",
      "\n",
      "    Fold:4, Epoch:12, LR:0.0004686047, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.0168   |   3.0310\n",
      "\n",
      "    LWLRAP:              0.9028   |   0.8553\n",
      "\n",
      "    Class Loss:          1.3769   |   2.2607\n",
      "\n",
      "    Consistency Loss:    0.6398   |   0.7703\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:13 - Loss:1.8544: 100%|██████████| 113/113 [00:38<00:00,  2.97it/s]\n",
      "Epoch:13 - Loss:2.6142: 100%|██████████| 28/28 [00:10<00:00,  2.69it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:14:38 2021 \n",
      "\n",
      "    Fold:4, Epoch:13, LR:0.0004063093, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.8544   |   2.6142\n",
      "\n",
      "    LWLRAP:              0.9127   |   0.8678\n",
      "\n",
      "    Class Loss:          1.2360   |   1.7827\n",
      "\n",
      "    Consistency Loss:    0.6184   |   0.8315\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:14 - Loss:1.8256: 100%|██████████| 113/113 [00:37<00:00,  3.04it/s]\n",
      "Epoch:14 - Loss:2.9929: 100%|██████████| 28/28 [00:08<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:15:24 2021 \n",
      "\n",
      "    Fold:4, Epoch:14, LR:0.0003454915, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.8256   |   2.9929\n",
      "\n",
      "    LWLRAP:              0.9164   |   0.8751\n",
      "\n",
      "    Class Loss:          1.2346   |   2.1951\n",
      "\n",
      "    Consistency Loss:    0.5910   |   0.7978\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8722691914972616 --> 0.8751028610899771\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:15 - Loss:1.8849: 100%|██████████| 113/113 [00:40<00:00,  2.82it/s]\n",
      "Epoch:15 - Loss:3.0380: 100%|██████████| 28/28 [00:09<00:00,  2.91it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:16:15 2021 \n",
      "\n",
      "    Fold:4, Epoch:15, LR:0.0002871104, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.8849   |   3.0380\n",
      "\n",
      "    LWLRAP:              0.9161   |   0.8447\n",
      "\n",
      "    Class Loss:          1.2064   |   2.3682\n",
      "\n",
      "    Consistency Loss:    0.6785   |   0.6698\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:16 - Loss:1.6898: 100%|██████████| 113/113 [00:38<00:00,  2.93it/s]\n",
      "Epoch:16 - Loss:2.7242: 100%|██████████| 28/28 [00:10<00:00,  2.77it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:17:04 2021 \n",
      "\n",
      "    Fold:4, Epoch:16, LR:0.0002320866, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.6898   |   2.7242\n",
      "\n",
      "    LWLRAP:              0.9244   |   0.8702\n",
      "\n",
      "    Class Loss:          1.0811   |   1.9770\n",
      "\n",
      "    Consistency Loss:    0.6086   |   0.7472\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:17 - Loss:1.5670: 100%|██████████| 113/113 [00:38<00:00,  2.92it/s]\n",
      "Epoch:17 - Loss:2.3258: 100%|██████████| 28/28 [00:09<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:17:52 2021 \n",
      "\n",
      "    Fold:4, Epoch:17, LR:0.000181288, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.5670   |   2.3258\n",
      "\n",
      "    LWLRAP:              0.9391   |   0.8849\n",
      "\n",
      "    Class Loss:          0.9663   |   1.5966\n",
      "\n",
      "    Consistency Loss:    0.6007   |   0.7292\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8751028610899771 --> 0.8849091701577386\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:18 - Loss:1.5444: 100%|██████████| 113/113 [00:37<00:00,  2.98it/s]\n",
      "Epoch:18 - Loss:2.3729: 100%|██████████| 28/28 [00:09<00:00,  3.04it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:18:40 2021 \n",
      "\n",
      "    Fold:4, Epoch:18, LR:0.0001355157, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.5444   |   2.3729\n",
      "\n",
      "    LWLRAP:              0.9402   |   0.8714\n",
      "\n",
      "    Class Loss:          0.9322   |   1.7763\n",
      "\n",
      "    Consistency Loss:    0.6121   |   0.5966\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:19 - Loss:1.4616: 100%|██████████| 113/113 [00:39<00:00,  2.86it/s]\n",
      "Epoch:19 - Loss:2.5880: 100%|██████████| 28/28 [00:09<00:00,  3.09it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:19:29 2021 \n",
      "\n",
      "    Fold:4, Epoch:19, LR:9.54915e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.4616   |   2.5880\n",
      "\n",
      "    LWLRAP:              0.9386   |   0.8796\n",
      "\n",
      "    Class Loss:          0.9151   |   1.9534\n",
      "\n",
      "    Consistency Loss:    0.5465   |   0.6347\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:20 - Loss:1.3974: 100%|██████████| 113/113 [00:39<00:00,  2.85it/s]\n",
      "Epoch:20 - Loss:2.4684: 100%|██████████| 28/28 [00:08<00:00,  3.20it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:20:17 2021 \n",
      "\n",
      "    Fold:4, Epoch:20, LR:6.184666e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3974   |   2.4684\n",
      "\n",
      "    LWLRAP:              0.9453   |   0.8698\n",
      "\n",
      "    Class Loss:          0.8314   |   1.9199\n",
      "\n",
      "    Consistency Loss:    0.5659   |   0.5485\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:21 - Loss:1.2602: 100%|██████████| 113/113 [00:38<00:00,  2.90it/s]\n",
      "Epoch:21 - Loss:2.4903: 100%|██████████| 28/28 [00:09<00:00,  2.97it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:21:06 2021 \n",
      "\n",
      "    Fold:4, Epoch:21, LR:3.511176e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.2602   |   2.4903\n",
      "\n",
      "    LWLRAP:              0.9524   |   0.8799\n",
      "\n",
      "    Class Loss:          0.7575   |   1.9461\n",
      "\n",
      "    Consistency Loss:    0.5027   |   0.5443\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:22 - Loss:1.1955: 100%|██████████| 113/113 [00:37<00:00,  2.97it/s]\n",
      "Epoch:22 - Loss:2.7956: 100%|██████████| 28/28 [00:10<00:00,  2.76it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:21:54 2021 \n",
      "\n",
      "    Fold:4, Epoch:22, LR:1.570842e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1955   |   2.7956\n",
      "\n",
      "    LWLRAP:              0.9585   |   0.8457\n",
      "\n",
      "    Class Loss:          0.7010   |   2.1003\n",
      "\n",
      "    Consistency Loss:    0.4945   |   0.6953\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:23 - Loss:1.2059: 100%|██████████| 113/113 [00:36<00:00,  3.12it/s]\n",
      "Epoch:23 - Loss:2.6588: 100%|██████████| 28/28 [00:10<00:00,  2.79it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:22:40 2021 \n",
      "\n",
      "    Fold:4, Epoch:23, LR:3.942649e-06, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.2059   |   2.6588\n",
      "\n",
      "    LWLRAP:              0.9522   |   0.8618\n",
      "\n",
      "    Class Loss:          0.6990   |   2.0138\n",
      "\n",
      "    Consistency Loss:    0.5070   |   0.6450\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:24 - Loss:1.3621: 100%|██████████| 113/113 [00:37<00:00,  3.03it/s]\n",
      "Epoch:24 - Loss:2.4847: 100%|██████████| 28/28 [00:09<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:23:27 2021 \n",
      "\n",
      "    Fold:4, Epoch:24, LR:0.0, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3621   |   2.4847\n",
      "\n",
      "    LWLRAP:              0.9431   |   0.8769\n",
      "\n",
      "    Class Loss:          0.8258   |   1.8885\n",
      "\n",
      "    Consistency Loss:    0.5363   |   0.5962\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train(df, fold):\n",
    "    train_df = df[df.fold != fold]\n",
    "    val_df = df[df.fold == fold]\n",
    "    train_loader = get_data_loader(train_df)\n",
    "    val_loader = get_data_loader(val_df)\n",
    "\n",
    "    student_model = get_model()\n",
    "    teacher_model = get_model(is_mean_teacher=True)\n",
    "\n",
    "#     optimizer = Ranger(student_model.parameters(),\n",
    "#                lr=config.lr,\n",
    "#                k=4,\n",
    "#                betas=(.9, 0.999), weight_decay=0)\n",
    "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=config.lr)\n",
    "    num_train_steps = int(len(train_loader) * config.epochs)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=num_train_steps)\n",
    "    criterion = MeanTeacherLoss()\n",
    "\n",
    "    best_val_metric = -np.inf\n",
    "    val_metrics = []\n",
    "    train_metrics = []\n",
    "    for epoch in range(0, config.epochs):\n",
    "        train_loss_metrics = train_one_epoch(\n",
    "            student_model, teacher_model, train_loader, \n",
    "            criterion, optimizer, scheduler, epoch)\n",
    "        val_loss_metrics = train_one_epoch(\n",
    "            student_model, teacher_model, val_loader, \n",
    "            criterion, optimizer, scheduler, epoch, is_val=True)\n",
    "\n",
    "        train_metrics.append(train_loss_metrics)\n",
    "        val_metrics.append(val_loss_metrics)\n",
    "        pretty_print_metrics(fold, epoch, optimizer, \n",
    "                             train_loss_metrics, val_loss_metrics)\n",
    "        \n",
    "        if val_loss_metrics['lwlrap'] > best_val_metric:\n",
    "            print(f\"    LWLRAP Improved from {best_val_metric} --> {val_loss_metrics['lwlrap']}\\n\")\n",
    "            best_val_metric = val_loss_metrics['lwlrap']\n",
    "            \n",
    "            torch.save(teacher_model.state_dict(), \n",
    "                       os.path.join(config.save_path, f'fold-{fold}_{best_val_metric:.3f}.bin'))\n",
    "    \n",
    "\n",
    "\n",
    "df = get_n_fold_df(config.train_tp_csv)\n",
    "for fold in range(5 if config.train_5_folds else 1):\n",
    "    train(df, fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test Set\n",
    "We'll predict using the teacher model but you could also use the student or a combination of the two. Inference works just like it would for a vanilla baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [01:47<00:00, 18.54it/s]\n",
      "100%|██████████| 1992/1992 [01:40<00:00, 19.83it/s]\n",
      "100%|██████████| 1992/1992 [01:41<00:00, 19.55it/s]\n",
      "100%|██████████| 1992/1992 [01:42<00:00, 19.39it/s]\n",
      "100%|██████████| 1992/1992 [01:42<00:00, 19.40it/s]\n"
     ]
    }
   ],
   "source": [
    "def test(test_df, train_fold):\n",
    "    test_dataset = TestDataset(\n",
    "        df=test_df,\n",
    "        data_path=\"/media/paniquex/samsung_2tb/rfcx_kaggle/rfcx-species-audio-detection/test\",\n",
    "        period=config.period_val,\n",
    "        step=config.step\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=config.num_workers\n",
    "    )\n",
    "    \n",
    "    weights_path = os.path.join(config.save_path, f'fold-{train_fold}.bin')\n",
    "    model = get_model()\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=config.device), strict=False)\n",
    "    \n",
    "    test_pred, ids = predict_on_test(model, test_loader)\n",
    "\n",
    "    # Build Submission File\n",
    "    test_pred_df = pd.DataFrame({\n",
    "        \"recording_id\": test_df.recording_id.values\n",
    "    })\n",
    "    target_cols = test_df.columns[1:].values.tolist()\n",
    "    test_pred_df = test_pred_df.join(pd.DataFrame(np.array(test_pred), \n",
    "                                                  columns=target_cols))\n",
    "    test_pred_df.to_csv(os.path.join(config.save_path, \n",
    "                                     f\"fold-{train_fold}-submission.csv\"), \n",
    "                        index=False)\n",
    "    \n",
    "    \n",
    "test_df = pd.read_csv(config.test_csv)\n",
    "for fold in range(5 if config.train_5_folds else 1):\n",
    "    test(test_df, fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Fold Ensemble\n",
    "For 5 fold runs, we'll create a single ensemble prediction by simply averaging all of the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(submission_path):\n",
    "    dfs = [pd.read_csv(os.path.join(\n",
    "        config.save_path, f\"fold-{i}-submission.csv\")) for i in range(5)]\n",
    "    anchor = dfs[0].copy()\n",
    "    cols = anchor.columns[1:]\n",
    "   \n",
    "    for c in cols:\n",
    "        total = 0\n",
    "        for df in dfs:\n",
    "            total += df[c]\n",
    "        anchor[c] = total / len(dfs)\n",
    "    anchor.to_csv(submission_path, index=False)\n",
    "\n",
    "\n",
    "submission_path = os.path.join(config.save_path, f\"submission.csv\")\n",
    "if config.train_5_folds:\n",
    "    ensemble(submission_path)\n",
    "else:\n",
    "    fold0_submission = os.path.join(config.save_path, f\"fold-0-submission.csv\")\n",
    "    os.rename(fold0_submission, submission_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "Thanks for reading! I dropped some unrelated tricks from this and didn't spend much time tuning so there's almost definetely room for improvement.\n",
    "\n",
    "I know it's pretty late in the competition for new notebooks, but considering that there are a few other public notebooks that score higher, I'm hoping this won't cause a significant shakeup. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
