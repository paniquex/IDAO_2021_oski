{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "I wanted to share something that worked pretty well for me early on in this competition. The idea comes from a [2018 paper](https://arxiv.org/pdf/1703.01780.pdf) titled *Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results* by Antti Tarvainen and Harri Valpola. \n",
    "\n",
    "### Mean Teacher\n",
    "Biefly, the idea is to use two models. A student model with weights trained the standard way, using backprop. And a teacher model with weights that are an exponential moving average of the student's weights. The teacher is the *mean* of the student \\*ba dum tss\\*. The student is then trained using two different losses, a standard classification loss and a consistency loss that penalizes student predictions that deviate from the teaher's. \n",
    "\n",
    "![](https://raw.githubusercontent.com/CuriousAI/mean-teacher/master/mean_teacher.png)\n",
    "\n",
    "Mean teachers are useful in a semi-supervised context where we have both labeled and unlabeled samples. The consistency loss on the unlabeled samples acts as a form of regularization and helps the model generalize better. As an added bonus the final teacher model is a temporal ensemble which tends to perform better than the results at the end of a single epoch. \n",
    "\n",
    "### Missing Labels\n",
    "As a few others have pointed out, there are a lot of missing labels. If we were to randomly sample a segment from the training data, we might consider it completely unlabeled rather than rely on the provided labels. We'll train our mean teacher model(s) on two classes of data, carefully selected positive samples and randomly selected unlabeled samples. The classification loss won't apply to the unlabeled samples. \n",
    "\n",
    "![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F4704212%2F9ca088bb386abf7114543c019c1d8a5f%2Ffig.png?generation=1609892974092435&alt=media)\n",
    "\n",
    "*Thanks to [shinmura0](https://www.kaggle.com/shinmurashinmura) for the great visualization!*\n",
    "\n",
    "### Results\n",
    "For me, mean teacher worked a good bit better than baseline models with similar configurations. \n",
    "\n",
    "|                                         | Baseline | Mean Teacher |\n",
    "|-----------------------------------------|----------|--------------|\n",
    "| Well Tuned, 5 fold, from my local setup | 0.847        | **0.865**            |\n",
    "| Single fold Expt1 on Kaggle                   | 0.592**        | **0.786**            |\n",
    "| Single fold Expt2 on Kaggle                   | 0.826        | **0.830**            |\n",
    "| 5 Fold on Kaggle***                        | 0.844        | **0.857**           |\n",
    "\n",
    "\\*\\* I might have accidentally sabatoged this run.\n",
    "\n",
    "\\*\\*\\* There was a major bug in v21 of the notebook where the consistence_ramp was set to 1000 which means it was just normal / non-mean-teacher training. Setting consisteny_ramp to 6 and using the mean teacher, we get an improvement of 0.13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "!pip -q install --upgrade pip\n",
    "!pip -q install timm\n",
    "!pip -q install torchlibrosa\n",
    "!pip -q install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "import audiomentations as A\n",
    "import os, time, librosa, random\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from timm.models import resnet34d, resnest26d, resnest50d\n",
    "from timm.models.efficientnet import tf_efficientnet_b4_ns, tf_efficientnet_b3_ns, \\\n",
    "    tf_efficientnet_b5_ns, tf_efficientnet_b2_ns, tf_efficientnet_b6_ns, tf_efficientnet_b7_ns, tf_efficientnet_b0_ns, tf_efficientnet_b1_ns\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "from contextlib import nullcontext\n",
    "\n",
    "\n",
    "from ranger import Ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixUp(nn.Module):\n",
    "    def __init__(self, prob=0.33, alpha=8, mixup_mode=\"basic\"):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.prob = prob\n",
    "        self.mixup_mode = mixup_mode\n",
    "        \n",
    "    def forward(self, waveforms, labels):\n",
    "        inds = np.arange(waveforms.shape[0])\n",
    "        new_inds = inds.copy()\n",
    "        np.random.shuffle(new_inds)\n",
    "        aug_count = int(inds[inds != new_inds].shape[0] * self.prob)\n",
    "        to_augment = np.random.choice(inds[inds != new_inds], aug_count, replace=False)\n",
    "        betas = torch.tensor(np.random.beta(self.alpha, self.alpha, size=aug_count),\n",
    "                             dtype=torch.float).unsqueeze(1).to(waveforms.device)\n",
    "        # new_inds = torch.tensor(new_inds)\n",
    "        # to_augment = torch.tensor(to_augment)\n",
    "        waveforms[to_augment] = betas * waveforms[to_augment] + (1 - betas) * waveforms[new_inds][to_augment]\n",
    "        if self.mixup_mode == \"basic\":\n",
    "            labels[to_augment] = betas * labels[to_augment] + (1 - betas) * labels[new_inds][to_augment]\n",
    "        elif self.mixup_mode == \"or\":\n",
    "            labels[to_augment] = torch.clamp_max(labels[to_augment] + labels[new_inds][to_augment], max=1.)\n",
    "        return waveforms, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config\n",
    "We'll start by setting up some global config variable that we'll access later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Global Vars\n",
    "NO_LABEL = -1\n",
    "NUM_CLASSES = 24\n",
    "\n",
    "LOSS_TYPE = \"LSEP\"\n",
    "\n",
    "class config:\n",
    "    seed = 42\n",
    "    device = \"cuda:1\"\n",
    "    \n",
    "    train_tp_csv = '/media/paniquex/samsung_2tb/rfcx_kaggle/rfcx-species-audio-detection/train_tp.csv'\n",
    "    test_csv = '/media/paniquex/samsung_2tb/rfcx_kaggle/rfcx-species-audio-detection/sample_submission.csv'\n",
    "    save_path = '../experiments/mean_teacher_mels=224_LSEP_eff_b0_adamw_period=3_val=2_encoder_percent_unlabeled=1.0_consistency_weight=50_consistency_rampup=6_ema_decay=0.995'\n",
    "    \n",
    "    encoder = tf_efficientnet_b0_ns\n",
    "    encoder_features = 1280\n",
    "    \n",
    "    percent_unlabeled = 1.0\n",
    "    consistency_weight = 100.0\n",
    "    consistency_rampup = 6\n",
    "    \n",
    "    ema_decay = 0.995\n",
    "    positive_weight = 2.0\n",
    "    \n",
    "    lr = 1e-3\n",
    "    epochs = 30\n",
    "    batch_size = 16\n",
    "    num_workers = 8\n",
    "    train_5_folds = True\n",
    "    \n",
    "    period = 3 # 6 second clips\n",
    "    period_val = 2\n",
    "\n",
    "    \n",
    "    step = 1\n",
    "    model_params = {\n",
    "        'sample_rate': 48000,\n",
    "        'window_size': 2048,\n",
    "        'hop_size': 345,\n",
    "        'mel_bins': 224,\n",
    "        'fmin': 20,\n",
    "        'fmax': 48000 // 2,\n",
    "        'classes_num': NUM_CLASSES,\n",
    "        'mixup_module': None\n",
    "    }\n",
    "    \n",
    "    augmenter = A.Compose([\n",
    "        A.AddGaussianNoise(p=0.33, max_amplitude=0.02),\n",
    "        A.AddGaussianSNR(p=0.33),\n",
    "        A.FrequencyMask(min_frequency_band=0.01,  max_frequency_band=0.25, p=0.33),\n",
    "        A.TimeMask(min_band_part=0.01, max_band_part=0.25, p=0.33),\n",
    "        A.Gain(p=0.33)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(config.save_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(config.save_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "## Utils - Not much interesting going on here.\n",
    "\n",
    "def get_n_fold_df(csv_path, folds=5):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df_group = df.groupby(\"recording_id\")[[\"species_id\"]].first().reset_index()\n",
    "    df_group = df_group.sample(frac=1, random_state=config.seed).reset_index(drop=True)\n",
    "    df_group.loc[:, 'fold'] = -1\n",
    "\n",
    "    X = df_group[\"recording_id\"].values\n",
    "    y = df_group[\"species_id\"].values\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=folds, random_state=config.seed)\n",
    "    for fold, (t_idx, v_idx) in enumerate(kfold.split(X, y)):\n",
    "        df_group.loc[v_idx, \"fold\"] = fold\n",
    "\n",
    "    return df.merge(df_group[['recording_id', 'fold']], on=\"recording_id\", how=\"left\")\n",
    "    \n",
    "\n",
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def sigmoid_rampup(current, rampup_length):\n",
    "    \"\"\"Exponential rampup from https://arxiv.org/abs/1610.02242\"\"\"\n",
    "    if rampup_length == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        current = np.clip(current, 0.0, rampup_length)\n",
    "        phase = 1.0 - current / rampup_length\n",
    "        return float(np.exp(-5.0 * phase * phase))\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class MetricMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.y_true = []\n",
    "        self.y_pred = []\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        try:\n",
    "            self.y_true.extend(y_true.detach().cpu().numpy().tolist())\n",
    "            self.y_pred.extend(torch.sigmoid(y_pred).cpu().detach().numpy().tolist())\n",
    "        except:\n",
    "            print(\"UPDATE FAILURE\")\n",
    "\n",
    "    def update_list(self, y_true, y_pred):\n",
    "        self.y_true.extend(y_true)\n",
    "        self.y_pred.extend(y_pred)\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        score_class, weight = lwlrap(np.array(self.y_true), np.array(self.y_pred))\n",
    "        self.score = (score_class * weight).sum()\n",
    "\n",
    "        return self.score\n",
    "    \n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "\n",
    "def lwlrap(truth, scores):\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = _one_sample_positive_class_precisions(scores[sample_num, :],\n",
    "                                                                                     truth[sample_num, :])\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = precision_at_hits\n",
    "\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    return per_class_lwlrap, weight_per_class\n",
    "\n",
    "\n",
    "def pretty_print_metrics(fold, epoch, optimizer, train_loss_metrics, val_loss_metrics):\n",
    "    print(f\"\"\"\n",
    "    {time.ctime()} \\n\n",
    "    Fold:{fold}, Epoch:{epoch}, LR:{optimizer.param_groups[0]['lr']:.7}, Cons. Weight: {train_loss_metrics['consistency_weight']}\\n\n",
    "    --------------------------------------------------------\n",
    "    Metric:              Train    |   Val\n",
    "    --------------------------------------------------------\n",
    "    Loss:                {train_loss_metrics['loss']:0.4f}   |   {val_loss_metrics['loss']:0.4f}\\n\n",
    "    LWLRAP:              {train_loss_metrics['lwlrap']:0.4f}   |   {val_loss_metrics['lwlrap']:0.4f}\\n\n",
    "    Class Loss:          {train_loss_metrics['class_loss']:0.4f}   |   {val_loss_metrics['class_loss']:0.4f}\\n\n",
    "    Consistency Loss:    {train_loss_metrics['consistency_loss']:0.4f}   |   {val_loss_metrics['consistency_loss']:0.4f}\\n\n",
    "    --------------------------------------------------------\\n\n",
    "    \"\"\")\n",
    "    \n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, data_path, period=10, step=1):\n",
    "        self.data_path = data_path\n",
    "        self.period = period\n",
    "        self.step = step\n",
    "        self.recording_ids = list(df[\"recording_id\"].unique())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.recording_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        recording_id = self.recording_ids[idx]\n",
    "\n",
    "        y, sr = sf.read(f\"{self.data_path}/{recording_id}.flac\")\n",
    "\n",
    "        len_y = len(y)\n",
    "        effective_length = sr * self.period\n",
    "        effective_step = sr * self.step\n",
    "\n",
    "        y_ = []\n",
    "        i = 0\n",
    "        while i+effective_length <= len_y:\n",
    "            y__ = y[i:i + effective_length]\n",
    "\n",
    "            y_.append(y__)\n",
    "            i = i + effective_step\n",
    "\n",
    "        y = np.stack(y_)\n",
    "\n",
    "        label = np.zeros(NUM_CLASSES, dtype='f')\n",
    "\n",
    "        return {\n",
    "            \"waveform\": y,\n",
    "            \"target\": torch.tensor(label, dtype=torch.float),\n",
    "            \"id\": recording_id\n",
    "        }\n",
    "\n",
    "\n",
    "def predict_on_test(model, test_loader):\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    id_list = []\n",
    "    with torch.no_grad():\n",
    "        t = tqdm(test_loader)\n",
    "        for i, sample in enumerate(t):\n",
    "            input = sample[\"waveform\"].to(config.device)\n",
    "            bs, seq, w = input.shape\n",
    "            input = input.reshape(bs * seq, w)\n",
    "            id = sample[\"id\"]\n",
    "            output, _ = model(input)\n",
    "            output = output.reshape(bs, seq, -1)\n",
    "            output, _ = torch.max(output, dim=1)\n",
    "            \n",
    "            output = output.cpu().detach().numpy().tolist()\n",
    "            pred_list.extend(output)\n",
    "            id_list.extend(id)\n",
    "\n",
    "    return pred_list, id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "The model should look pretty familiar if you're using [SED](https://arxiv.org/abs/1912.04761). (Huge thanks to [Hidehisa Arai](https://www.kaggle.com/hidehisaarai1213) and their [SED Notebook](https://www.kaggle.com/hidehisaarai1213/introduction-to-sound-event-detection)!) You could use any model you'd like here. There's just one small tweak we need to make for our mean teacher setup. We need to \"detach\" the teacher's parameters so they aren't updated by the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class SEDAudioClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, sample_rate, window_size, hop_size, \n",
    "                 mel_bins, fmin, fmax, classes_num, mixup_module=None):\n",
    "        super().__init__()\n",
    "        self.interpolate_ratio = 32\n",
    "\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, \n",
    "                                                 hop_length=hop_size,\n",
    "                                                 win_length=window_size, \n",
    "                                                 window='hann', center=True,\n",
    "                                                 pad_mode='reflect', \n",
    "                                                 freeze_parameters=True)\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size,\n",
    "                                                 n_mels=mel_bins, fmin=fmin, \n",
    "                                                 fmax=fmax, ref=1.0, \n",
    "                                                 amin=1e-10, top_db=None, \n",
    "                                                 freeze_parameters=True)\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm2d(mel_bins)\n",
    "        self.encoder = partial(config.encoder, pretrained=True, in_chans=1)()\n",
    "        self.fc = nn.Linear(config.encoder_features, \n",
    "                            config.encoder_features, bias=True)\n",
    "        self.att_head = AttBlockV2(config.encoder_features, classes_num)\n",
    "        self.avg_pool = nn.modules.pooling.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.mixup_module = mixup_module\n",
    "        \n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.batch_norm)\n",
    "        init_layer(self.fc)\n",
    "        self.att_head.init_weights()\n",
    "\n",
    "    def forward(self, input, labels=None, spec_aug=False, return_encoding=False):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if self.mixup_module and labels is not None:\n",
    "                input, labels = self.mixup_module(input, labels)\n",
    "        \n",
    "        x = self.spectrogram_extractor(input.float())\n",
    "        x = self.logmel_extractor(x)\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.batch_norm(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        x = self.encoder.forward_features(x)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "#         print(x.shape)\n",
    "        x = F.relu_(self.fc(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_head(x)\n",
    "        logit = torch.sum(norm_att * self.att_head.cla(x), dim=2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        framewise_output = interpolate(segmentwise_output, self.interpolate_ratio)\n",
    "        if labels is not None:\n",
    "            return clipwise_output, framewise_output, logit, labels\n",
    "        else:\n",
    "            return clipwise_output, framewise_output, labels\n",
    "\n",
    "\n",
    "def get_model(is_mean_teacher=False):\n",
    "    model = SEDAudioClassifier(**config.model_params)\n",
    "    model = model.to(config.device)\n",
    "    \n",
    "    # Detach params for Exponential Moving Average Model (aka the Mean Teacher).\n",
    "    # We'll manually update these params instead of using backprop.\n",
    "    if is_mean_teacher:\n",
    "        for param in model.parameters():\n",
    "            param.detach_()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "The loss function has 2 components:\n",
    "\n",
    "1. A classification loss that only applies to labeled samples.\n",
    "2. A consistency loss that applies to all samples. \n",
    "\n",
    "For the consistency loss we'll use the mean square error between the student and teacher predictions. We'll slowly ramp up the influence of the consistency loss since we don't want bad, early predictions having too much influence. \n",
    "\n",
    "Notice that we're weighting the positive samples for the classification loss. This is because we know the positives are correct while we're less sure about the negatives due to the missing labels issue. I found that this works better in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedPANNsLoss(nn.Module):\n",
    "    def __init__(self, pos_weight, weights=[1, 0.5]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.normal_loss = nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
    "\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, input, framewise_output, target):\n",
    "        input_ = input\n",
    "        target = target.float()\n",
    "\n",
    "        clipwise_output_with_max, _ = framewise_output.max(dim=1)\n",
    "\n",
    "        normal_loss = self.normal_loss(input_, target)\n",
    "        auxiliary_loss = self.bce(clipwise_output_with_max, target)\n",
    "\n",
    "        return self.weights[0] * normal_loss + self.weights[1] * auxiliary_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_mse_loss(input_logits, target_logits):\n",
    "    assert input_logits.size() == target_logits.size()\n",
    "    input_softmax = torch.sigmoid(input_logits)\n",
    "    target_softmax = torch.sigmoid(target_logits)\n",
    "    num_classes = input_logits.size()[1]\n",
    "    return F.mse_loss(input_softmax, target_softmax, size_average=False\n",
    "                     ) / num_classes\n",
    "\n",
    "def lsep_loss_stable(input, target, average=True):\n",
    "\n",
    "    n = input.size(0)\n",
    "\n",
    "    differences = input.unsqueeze(1) - input.unsqueeze(2)\n",
    "    where_lower = (target.unsqueeze(1) < target.unsqueeze(2)).float()\n",
    "\n",
    "    differences = differences.view(n, -1)\n",
    "    where_lower = where_lower.view(n, -1)\n",
    "\n",
    "    max_difference, index = torch.max(differences, dim=1, keepdim=True)\n",
    "    differences = differences - max_difference\n",
    "    exps = differences.exp() * where_lower\n",
    "\n",
    "    lsep = max_difference + torch.log(torch.exp(-max_difference) + exps.sum(-1))\n",
    "\n",
    "    if average:\n",
    "        return lsep.mean()\n",
    "    else:\n",
    "        return lsep\n",
    "\n",
    "\n",
    "class MeanTeacherLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.positive_weight = torch.ones(\n",
    "            NUM_CLASSES).to(config.device) * config.positive_weight\n",
    "        self.class_criterion = nn.BCEWithLogitsLoss(\n",
    "            reduction='none', pos_weight=self.positive_weight)\n",
    "        self.consistency_criterion = sigmoid_mse_loss\n",
    "\n",
    "    def make_safe(self, pred):\n",
    "        pred = torch.where(torch.isnan(pred), torch.zeros_like(pred), pred)\n",
    "        return torch.where(torch.isinf(pred), torch.zeros_like(pred), pred)\n",
    "        \n",
    "    def get_consistency_weight(self, epoch):\n",
    "        # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
    "        return config.consistency_weight * sigmoid_rampup(\n",
    "            epoch, config.consistency_rampup)\n",
    "    \n",
    "    def forward(self, student_pred, teacher_pred, target, classif_weights, epoch):\n",
    "        student_pred = self.make_safe(student_pred)\n",
    "        teacher_pred = self.make_safe(teacher_pred).detach().data\n",
    "\n",
    "        batch_size = len(target)\n",
    "        labeled_batch_size = target.ne(NO_LABEL).all(axis=1).sum().item() + 1e-3\n",
    "\n",
    "        student_classif, student_consistency = student_pred, student_pred\n",
    "        student_class_loss = (self.class_criterion(\n",
    "            student_classif, target) * classif_weights / labeled_batch_size).sum()\n",
    "\n",
    "        consistency_weights = self.get_consistency_weight(epoch)\n",
    "        consistency_loss = consistency_weights * self.consistency_criterion(\n",
    "            student_consistency, teacher_pred) / batch_size\n",
    "        loss = student_class_loss + consistency_loss\n",
    "        return loss, student_class_loss, consistency_loss, consistency_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader\n",
    "The data loader produces two types of samples:\n",
    "\n",
    "1. Labeled samples with the audio centered in the clip.\n",
    "2. Random unlabeled clips without labels selected from files with at least one true positive label.\n",
    "\n",
    "Each sample contains 2 different inputs, one for the student and one for the teacher. Different augmentations are applied to each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanTeacherDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transforms, period=5, \n",
    "                 data_path=\"/media/paniquex/samsung_2tb/rfcx_kaggle/rfcx-species-audio-detection/train\", \n",
    "                 val=False, percent_unlabeled=0.0):\n",
    "        self.period = period\n",
    "        self.transforms = transforms\n",
    "        self.data_path = data_path\n",
    "        self.val = val\n",
    "        self.percent_unlabeled = percent_unlabeled\n",
    "\n",
    "        dfgby = df.groupby(\"recording_id\").agg(lambda x: list(x)).reset_index()\n",
    "        self.recording_ids = dfgby[\"recording_id\"].values\n",
    "        self.species_ids = dfgby[\"species_id\"].values\n",
    "        self.t_mins = dfgby[\"t_min\"].values\n",
    "        self.t_maxs = dfgby[\"t_max\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.recording_ids) * (1 + self.percent_unlabeled))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.recording_ids):\n",
    "            audio, label, rec_id, sr = self.get_unlabeled_item(idx)\n",
    "            # For unlabeled samples, we zero out the classification loss.\n",
    "            classif_weights = np.zeros(NUM_CLASSES, dtype='f')\n",
    "        else:\n",
    "            audio, label, rec_id, sr = self.get_labeled_item(idx)\n",
    "            classif_weights = np.ones(NUM_CLASSES, dtype='f')\n",
    "\n",
    "        audio_teacher = np.copy(audio)\n",
    "\n",
    "        # The 2 samples fed to the 2 models have should have different augmentations.\n",
    "        audio = self.transforms(samples=audio, sample_rate=sr)\n",
    "        audio_teacher = self.transforms(samples=audio_teacher, sample_rate=sr)\n",
    "        # assert (audio != audio_teacher).any()\n",
    "        \n",
    "        return {\n",
    "            \"waveform\": audio,\n",
    "            \"teacher_waveform\": audio_teacher,\n",
    "            \"target\": torch.tensor(label, dtype=torch.float),\n",
    "            \"classification_weights\": classif_weights,\n",
    "            \"id\": rec_id\n",
    "        }\n",
    "\n",
    "    def get_labeled_item(self, idx):\n",
    "        recording_id = self.recording_ids[idx]\n",
    "        species_id = self.species_ids[idx]\n",
    "        t_min, t_max = self.t_mins[idx], self.t_maxs[idx]\n",
    "\n",
    "        rec, sr = sf.read(f\"{self.data_path}/{recording_id}.flac\")\n",
    "\n",
    "        len_rec = len(rec)\n",
    "        effective_length = sr * self.period\n",
    "        rint = np.random.randint(len(t_min))\n",
    "        tmin, tmax = round(sr * t_min[rint]), round(sr * t_max[rint])\n",
    "        dur = tmax - tmin\n",
    "        min_dur = min(dur, round(sr * self.period))\n",
    "\n",
    "        center = round((tmin + tmax) / 2)\n",
    "        rand_start = center - effective_length + max(min_dur - dur//2, 0)\n",
    "        if rand_start < 0:\n",
    "            rand_start = 0\n",
    "        rand_end = center - max(min_dur - dur//2, 0)\n",
    "        start = np.random.randint(rand_start, rand_end)\n",
    "        rec = rec[start:start + effective_length]\n",
    "        if len(rec) < effective_length:\n",
    "            new_rec = np.zeros(effective_length, dtype=rec.dtype)\n",
    "            start1 = np.random.randint(effective_length - len(rec))\n",
    "            new_rec[start1:start1 + len(rec)] = rec\n",
    "            rec = new_rec.astype(np.float32)\n",
    "        else:\n",
    "            rec = rec.astype(np.float32)\n",
    "\n",
    "        start_time = start / sr\n",
    "        end_time = (start + effective_length) / sr\n",
    "\n",
    "        label = np.zeros(NUM_CLASSES, dtype='f')\n",
    "\n",
    "        for i in range(len(t_min)):\n",
    "            if (t_min[i] >= start_time) & (t_max[i] <= end_time):\n",
    "                label[species_id[i]] = 1\n",
    "            elif start_time <= ((t_min[i] + t_max[i]) / 2) <= end_time:\n",
    "                label[species_id[i]] = 1\n",
    "\n",
    "        return rec, label, recording_id, sr\n",
    "\n",
    "    def get_unlabeled_item(self, idx, random_sample=False):\n",
    "        real_idx = idx - len(self.recording_ids)\n",
    "        # We want our validation set to be fixed.\n",
    "        if self.val:\n",
    "            rec_id = self.recording_ids[real_idx]\n",
    "        else:\n",
    "            rec_id = random.sample(list(self.recording_ids), 1)[0]\n",
    "\n",
    "        rec, sr = sf.read(f\"{self.data_path}/{rec_id}.flac\")\n",
    "        effective_length = int(sr * self.period)\n",
    "        max_end = len(rec) - effective_length\n",
    "        if self.val:\n",
    "            # Fixed start for validation. Probaably a better way to do this.\n",
    "            start = int(idx * 16963 % max_end)\n",
    "        else:\n",
    "            start = np.random.randint(0, max_end)\n",
    "        rec = rec[start:(start+effective_length)]\n",
    "        rec = rec.astype(np.float32)\n",
    "\n",
    "        label = np.ones(NUM_CLASSES, dtype='f') * NO_LABEL\n",
    "\n",
    "        return rec, label, rec_id, sr\n",
    "\n",
    "    \n",
    "def get_data_loader(df, is_val=False):\n",
    "    if is_val:\n",
    "        period = config.period_val\n",
    "    else:\n",
    "        period = config.period\n",
    "    dataset = MeanTeacherDataset(\n",
    "        df=df,\n",
    "        transforms=config.augmenter,\n",
    "        period=period,\n",
    "        percent_unlabeled=config.percent_unlabeled\n",
    "    )\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=not is_val,\n",
    "        drop_last=not is_val,\n",
    "        num_workers=config.num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "At the end of each training step we update the teacher weights by averaging in the latest student weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update teacher to be exponential moving average of student params.\n",
    "def update_teacher_params(student, teacher, alpha, global_step):\n",
    "    # Use the true average until the exponential average is more correct\n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    for ema_param, param in zip(teacher.parameters(), student.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n",
    "\n",
    "\n",
    "def train_one_epoch(student, mean_teacher, loader, \n",
    "                    criterion, optimizer, scheduler, epoch, is_val=False):\n",
    "    global_step = 0\n",
    "    losses = AverageMeter()\n",
    "    consistency_loss_avg = AverageMeter()\n",
    "    class_loss_avg = AverageMeter()\n",
    "    comp_metric = MetricMeter()\n",
    "    \n",
    "    if is_val:\n",
    "        student.eval()\n",
    "        mean_teacher.eval()\n",
    "        context = torch.no_grad()\n",
    "    else:\n",
    "        student.train()\n",
    "        mean_teacher.train()\n",
    "        context = nullcontext()\n",
    "    \n",
    "    with context:\n",
    "        t = tqdm(loader)\n",
    "        for i, sample in enumerate(t):\n",
    "            student_input = sample['waveform'].to(config.device)\n",
    "            teacher_input = sample['teacher_waveform'].to(config.device)\n",
    "            target = sample['target'].to(config.device)\n",
    "            classif_weights = sample['classification_weights'].to(config.device)\n",
    "            batch_size = len(target)\n",
    "            \n",
    "            if student.mixup_module:\n",
    "                student_pred, framewise_output, logit, target  = student(student_input, labels=target)\n",
    "            else:\n",
    "                student_pred, framewise_output, logit, target  = student(student_input, labels=target)\n",
    "#             if teacher.mixup_module:\n",
    "#                 teacher_pred, _, target  = mean_teacher(teacher_input, labels=target)\n",
    "#             else:\n",
    "            teacher_pred, _, _ = mean_teacher(teacher_input)\n",
    "\n",
    "            loss, class_loss, consistency_loss, consistency_weight = criterion(\n",
    "                student_pred, teacher_pred, target, classif_weights, epoch)\n",
    "\n",
    "            if not is_val:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                update_teacher_params(student, mean_teacher, \n",
    "                                      config.ema_decay, global_step)\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "            comp_metric.update(target, student_pred)\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            consistency_loss_avg.update(consistency_loss.item(), batch_size)\n",
    "            class_loss_avg.update(class_loss.item(), batch_size)\n",
    "            global_step += 1\n",
    "\n",
    "            t.set_description(f\"Epoch:{epoch} - Loss:{losses.avg:0.4f}\")\n",
    "        t.close()\n",
    "    return {'lwlrap':comp_metric.avg, \n",
    "            'loss':losses.avg, \n",
    "            'consistency_loss':consistency_loss_avg.avg, \n",
    "            'class_loss':class_loss_avg.avg, \n",
    "            'consistency_weight':consistency_weight}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally putting everything together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  \n",
      "Epoch:0 - Loss:7.0440: 100%|██████████| 113/113 [00:42<00:00,  2.65it/s]\n",
      "Epoch:0 - Loss:6.1351: 100%|██████████| 28/28 [00:09<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:57:31 2021 \n",
      "\n",
      "    Fold:0, Epoch:0, LR:0.0009972609, Cons. Weight: 0.6737946999085467\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                7.0440   |   6.1351\n",
      "\n",
      "    LWLRAP:              0.2904   |   0.4001\n",
      "\n",
      "    Class Loss:          7.0364   |   6.1201\n",
      "\n",
      "    Consistency Loss:    0.0076   |   0.0150\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from -inf --> 0.4000716429109744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 - Loss:5.2974: 100%|██████████| 113/113 [00:42<00:00,  2.68it/s]\n",
      "Epoch:1 - Loss:5.0773: 100%|██████████| 28/28 [00:08<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:58:23 2021 \n",
      "\n",
      "    Fold:0, Epoch:1, LR:0.0009890738, Cons. Weight: 3.1047958479329627\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                5.2974   |   5.0773\n",
      "\n",
      "    LWLRAP:              0.5002   |   0.5503\n",
      "\n",
      "    Class Loss:          5.2557   |   5.0109\n",
      "\n",
      "    Consistency Loss:    0.0418   |   0.0664\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.4000716429109744 --> 0.5502911941859311\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2 - Loss:4.0374: 100%|██████████| 113/113 [00:42<00:00,  2.69it/s]\n",
      "Epoch:2 - Loss:5.0490: 100%|██████████| 28/28 [00:09<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 01:59:15 2021 \n",
      "\n",
      "    Fold:0, Epoch:2, LR:0.0009755283, Cons. Weight: 10.836802322189582\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                4.0374   |   5.0490\n",
      "\n",
      "    LWLRAP:              0.6538   |   0.6358\n",
      "\n",
      "    Class Loss:          3.9012   |   4.8233\n",
      "\n",
      "    Consistency Loss:    0.1362   |   0.2257\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.5502911941859311 --> 0.6358252753522144\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3 - Loss:3.4321: 100%|██████████| 113/113 [00:41<00:00,  2.74it/s]\n",
      "Epoch:3 - Loss:4.6742: 100%|██████████| 28/28 [00:10<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:00:08 2021 \n",
      "\n",
      "    Fold:0, Epoch:3, LR:0.0009567727, Cons. Weight: 28.650479686019008\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.4321   |   4.6742\n",
      "\n",
      "    LWLRAP:              0.7417   |   0.6926\n",
      "\n",
      "    Class Loss:          3.0922   |   4.0465\n",
      "\n",
      "    Consistency Loss:    0.3400   |   0.6277\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.6358252753522144 --> 0.6925532299621986\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4 - Loss:3.3952: 100%|██████████| 113/113 [00:41<00:00,  2.71it/s]\n",
      "Epoch:4 - Loss:4.2938: 100%|██████████| 28/28 [00:10<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:01:00 2021 \n",
      "\n",
      "    Fold:0, Epoch:4, LR:0.0009330127, Cons. Weight: 57.375342073743276\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.3952   |   4.2938\n",
      "\n",
      "    LWLRAP:              0.7726   |   0.7721\n",
      "\n",
      "    Class Loss:          2.8103   |   3.3459\n",
      "\n",
      "    Consistency Loss:    0.5849   |   0.9479\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.6925532299621986 --> 0.772089432664018\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5 - Loss:3.2415: 100%|██████████| 113/113 [00:42<00:00,  2.67it/s]\n",
      "Epoch:5 - Loss:3.5686: 100%|██████████| 28/28 [00:09<00:00,  2.80it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:01:53 2021 \n",
      "\n",
      "    Fold:0, Epoch:5, LR:0.0009045085, Cons. Weight: 87.03247258333906\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.2415   |   3.5686\n",
      "\n",
      "    LWLRAP:              0.8158   |   0.8073\n",
      "\n",
      "    Class Loss:          2.4154   |   2.6649\n",
      "\n",
      "    Consistency Loss:    0.8261   |   0.9037\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.772089432664018 --> 0.807271222604556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6 - Loss:3.1621: 100%|██████████| 113/113 [00:41<00:00,  2.69it/s]\n",
      "Epoch:6 - Loss:3.9969: 100%|██████████| 28/28 [00:09<00:00,  2.98it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:02:45 2021 \n",
      "\n",
      "    Fold:0, Epoch:6, LR:0.0008715724, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                3.1621   |   3.9969\n",
      "\n",
      "    LWLRAP:              0.8308   |   0.7955\n",
      "\n",
      "    Class Loss:          2.2561   |   2.9033\n",
      "\n",
      "    Consistency Loss:    0.9060   |   1.0936\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7 - Loss:2.6610: 100%|██████████| 113/113 [00:41<00:00,  2.74it/s]\n",
      "Epoch:7 - Loss:3.6928: 100%|██████████| 28/28 [00:10<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:03:36 2021 \n",
      "\n",
      "    Fold:0, Epoch:7, LR:0.0008345653, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.6610   |   3.6928\n",
      "\n",
      "    LWLRAP:              0.8687   |   0.8229\n",
      "\n",
      "    Class Loss:          1.9102   |   2.6117\n",
      "\n",
      "    Consistency Loss:    0.7507   |   1.0812\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.807271222604556 --> 0.8228528911564625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8 - Loss:2.5214: 100%|██████████| 113/113 [00:39<00:00,  2.83it/s]\n",
      "Epoch:8 - Loss:3.3619: 100%|██████████| 28/28 [00:10<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:04:27 2021 \n",
      "\n",
      "    Fold:0, Epoch:8, LR:0.0007938926, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.5214   |   3.3619\n",
      "\n",
      "    LWLRAP:              0.8759   |   0.8372\n",
      "\n",
      "    Class Loss:          1.7669   |   2.2147\n",
      "\n",
      "    Consistency Loss:    0.7545   |   1.1473\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8228528911564625 --> 0.8371736984464149\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9 - Loss:2.3651: 100%|██████████| 113/113 [00:39<00:00,  2.86it/s]\n",
      "Epoch:9 - Loss:3.3914: 100%|██████████| 28/28 [00:10<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:05:18 2021 \n",
      "\n",
      "    Fold:0, Epoch:9, LR:0.00075, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.3651   |   3.3914\n",
      "\n",
      "    LWLRAP:              0.8791   |   0.8473\n",
      "\n",
      "    Class Loss:          1.5678   |   2.3553\n",
      "\n",
      "    Consistency Loss:    0.7974   |   1.0361\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8371736984464149 --> 0.8472876972876973\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:10 - Loss:2.2403: 100%|██████████| 113/113 [00:40<00:00,  2.80it/s]\n",
      "Epoch:10 - Loss:4.1486: 100%|██████████| 28/28 [00:10<00:00,  2.59it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:06:10 2021 \n",
      "\n",
      "    Fold:0, Epoch:10, LR:0.0007033683, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.2403   |   4.1486\n",
      "\n",
      "    LWLRAP:              0.8910   |   0.8019\n",
      "\n",
      "    Class Loss:          1.4614   |   2.9535\n",
      "\n",
      "    Consistency Loss:    0.7789   |   1.1952\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:11 - Loss:2.1005: 100%|██████████| 113/113 [00:40<00:00,  2.81it/s]\n",
      "Epoch:11 - Loss:3.3221: 100%|██████████| 28/28 [00:10<00:00,  2.60it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:07:01 2021 \n",
      "\n",
      "    Fold:0, Epoch:11, LR:0.0006545085, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                2.1005   |   3.3221\n",
      "\n",
      "    LWLRAP:              0.9048   |   0.8277\n",
      "\n",
      "    Class Loss:          1.4215   |   2.4387\n",
      "\n",
      "    Consistency Loss:    0.6791   |   0.8834\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:12 - Loss:1.8329: 100%|██████████| 113/113 [00:39<00:00,  2.83it/s]\n",
      "Epoch:12 - Loss:3.9153: 100%|██████████| 28/28 [00:10<00:00,  2.63it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:07:52 2021 \n",
      "\n",
      "    Fold:0, Epoch:12, LR:0.0006039558, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.8329   |   3.9153\n",
      "\n",
      "    LWLRAP:              0.9184   |   0.8282\n",
      "\n",
      "    Class Loss:          1.1813   |   2.9946\n",
      "\n",
      "    Consistency Loss:    0.6516   |   0.9207\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:13 - Loss:1.8506: 100%|██████████| 113/113 [00:39<00:00,  2.84it/s]\n",
      "Epoch:13 - Loss:3.1431: 100%|██████████| 28/28 [00:10<00:00,  2.74it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:08:42 2021 \n",
      "\n",
      "    Fold:0, Epoch:13, LR:0.0005522642, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.8506   |   3.1431\n",
      "\n",
      "    LWLRAP:              0.9167   |   0.8299\n",
      "\n",
      "    Class Loss:          1.1643   |   2.3327\n",
      "\n",
      "    Consistency Loss:    0.6864   |   0.8103\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:14 - Loss:1.7527: 100%|██████████| 113/113 [00:40<00:00,  2.77it/s]\n",
      "Epoch:14 - Loss:3.2721: 100%|██████████| 28/28 [00:10<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:09:33 2021 \n",
      "\n",
      "    Fold:0, Epoch:14, LR:0.0005, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.7527   |   3.2721\n",
      "\n",
      "    LWLRAP:              0.9261   |   0.8566\n",
      "\n",
      "    Class Loss:          1.0986   |   2.5829\n",
      "\n",
      "    Consistency Loss:    0.6541   |   0.6892\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8472876972876973 --> 0.8566335074102289\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:15 - Loss:1.7635: 100%|██████████| 113/113 [00:40<00:00,  2.80it/s]\n",
      "Epoch:15 - Loss:3.0625: 100%|██████████| 28/28 [00:09<00:00,  2.83it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:10:24 2021 \n",
      "\n",
      "    Fold:0, Epoch:15, LR:0.0004477358, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.7635   |   3.0625\n",
      "\n",
      "    LWLRAP:              0.9220   |   0.8504\n",
      "\n",
      "    Class Loss:          1.1096   |   2.2939\n",
      "\n",
      "    Consistency Loss:    0.6538   |   0.7686\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:16 - Loss:1.4932: 100%|██████████| 113/113 [00:41<00:00,  2.70it/s]\n",
      "Epoch:16 - Loss:2.5619: 100%|██████████| 28/28 [00:10<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:11:17 2021 \n",
      "\n",
      "    Fold:0, Epoch:16, LR:0.0003960442, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.4932   |   2.5619\n",
      "\n",
      "    LWLRAP:              0.9422   |   0.8734\n",
      "\n",
      "    Class Loss:          0.9563   |   1.8343\n",
      "\n",
      "    Consistency Loss:    0.5369   |   0.7276\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8566335074102289 --> 0.8733905800082271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:17 - Loss:1.4382: 100%|██████████| 113/113 [00:39<00:00,  2.83it/s]\n",
      "Epoch:17 - Loss:2.5873: 100%|██████████| 28/28 [00:10<00:00,  2.79it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:12:07 2021 \n",
      "\n",
      "    Fold:0, Epoch:17, LR:0.0003454915, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.4382   |   2.5873\n",
      "\n",
      "    LWLRAP:              0.9437   |   0.8717\n",
      "\n",
      "    Class Loss:          0.8795   |   1.9357\n",
      "\n",
      "    Consistency Loss:    0.5586   |   0.6516\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:18 - Loss:1.3662: 100%|██████████| 113/113 [00:39<00:00,  2.83it/s]\n",
      "Epoch:18 - Loss:2.8550: 100%|██████████| 28/28 [00:11<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:12:59 2021 \n",
      "\n",
      "    Fold:0, Epoch:18, LR:0.0002966317, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3662   |   2.8550\n",
      "\n",
      "    LWLRAP:              0.9468   |   0.8737\n",
      "\n",
      "    Class Loss:          0.8196   |   2.1529\n",
      "\n",
      "    Consistency Loss:    0.5465   |   0.7021\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8733905800082271 --> 0.8736861485006981\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:19 - Loss:1.3062: 100%|██████████| 113/113 [00:39<00:00,  2.89it/s]\n",
      "Epoch:19 - Loss:2.9304: 100%|██████████| 28/28 [00:11<00:00,  2.39it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:13:50 2021 \n",
      "\n",
      "    Fold:0, Epoch:19, LR:0.00025, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.3062   |   2.9304\n",
      "\n",
      "    LWLRAP:              0.9555   |   0.8324\n",
      "\n",
      "    Class Loss:          0.7586   |   2.2105\n",
      "\n",
      "    Consistency Loss:    0.5476   |   0.7199\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:20 - Loss:1.2007: 100%|██████████| 113/113 [00:39<00:00,  2.85it/s]\n",
      "Epoch:20 - Loss:2.9611: 100%|██████████| 28/28 [00:11<00:00,  2.40it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:14:42 2021 \n",
      "\n",
      "    Fold:0, Epoch:20, LR:0.0002061074, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.2007   |   2.9611\n",
      "\n",
      "    LWLRAP:              0.9578   |   0.8593\n",
      "\n",
      "    Class Loss:          0.6631   |   2.1677\n",
      "\n",
      "    Consistency Loss:    0.5376   |   0.7934\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:21 - Loss:1.1507: 100%|██████████| 113/113 [00:40<00:00,  2.80it/s]\n",
      "Epoch:21 - Loss:2.6994: 100%|██████████| 28/28 [00:11<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:15:34 2021 \n",
      "\n",
      "    Fold:0, Epoch:21, LR:0.0001654347, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1507   |   2.6994\n",
      "\n",
      "    LWLRAP:              0.9570   |   0.8811\n",
      "\n",
      "    Class Loss:          0.6040   |   2.0486\n",
      "\n",
      "    Consistency Loss:    0.5467   |   0.6508\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from 0.8736861485006981 --> 0.8811443494776827\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:22 - Loss:1.1455: 100%|██████████| 113/113 [00:39<00:00,  2.86it/s]\n",
      "Epoch:22 - Loss:2.4057: 100%|██████████| 28/28 [00:11<00:00,  2.45it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:16:26 2021 \n",
      "\n",
      "    Fold:0, Epoch:22, LR:0.0001284276, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.1455   |   2.4057\n",
      "\n",
      "    LWLRAP:              0.9662   |   0.8620\n",
      "\n",
      "    Class Loss:          0.6196   |   1.8908\n",
      "\n",
      "    Consistency Loss:    0.5259   |   0.5149\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:23 - Loss:1.0481: 100%|██████████| 113/113 [00:39<00:00,  2.89it/s]\n",
      "Epoch:23 - Loss:2.7173: 100%|██████████| 28/28 [00:11<00:00,  2.37it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:17:17 2021 \n",
      "\n",
      "    Fold:0, Epoch:23, LR:9.54915e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.0481   |   2.7173\n",
      "\n",
      "    LWLRAP:              0.9656   |   0.8617\n",
      "\n",
      "    Class Loss:          0.5481   |   2.1846\n",
      "\n",
      "    Consistency Loss:    0.5000   |   0.5328\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:24 - Loss:0.9337: 100%|██████████| 113/113 [00:39<00:00,  2.87it/s]\n",
      "Epoch:24 - Loss:2.5130: 100%|██████████| 28/28 [00:12<00:00,  2.22it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:18:09 2021 \n",
      "\n",
      "    Fold:0, Epoch:24, LR:6.69873e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.9337   |   2.5130\n",
      "\n",
      "    LWLRAP:              0.9701   |   0.8658\n",
      "\n",
      "    Class Loss:          0.4641   |   1.9967\n",
      "\n",
      "    Consistency Loss:    0.4696   |   0.5164\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:25 - Loss:1.0129: 100%|██████████| 113/113 [00:39<00:00,  2.88it/s]\n",
      "Epoch:25 - Loss:2.8657: 100%|██████████| 28/28 [00:12<00:00,  2.30it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:19:00 2021 \n",
      "\n",
      "    Fold:0, Epoch:25, LR:4.322727e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                1.0129   |   2.8657\n",
      "\n",
      "    LWLRAP:              0.9667   |   0.8527\n",
      "\n",
      "    Class Loss:          0.5280   |   2.1849\n",
      "\n",
      "    Consistency Loss:    0.4849   |   0.6809\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:26 - Loss:0.9611: 100%|██████████| 113/113 [00:38<00:00,  2.92it/s]\n",
      "Epoch:26 - Loss:2.5857: 100%|██████████| 28/28 [00:11<00:00,  2.37it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:19:51 2021 \n",
      "\n",
      "    Fold:0, Epoch:26, LR:2.447174e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.9611   |   2.5857\n",
      "\n",
      "    LWLRAP:              0.9717   |   0.8660\n",
      "\n",
      "    Class Loss:          0.4685   |   2.0600\n",
      "\n",
      "    Consistency Loss:    0.4926   |   0.5257\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:27 - Loss:0.9019: 100%|██████████| 113/113 [00:40<00:00,  2.82it/s]\n",
      "Epoch:27 - Loss:2.4177: 100%|██████████| 28/28 [00:11<00:00,  2.51it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:20:42 2021 \n",
      "\n",
      "    Fold:0, Epoch:27, LR:1.09262e-05, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.9019   |   2.4177\n",
      "\n",
      "    LWLRAP:              0.9778   |   0.8772\n",
      "\n",
      "    Class Loss:          0.4232   |   1.8037\n",
      "\n",
      "    Consistency Loss:    0.4788   |   0.6140\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:28 - Loss:0.9030: 100%|██████████| 113/113 [00:39<00:00,  2.84it/s]\n",
      "Epoch:28 - Loss:2.6731: 100%|██████████| 28/28 [00:11<00:00,  2.46it/s]\n",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:21:34 2021 \n",
      "\n",
      "    Fold:0, Epoch:28, LR:2.739052e-06, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.9030   |   2.6731\n",
      "\n",
      "    LWLRAP:              0.9694   |   0.8706\n",
      "\n",
      "    Class Loss:          0.4853   |   1.9494\n",
      "\n",
      "    Consistency Loss:    0.4177   |   0.7237\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:29 - Loss:0.8072: 100%|██████████| 113/113 [00:39<00:00,  2.89it/s]\n",
      "Epoch:29 - Loss:2.8178: 100%|██████████| 28/28 [00:11<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:22:25 2021 \n",
      "\n",
      "    Fold:0, Epoch:29, LR:0.0, Cons. Weight: 100.0\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                0.8072   |   2.8178\n",
      "\n",
      "    LWLRAP:              0.9793   |   0.8619\n",
      "\n",
      "    Class Loss:          0.3930   |   2.1790\n",
      "\n",
      "    Consistency Loss:    0.4142   |   0.6389\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:0 - Loss:6.8989: 100%|██████████| 113/113 [00:41<00:00,  2.75it/s]\n",
      "Epoch:0 - Loss:6.8158: 100%|██████████| 28/28 [00:10<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Thu Feb 18 02:23:22 2021 \n",
      "\n",
      "    Fold:1, Epoch:0, LR:0.0009972609, Cons. Weight: 0.6737946999085467\n",
      "\n",
      "    --------------------------------------------------------\n",
      "    Metric:              Train    |   Val\n",
      "    --------------------------------------------------------\n",
      "    Loss:                6.8989   |   6.8158\n",
      "\n",
      "    LWLRAP:              0.3071   |   0.4104\n",
      "\n",
      "    Class Loss:          6.8908   |   6.7988\n",
      "\n",
      "    Consistency Loss:    0.0080   |   0.0169\n",
      "\n",
      "    --------------------------------------------------------\n",
      "\n",
      "    \n",
      "    LWLRAP Improved from -inf --> 0.4104104726669944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 - Loss:5.3511:  27%|██▋       | 31/113 [00:12<00:21,  3.83it/s]"
     ]
    }
   ],
   "source": [
    "def train(df, fold):\n",
    "    train_df = df[df.fold != fold]\n",
    "    val_df = df[df.fold == fold]\n",
    "    train_loader = get_data_loader(train_df)\n",
    "    val_loader = get_data_loader(val_df)\n",
    "\n",
    "    student_model = get_model()\n",
    "    teacher_model = get_model(is_mean_teacher=True)\n",
    "\n",
    "#     optimizer = Ranger(student_model.parameters(),\n",
    "#                lr=config.lr,\n",
    "#                k=4,\n",
    "#                betas=(.9, 0.999), weight_decay=0)\n",
    "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=config.lr)\n",
    "    num_train_steps = int(len(train_loader) * config.epochs)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=num_train_steps)\n",
    "    criterion = MeanTeacherLoss()\n",
    "\n",
    "    best_val_metric = -np.inf\n",
    "    val_metrics = []\n",
    "    train_metrics = []\n",
    "    for epoch in range(0, config.epochs):\n",
    "        train_loss_metrics = train_one_epoch(\n",
    "            student_model, teacher_model, train_loader, \n",
    "            criterion, optimizer, scheduler, epoch)\n",
    "        val_loss_metrics = train_one_epoch(\n",
    "            student_model, teacher_model, val_loader, \n",
    "            criterion, optimizer, scheduler, epoch, is_val=True)\n",
    "\n",
    "        train_metrics.append(train_loss_metrics)\n",
    "        val_metrics.append(val_loss_metrics)\n",
    "        pretty_print_metrics(fold, epoch, optimizer, \n",
    "                             train_loss_metrics, val_loss_metrics)\n",
    "        \n",
    "        if val_loss_metrics['lwlrap'] > best_val_metric:\n",
    "            print(f\"    LWLRAP Improved from {best_val_metric} --> {val_loss_metrics['lwlrap']}\\n\")\n",
    "            best_val_metric = val_loss_metrics['lwlrap']\n",
    "            \n",
    "            torch.save(teacher_model.state_dict(), \n",
    "                       os.path.join(config.save_path, f'fold-{fold}_{best_val_metric:.3f}.bin'))\n",
    "    \n",
    "\n",
    "\n",
    "df = get_n_fold_df(config.train_tp_csv)\n",
    "for fold in range(5 if config.train_5_folds else 1):\n",
    "    train(df, fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test Set\n",
    "We'll predict using the teacher model but you could also use the student or a combination of the two. Inference works just like it would for a vanilla baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_df, train_FSLfold):\n",
    "    test_dataset = TestDataset(\n",
    "        df=test_df,\n",
    "        data_path=\"/media/paniquex/samsung_2tb/rfcx_kaggle/rfcx-species-audio-detection/test\",\n",
    "        period=config.period_val,\n",
    "        step=config.step\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=config.num_workers\n",
    "    )\n",
    "    \n",
    "    weights_path = os.path.join(config.save_path, f'fold-{train_fold}.bin')\n",
    "    model = get_model()\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=config.device), strict=False)\n",
    "    \n",
    "    test_pred, ids = predict_on_test(model, test_loader)\n",
    "\n",
    "    # Build Submission File\n",
    "    test_pred_df = pd.DataFrame({\n",
    "        \"recording_id\": test_df.recording_id.values\n",
    "    })\n",
    "    target_cols = test_df.columns[1:].values.tolist()\n",
    "    test_pred_df = test_pred_df.join(pd.DataFrame(np.array(test_pred), \n",
    "                                                  columns=target_cols))\n",
    "    test_pred_df.to_csv(os.path.join(config.save_path, \n",
    "                                     f\"fold-{train_fold}-submission.csv\"), \n",
    "                        index=False)\n",
    "    \n",
    "    \n",
    "test_df = pd.read_csv(config.test_csv)\n",
    "for fold in range(5 if config.train_5_folds else 1):\n",
    "    test(test_df, fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Fold Ensemble\n",
    "For 5 fold runs, we'll create a single ensemble prediction by simply averaging all of the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(submission_path):\n",
    "    dfs = [pd.read_csv(os.path.join(\n",
    "        config.save_path, f\"fold-{i}-submission.csv\")) for i in range(5)]\n",
    "    anchor = dfs[0].copy()\n",
    "    cols = anchor.columns[1:]\n",
    "   \n",
    "    for c in cols:\n",
    "        total = 0\n",
    "        for df in dfs:\n",
    "            total += df[c]\n",
    "        anchor[c] = total / len(dfs)\n",
    "    anchor.to_csv(submission_path, index=False)\n",
    "\n",
    "\n",
    "submission_path = os.path.join(config.save_path, f\"submission.csv\")\n",
    "if config.train_5_folds:\n",
    "    ensemble(submission_path)\n",
    "else:\n",
    "    fold0_submission = os.path.join(config.save_path, f\"fold-0-submission.csv\")\n",
    "    os.rename(fold0_submission, submission_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "Thanks for reading! I dropped some unrelated tricks from this and didn't spend much time tuning so there's almost definetely room for improvement.\n",
    "\n",
    "I know it's pretty late in the competition for new notebooks, but considering that there are a few other public notebooks that score higher, I'm hoping this won't cause a significant shakeup. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
