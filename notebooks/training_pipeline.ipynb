{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/media/paniquex/samsung_2tb/IDAO_2021_oski/src\") # path to your src\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from datasets import SimpleDataset\n",
    "from models import Wrapper, MixUp\n",
    "from pipeline_utils import training\n",
    "from models import ENCODER_PARAMS\n",
    "from ranger import Ranger\n",
    "\n",
    "try:\n",
    "    os.chdir(\"/media/paniquex/samsung_2tb/\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:3: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_CFG = \"/media/paniquex/samsung_2tb/IDAO_2021_oski/config/config.yaml\" # path to your cfg\n",
    "with open(PATH_TO_CFG, \"r\") as file:\n",
    "    config = yaml.load(file)\n",
    "\n",
    "DATA_ROOT = config[\"general\"][\"data_root\"]\n",
    "\n",
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "fix_seed(config[\"general\"][\"seed\"])\n",
    "device_ids = [str(id) for id in config[\"general\"][\"device_ids\"]]\n",
    "ids = \",\".join(device_ids)\n",
    "DEVICE = torch.device(f\"cuda:{ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/paniquex/samsung_2tb/IDAO_2021_oski/data/track_1/idao_dataset'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_ROOT, \"train.csv\"), index_col=0)\n",
    "val_private = pd.read_csv(os.path.join(DATA_ROOT, \"val_private.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>file_path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4030</th>\n",
       "      <td>NR</td>\n",
       "      <td>20</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12593</th>\n",
       "      <td>ER</td>\n",
       "      <td>30</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7515</th>\n",
       "      <td>ER</td>\n",
       "      <td>3</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>NR</td>\n",
       "      <td>6</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9627</th>\n",
       "      <td>ER</td>\n",
       "      <td>30</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7460</th>\n",
       "      <td>ER</td>\n",
       "      <td>30</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8568</th>\n",
       "      <td>ER</td>\n",
       "      <td>10</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7526</th>\n",
       "      <td>ER</td>\n",
       "      <td>10</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NR</td>\n",
       "      <td>20</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>NR</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1                                          file_path  target\n",
       "4030   NR  20  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       8\n",
       "12593  ER  30  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       4\n",
       "7515   ER   3  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       3\n",
       "1608   NR   6  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...      11\n",
       "9627   ER  30  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       4\n",
       "7460   ER  30  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       4\n",
       "8568   ER  10  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       1\n",
       "7526   ER  10  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       1\n",
       "35     NR  20  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       8\n",
       "1749   NR   1  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder() \n",
    "\n",
    "\n",
    "\n",
    "mask_NR = (train[\"0\"] == \"NR\") & ((train[\"1\"] == 1) | (train[\"1\"] == 6) | (train[\"1\"] == 20))\n",
    "mask_ER = (train[\"0\"] == \"ER\") & ((train[\"1\"] == 3) | (train[\"1\"] == 10) | (train[\"1\"] == 30))\n",
    "train = train[mask_NR | mask_ER]\n",
    "train.index = pd.RangeIndex(0, len(train.index))\n",
    "if config[\"general\"][\"task_type\"] == \"regression\":\n",
    "    train[\"target\"] = train[\"1\"]\n",
    "    val_private[\"target\"] = val_private[\"1\"]\n",
    "elif config[\"general\"][\"task_type\"] == \"classification\":\n",
    "    train[\"target\"] = le.fit_transform(train[\"target\"])\n",
    "#     val_private[\"target\"] = le.fit_transform(val_private)\n",
    "elif config[\"general\"][\"task_type\"] == \"joint\":\n",
    "    train[\"target_regression\"] = train[\"1\"]\n",
    "    train[\"target_classification\"] = le.fit_transform(train[\"0\"])\n",
    "    train[\"target\"] = train[\"target_regression\"].astype(str) + \"_\" + train[\"target_classification\"].astype(str)\n",
    "    \n",
    "    val_private[\"target_regression\"] = val_private[\"1\"]\n",
    "    val_private[\"target_classification\"] = le.fit_transform(val_private[\"0\"])\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=config[\"training\"][\"n_folds\"], shuffle=True,\n",
    "                        random_state=config[\"general\"][\"seed\"])\n",
    "for fold, (t_idx, v_idx) in enumerate(kfold.split(train, train[\"target\"])):\n",
    "    train.loc[v_idx, \"kfold\"] = fold\n",
    "\n",
    "\n",
    "    \n",
    "train.to_csv(os.path.join(DATA_ROOT, \"train\", \"train_folds.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>file_path</th>\n",
       "      <th>target</th>\n",
       "      <th>target_regression</th>\n",
       "      <th>target_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>NR</td>\n",
       "      <td>30</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>NR</td>\n",
       "      <td>3</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>NR</td>\n",
       "      <td>10</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>NR</td>\n",
       "      <td>30</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5485</th>\n",
       "      <td>NR</td>\n",
       "      <td>3</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5781</th>\n",
       "      <td>NR</td>\n",
       "      <td>10</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7132</th>\n",
       "      <td>ER</td>\n",
       "      <td>20</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>ER</td>\n",
       "      <td>20</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8012</th>\n",
       "      <td>ER</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>ER</td>\n",
       "      <td>6</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8712</th>\n",
       "      <td>ER</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11714</th>\n",
       "      <td>ER</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/paniquex/samsung_2tb/IDAO_2021_oski/dat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1                                          file_path  target  \\\n",
       "2719   NR  30  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...      10   \n",
       "3783   NR   3  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       9   \n",
       "4874   NR  10  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       7   \n",
       "4915   NR  30  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...      10   \n",
       "5485   NR   3  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       9   \n",
       "5781   NR  10  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       7   \n",
       "7132   ER  20  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       2   \n",
       "7397   ER  20  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       2   \n",
       "8012   ER   1  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       0   \n",
       "8142   ER   6  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       5   \n",
       "8712   ER   1  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       0   \n",
       "11714  ER   1  /media/paniquex/samsung_2tb/IDAO_2021_oski/dat...       0   \n",
       "\n",
       "       target_regression  target_classification  \n",
       "2719                  30                      1  \n",
       "3783                   3                      1  \n",
       "4874                  10                      1  \n",
       "4915                  30                      1  \n",
       "5485                   3                      1  \n",
       "5781                  10                      1  \n",
       "7132                  20                      0  \n",
       "7397                  20                      0  \n",
       "8012                   1                      0  \n",
       "8142                   6                      0  \n",
       "8712                   1                      0  \n",
       "11714                  1                      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "transforms_train = albumentations.Compose([\n",
    "    ColorJitter (brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "    ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "    CenterCrop(height=400,\n",
    "               width=400),\n",
    "    Resize(*config[\"preprocessing\"][\"img_size\"]),\n",
    "    Normalize(\n",
    "         mean=[0.485, 0.456, 0.406],\n",
    "         std=[0.229, 0.224, 0.225],\n",
    "     ),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "transforms_val = albumentations.Compose([\n",
    "    CenterCrop(height=400,\n",
    "               width=400),\n",
    "    Resize(*config[\"preprocessing\"][\"img_size\"]),\n",
    "    Normalize(\n",
    "         mean=[0.485, 0.456, 0.406],\n",
    "         std=[0.229, 0.224, 0.225],\n",
    "     ),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "    \n",
    "def focal_loss(input, target, focus=2.0, raw=False):\n",
    "\n",
    "    if raw:\n",
    "        input = torch.sigmoid(input)\n",
    "\n",
    "    eps = 1e-7\n",
    "\n",
    "    prob_true = input * target + (1 - input) * (1 - target)\n",
    "    prob_true = torch.clamp(prob_true, eps, 1-eps)\n",
    "    modulating_factor = (1.0 - prob_true).pow(focus)\n",
    "\n",
    "    return (-modulating_factor * prob_true.log()).mean()\n",
    "\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "\n",
    "\n",
    "class AngularPenaltySMLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, loss_type=\"cosface\", eps=1e-7, s=None, m=None):\n",
    "        '''\n",
    "        Angular Penalty Softmax Loss\n",
    "        Three 'loss_types' available: ['arcface', 'sphereface', 'cosface']\n",
    "        These losses are described in the following papers: \n",
    "        \n",
    "        ArcFace: https://arxiv.org/abs/1801.07698\n",
    "        SphereFace: https://arxiv.org/abs/1704.08063\n",
    "        CosFace/Ad Margin: https://arxiv.org/abs/1801.05599\n",
    "        '''\n",
    "        super(AngularPenaltySMLoss, self).__init__()\n",
    "        loss_type = loss_type.lower()\n",
    "        assert loss_type in  ['arcface', 'sphereface', 'cosface']\n",
    "        if loss_type == 'arcface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 0.5 if not m else m\n",
    "        if loss_type == 'sphereface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 1.35 if not m else m\n",
    "        if loss_type == 'cosface':\n",
    "            self.s = 30.0 if not s else s\n",
    "            self.m = 0.4 if not m else m\n",
    "        self.loss_type = loss_type\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        '''\n",
    "        input shape (N, in_features)\n",
    "        '''\n",
    "        assert len(x) == len(labels)\n",
    "        assert torch.min(labels) >= 0\n",
    "        assert torch.max(labels) < self.out_features\n",
    "        \n",
    "        for W in self.fc.parameters():\n",
    "            W = F.normalize(W, p=2, dim=1)\n",
    "\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "#         print(x.shape)\n",
    "        wf = self.fc(x)\n",
    "        if self.loss_type == 'cosface':\n",
    "            numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n",
    "        if self.loss_type == 'arcface':\n",
    "            numerator = self.s * torch.cos(torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)) + self.m)\n",
    "        if self.loss_type == 'sphereface':\n",
    "            numerator = self.s * torch.cos(self.m * torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)))\n",
    "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
    "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
    "        L = numerator - torch.log(denominator)\n",
    "        return -torch.mean(L), wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = config[\"training\"][\"n_epochs\"]\n",
    "\n",
    "\n",
    "criterion_aam = None\n",
    "if config[\"general\"][\"task_type\"] == \"classification\":\n",
    "    if config[\"training\"][\"loss\"][\"clf\"] == \"FOCAL\":\n",
    "        criterion = focal_loss\n",
    "    elif config[\"training\"][\"loss\"][\"clf\"] == \"AAM\":\n",
    "        criterion = \"AAM\"\n",
    "        criterion_aam = AngularPenaltySMLoss\n",
    "    elif config[\"training\"][\"loss\"][\"clf\"] == \"BCE\":\n",
    "        criterion = nn.BCELoss()\n",
    "elif config[\"general\"][\"task_type\"] == \"regression\":\n",
    "    if config[\"training\"][\"loss\"][\"reg\"] == \"L1\":\n",
    "        criterion = nn.L1Loss()\n",
    "    elif config[\"training\"][\"loss\"][\"reg\"] == \"L2\":\n",
    "        criterion = nn.MSELoss()\n",
    "elif config[\"training\"][\"loss\"] == \"L1\":\n",
    "    criterion = nn.L1Loss()\n",
    "elif config[\"general\"][\"task_type\"] == \"joint\":\n",
    "    criterion = {}\n",
    "    if config[\"training\"][\"loss\"][\"clf\"] == \"FOCAL\":\n",
    "        criterion[\"clf\"] = focal_loss\n",
    "    elif config[\"training\"][\"loss\"][\"clf\"] == \"AAM\":\n",
    "        criterion[\"clf\"] = \"AAM\"\n",
    "        criterion_aam = AngularPenaltySMLoss\n",
    "    elif config[\"training\"][\"loss\"][\"clf\"] == \"BCE\":\n",
    "        criterion[\"clf\"] = nn.BCELoss()\n",
    "    if config[\"general\"][\"task_type\"] == \"regression\":\n",
    "        if config[\"training\"][\"loss\"][\"reg\"] == \"L1\":\n",
    "            criterion[\"reg\"] = nn.L1Loss()\n",
    "        elif config[\"training\"][\"loss\"][\"reg\"] == \"L2\":\n",
    "            criterion[\"reg\"] = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = None\n",
    "if config[\"training\"][\"finetune\"]:\n",
    "    model_names = [name for name in os.listdir(config['training']['models_dir']) if name.find(\"best_model_fold\") != -1]\n",
    "    model_names = sorted(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(config[\"general\"][\"out_path\"])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(config[\"general\"][\"out_path\"])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "if config[\"general\"][\"task_type\"] == \"regression\":\n",
    "    config[\"general\"][\"classes_num\"] = 1\n",
    "elif config[\"general\"][\"task_type\"] == \"joint\":\n",
    "    config[\"general\"][\"classes_num\"] = 2\n",
    "    \n",
    "    \n",
    "samples2preds_all = {}\n",
    "samples2trues_all = {}\n",
    "for i in range(config[\"training\"][\"n_folds\"]):\n",
    "    model_name = config[\"general\"][\"model_name\"]\n",
    "    model = None\n",
    "    model = ENCODER_PARAMS[model_name][\"init_op\"]()\n",
    "    model = Wrapper(model, feat_module=None, classes_num=config[\"general\"][\"classes_num\"],\n",
    "                    model_name=model_name,\n",
    "                    spec_augmenter=None, \n",
    "                    mixup_module=None,\n",
    "                    task_type=config[\"general\"][\"task_type\"],\n",
    "                    activation_func=config[\"training\"][\"activation_func\"],\n",
    "                    criterion_aam=criterion_aam)\n",
    "    model.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"training\"][\"lr\"])\n",
    "#         optimizer = Ranger(model.parameters(),\n",
    "#                lr=config[\"training\"][\"lr\"],\n",
    "#                betas=(.90, 0.999), k=4)\n",
    "    train_dataset = SimpleDataset(df=train[train[\"kfold\"] != fold], mode=\"train\",\n",
    "                                  transform=transforms_train, classes_num=config[\"general\"][\"classes_num\"],\n",
    "                                  task_type=config[\"general\"][\"task_type\"])\n",
    "\n",
    "    val_dataset = SimpleDataset(df=train[train[\"kfold\"] == fold], mode=\"val\",\n",
    "                                transform=transforms_val, classes_num=config[\"general\"][\"classes_num\"],\n",
    "                                task_type=config[\"general\"][\"task_type\"])\n",
    "    val_private_dataset = SimpleDataset(df=val_private, mode=\"val\",\n",
    "                                        transform=transforms_val, classes_num=config[\"general\"][\"classes_num\"],\n",
    "                                        task_type=config[\"general\"][\"task_type\"])\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                  **config[\"training\"][\"dataloader\"])\n",
    "    val_dataloader = DataLoader(val_dataset,\n",
    "                                **config[\"validation\"][\"dataloader\"])\n",
    "    val_private_dataloader = DataLoader(val_private_dataset,\n",
    "                                        **config[\"validation\"][\"dataloader\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                       T_max=(config[\"training\"][\"n_epochs\"] - config[\"training\"][\"n_epochs_flat\"])  * len(train_dataloader),\n",
    "                                                       eta_min=1e-8)    \n",
    "    samples2preds, samples2trues = training(EPOCHS=EPOCHS, model=model,\n",
    "                                            train_dataloader=train_dataloader, \n",
    "                                            val_dataloaders_dct={\"val_dataloader\": val_dataloader,\n",
    "                                                                  \"val_private_dataloader\": val_private_dataloader},\n",
    "                                            DEVICE=DEVICE, criterion=criterion,\n",
    "                                            optimizer=optimizer, scheduler=scheduler,\n",
    "                                            config=config, fold=i,\n",
    "                                            task_type=config[\"general\"][\"task_type\"], CONFIG_PATH=CONFIG_PATH)\n",
    "    samples2preds_all.update(samples2preds)\n",
    "    samples2trues_all.update(samples2trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}