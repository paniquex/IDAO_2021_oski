{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/media/paniquex/samsung_2tb/IDAO_2021_oski/src\")\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "import audiomentations\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from datasets import SimpleDataset\n",
    "from preprocessing import CMVN, MelSpecComputer, MFCCComputer, MelSpecComputer3D\n",
    "from models import Wrapper\n",
    "from pipeline_utils import evaluate_test\n",
    "from models import ENCODER_PARAMS\n",
    "\n",
    "\n",
    "os.chdir(\"/media/paniquex/samsung_2tb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:3: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_CFG = \"/media/paniquex/samsung_2tb/IDAO_2021_oski/experiments/check_experiment/config.yaml\"\n",
    "with open(PATH_TO_CFG, \"r\") as file:\n",
    "    config = yaml.load(file)\n",
    "\n",
    "DATA_ROOT = config[\"general\"][\"data_root\"]\n",
    "\n",
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "fix_seed(config[\"general\"][\"seed\"])\n",
    "device_ids = [str(id) for id in config[\"general\"][\"device_ids\"]]\n",
    "ids = \",\".join(device_ids)\n",
    "DEVICE = torch.device(f\"cuda:{ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [name for name in os.listdir(config['general']['out_path']) if name.find(\"best_model_fold\") != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "transforms_test = albumentations.Compose([\n",
    "    Resize(384, 384),\n",
    "    Normalize(\n",
    "         mean=[0.485, 0.456, 0.406],\n",
    "         std=[0.229, 0.224, 0.225],\n",
    "     ),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(DATA_ROOT, \"test.csv\"))\n",
    "\n",
    "\n",
    "test_dataset = SimpleDataset(df=test, mode=\"test\", transform=transforms_test)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, **config[\"testing\"][\"dataloader\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrogram_extractor = Spectrogram(**config[\"preprocessing\"][\"spectrogram\"])\n",
    "# logmel_extractor = LogmelFilterBank(sr=config[\"preprocessing\"][\"sr\"],\n",
    "#                                     **config[\"preprocessing\"][\"logmel\"])\n",
    "\n",
    "# if config[\"preprocessing\"][\"features_type\"] == \"logmel\":\n",
    "#     spectrogram_extractor = Spectrogram(**config[\"preprocessing\"][\"spectrogram\"])\n",
    "#     logmel_extractor = LogmelFilterBank(sr=config[\"preprocessing\"][\"sr\"],\n",
    "#                                         **config[\"preprocessing\"][\"logmel\"])\n",
    "# elif config[\"preprocessing\"][\"features_type\"] == \"melspec\":\n",
    "#     melspec_extractor = MelSpecComputer(config=config)\n",
    "# elif config[\"preprocessing\"][\"features_type\"] == \"mfcc\":\n",
    "#     mfcc_extractor = MFCCComputer(config=config)\n",
    "# elif config[\"preprocessing\"][\"features_type\"] == \"3D\":\n",
    "#     melspec_extractor = MelSpecComputer3D(config=config)\n",
    "\n",
    "# # Spec augmenter\n",
    "# if \"SpecAug\" in config[\"testing\"][\"augmentations\"]:\n",
    "#     spec_augmenter = SpecAugmentation(**config[\"training\"][\"augmentations\"][\"SpecAug\"])\n",
    "# else:\n",
    "#     spec_augmenter = None\n",
    "\n",
    "# if config[\"preprocessing\"][\"use_cmvn\"]:\n",
    "#     cmvn = CMVN(2)\n",
    "# else:\n",
    "#     cmvn = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"general\"][\"task_type\"] == \"regression\":\n",
    "    config[\"general\"][\"classes_num\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config[\"general\"][\"model_name\"]\n",
    "model = ENCODER_PARAMS[model_name][\"init_op\"]()\n",
    "# if config[\"preprocessing\"][\"features_type\"] == \"logmelfilter\":\n",
    "#     feat_module = [spectrogram_extractor]\n",
    "#     if cmvn is not None:\n",
    "#         feat_module.append(cmvn)\n",
    "#     feat_module.append(logmel_extractor)\n",
    "# elif config[\"preprocessing\"][\"features_type\"] == \"melspec\":\n",
    "#     feat_module = [melspec_extractor]\n",
    "#     if cmvn is not None:\n",
    "#         feat_module.append(cmvn)\n",
    "# elif config[\"preprocessing\"][\"features_type\"] == \"mfcc\":\n",
    "#     feat_module = [mfcc_extractor]\n",
    "#     if cmvn is not None:\n",
    "#         feat_module.append(cmvn)\n",
    "# elif config[\"preprocessing\"][\"features_type\"] == \"3D\":\n",
    "#     feat_module = [melspec_extractor]\n",
    "#     if cmvn is not None:\n",
    "#         feat_module.append(cmvn)\n",
    "        \n",
    "if config[\"training\"][\"loss\"] == \"AAM\":\n",
    "    criterion_aam = AngularPenaltySMLoss\n",
    "else:\n",
    "    criterion_aam = None\n",
    "model = Wrapper(model, feat_module=None, classes_num=config[\"general\"][\"classes_num\"],\n",
    "                    model_name=model_name,\n",
    "                spec_augmenter=None, \n",
    "                mixup_module=None,\n",
    "                task_type=config[\"general\"][\"task_type\"],\n",
    "                SED=config[\"general\"][\"SED\"],\n",
    "                activation_func=config[\"training\"][\"activation_func\"],\n",
    "                criterion_aam=criterion_aam)\n",
    "# if config[\"testing\"][\"state_dict\"] is not None:\n",
    "#     model.load_state_dict(torch.load(config[\"testing\"][\"state_dict\"],\n",
    "#                                      map_location=torch.device(DEVICE))['model_state_dict'])\n",
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 518/518 [02:34<00:00,  3.35it/s]\n",
      "100%|██████████| 518/518 [02:31<00:00,  3.41it/s]\n",
      "100%|██████████| 518/518 [02:29<00:00,  3.47it/s]\n",
      "100%|██████████| 518/518 [02:30<00:00,  3.45it/s]\n",
      "100%|██████████| 518/518 [02:31<00:00,  3.41it/s]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(config[\"general\"][\"out_path\"])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "sample2preds = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    for model_name in model_names:\n",
    "        model.load_state_dict(torch.load(os.path.join(config[\"general\"][\"out_path\"], model_name),\n",
    "                                    map_location=torch.device(DEVICE))['model_state_dict'])\n",
    "        if sample2preds is None:\n",
    "            sample2preds = evaluate_test(model=model, dataloader=test_dataloader,\n",
    "                          DEVICE=DEVICE, config=config)\n",
    "        else:\n",
    "            sample2preds_new = evaluate_test(model=model, dataloader=test_dataloader,\n",
    "                          DEVICE=DEVICE, config=config)\n",
    "            for sample in sample2preds:\n",
    "                sample2preds[sample] += sample2preds_new[sample]\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.read_csv('/media/paniquex/samsung_2tb/IDAO_2021_oski/data/track1_predictions_example.csv')\n",
    "\n",
    "\n",
    "for sample in sample2preds:\n",
    "    \n",
    "    sample_short = sample.split(\"/\")[-1][:-4]\n",
    "    if config[\"general\"][\"task_type\"] == \"regression\":\n",
    "        preds.loc[preds[\"id\"] == sample_short, \"regression_predictions\"] = np.mean(sample2preds[sample])\n",
    "    elif config[\"general\"][\"task_type\"] == \"classification\":\n",
    "        preds.loc[preds[\"id\"] == sample_short, \"classification_predictions\"] = np.argmax(np.bincount(sample2preds[sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.to_csv(f\"predictions_{config['general']['task_type']}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_classif = (pd.read_csv(f\"predictions_classification.csv\")[\"classification_predictions\"].values < 3).astype(int)\n",
    "preds_regr = pd.read_csv(f\"predictions_regression.csv\")[\"regression_predictions\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[\"classification_predictions\"] = preds_classif\n",
    "preds[\"regression_predictions\"] = preds_regr\n",
    "preds.to_csv(f\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_ROOT + \"/train/train_folds_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train[\"0\"] == \"NR\")][\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_csv = pd.read_csv(os.path.join(config[\"general\"][\"data_root\"], 'sample_submission.csv'), index_col=0)\n",
    "# for sample in sample2preds:\n",
    "#     preds = np.vstack(sample2preds[sample])\n",
    "#     if config[\"general\"][\"use_silence_class\"]:\n",
    "#         silence_mask = np.argmax(pred, axis=1) == 24 #preds[:, -1] > 0.2\n",
    "#         preds[silence_mask, :] = 0\n",
    "#     preds_csv.loc[sample] = np.max(preds, axis=0)[:24] # [:24] to exclude silence class\n",
    "# preds_csv.to_csv(os.path.join(config[\"general\"][\"out_path\"], 'submission_ensemble_max.csv'), index='recording_id')\n",
    "\n",
    "\n",
    "# for sample in sample2preds:\n",
    "#     preds = np.vstack(sample2preds[sample])\n",
    "#     if config[\"general\"][\"use_silence_class\"]:\n",
    "#         silence_mask = np.argmax(preds, axis=1) == 24\n",
    "#         pred[silence_mask, :] = 0\n",
    "#     preds_csv.loc[sample] = np.mean(preds, axis=0)[:24] # [:24] to exclude silence class\n",
    "\n",
    "# preds_csv.to_csv(os.path.join(config[\"general\"][\"out_path\"], 'submission_ensemble_mean.csv'), index='recording_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls './rfcx_kaggle_git/RFCX_kaggle/experiments/logs1_features=melspec_mr_SR=32_CMVN=F_mean_model=tf_effnet_b0_Pretrained=T_SED=T_aggr=mean_act_func=Mish_criterion=FOCAL_Balanced=T_length=6_n_classes=24_optim=ranger_sched=cosine_lr=1e-3_SpecAug=F_MixUp=True_alpha=16_Gain=T_n_mels=256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ls /media/paniquex/samsung_2tb/rfcx_kaggle/rfcx-species-audio-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(config[\"general\"][\"data_root\"], 'train_tp.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"time_diff\"] = data[\"t_max\"] - data[\"t_min\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"time_diff\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"time_diff\"] < 0.6][\"time_diff\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
